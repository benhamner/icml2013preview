{
 "metadata": {
  "name": "LDA Exploration"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "import cPickle as pickle\n",
      "from gensim import corpora, models, similarities\n",
      "import itertools\n",
      "import nltk\n",
      "import os\n",
      "import paper\n",
      "\n",
      "papers = pickle.load(open(os.path.join(os.environ[\"DataPath\"], \"icml2013preview\", \"papers\", \"papers.pickle\")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def require_word_to_be_in_n_documents(n, texts):\n",
      "    unique_words = [list(set(text)) for text in texts]\n",
      "    counts = Counter(itertools.chain(*unique_words))\n",
      "    return [[word for word in text if counts[word]>=n] for text in texts]\n",
      "\n",
      "def papers_to_corpora(papers):\n",
      "    texts = [paper.tokens for paper in papers]\n",
      "    texts = require_word_to_be_in_n_documents(2, texts)\n",
      "\n",
      "    dictionary = corpora.Dictionary(texts)\n",
      "    print(dictionary)\n",
      "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "    tfidf = models.TfidfModel(corpus)\n",
      "    corpus_tfidf = tfidf[corpus]\n",
      "    return corpus_tfidf, dictionary\n",
      "\n",
      "def train_lda(num_topics, corpus, dictionary):\n",
      "    lda = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, update_every=1, passes=10)\n",
      "    return lda\n",
      "\n",
      "def run_pipeline(papers):\n",
      "    corpus, dictionary = papers_to_corpora(papers)\n",
      "    lda = train_lda(6, corpus, dictionary)\n",
      "    print(lda.show_topics(-1, 10))\n",
      "    return lda, corpus, dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda, corpus, dictionary = run_pipeline(papers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(4055 unique tokens)\n",
        "['0.003*kernel + 0.002*loss + 0.002*sparse + 0.002*matrix + 0.002*log + 0.002*inference + 0.002*tree + 0.002*convex + 0.002*regression + 0.002*feature', '0.003*topic + 0.003*dropout + 0.002*deep + 0.002*policy + 0.001*environment + 0.001*units + 0.001*reinforcement + 0.001*words + 0.001*topics + 0.001*state', '0.003*domain + 0.002*arm + 0.002*adaptation + 0.002*target + 0.002*source + 0.002*transfer + 0.002*arms + 0.002*regret + 0.002*online + 0.001*measures', '0.003*policy + 0.002*reward + 0.001*screening + 0.001*kde + 0.001*reinforcement + 0.001*causal + 0.001*completion + 0.001*annotation + 0.001*sdca + 0.001*auc', '0.002*dictionary + 0.002*images + 0.002*cca + 0.002*tensor + 0.002*image + 0.001*bag + 0.001*pooling + 0.001*canonical + 0.001*sampling + 0.001*object', '0.002*patterns + 0.001*corruption + 0.001*copula + 0.001*auc + 0.001*static + 0.001*stability + 0.001*vanishing + 0.001*quotient + 0.001*corrupted + 0.001*behaviors']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(lda.num_topics):\n",
      "    print(\" \".join([x[1] for x in lda.show_topic(i,10)]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "kernel loss sparse matrix log inference tree convex regression feature\n",
        "topic dropout deep policy environment units reinforcement words topics state\n",
        "domain arm adaptation target source transfer arms regret online measures\n",
        "policy reward screening kde reinforcement causal completion annotation sdca auc\n",
        "dictionary images cca tensor image bag pooling canonical sampling object\n",
        "patterns corruption copula auc static stability vanishing quotient corrupted behaviors\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.filter_extremes(3,.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    }
   ],
   "metadata": {}
  }
 ]
}