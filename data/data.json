{"topics": [["dropout", "admm", "momentum", "options", "rbm", "visible", "softmax", "rbms", "lmnn", "itml", "dbns", "bregman", "bisection", "units", "hashing", "bit", "lsh", "fergus", "corruption", "martens"], ["submodular", "realizable", "feedback", "scalable", "nonnegative", "sgd", "audio", "bilmes", "poisson", "items", "ibp", "music", "sort", "contraction", "waiting", "item", "perturbation", "unconstrained", "psd", "stochastic"], ["kernel", "loss", "policy", "sparse", "topic", "inference", "regression", "features", "latent", "convex", "online", "tree", "kernels", "gaussian", "sampling", "label", "regret", "domain", "state", "dictionary"], ["cca", "vol", "customer", "canonical", "smc", "strict", "cut", "particles", "monotonicity", "proposal", "particle", "leverage", "clustering", "clusters", "safe", "sec", "knn", "submodular", "tracking", "boltzmann"], ["daily", "subsample", "worker", "portfolio", "returns", "extreme", "viral", "subsampling", "workers", "movie", "channel", "hash", "hashing", "particle", "multitask", "chaudhuri", "day", "nmf", "percentage", "event"], ["songs", "tags", "neurons", "internal", "annotation", "neuron", "stability", "music", "sound", "separation", "dag", "passive", "innovation", "moment", "rbm", "annotations", "deep", "audio", "rifai", "autoencoder"]], "papers": [{"title": "On autoencoder scoring", "topics": [0.018958032016536352, 0.018869452037032226, 0.90554643446602456, 0.018869791436974134, 0.018869461031712796, 0.018886829011719702], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kamyshanska13.pdf", "most_common": ["autoencoder", "data", "scores", "autoencoders", "energy", "learning", "training", "using", "activation", "hidden", "model", "function", "models", "class", "may", "log", "bengio", "sigmoid", "linear", "vector", "reconstruction", "factored", "assign", "one", "error", "example", "dynamical", "vincent", "conference", "memisevic", "scoring", "show", "score", "binary", "alain", "const", "activations", "international", "hinton", "train", "machine", "systems", "compute", "case", "rbm", "used", "functions", "weights", "learn", "representations", "gradient", "classes", "also", "performance", "probabilistic", "unnormalized", "units", "neural", "input", "denoising", "unit", "information", "shown", "features", "number", "based", "processing", "deep", "parameters", "trained", "viewed", "aes", "rifai", "variety", "allows", "use", "work", "criterion", "swersky", "energies", "squared", "larochelle", "exp", "typically", "section", "networks", "contractive", "like", "way", "outputs", "figure", "good", "term", "weight", "since", "shows", "normalizing", "icml", "potential", "multiple"], "authors": ["Hanna Kamyshanska", "Roland Memisevic"], "thumbnail_path": "thumbnails/On autoencoder scoring.jpg"}, {"title": "On the difficulty of training Recurrent Neural Networks", "topics": [0.015690514435736019, 0.015688876408962032, 0.92155274972942625, 0.015689003393338653, 0.01568934536878247, 0.015689510663754659], "pdf_url": "http://jmlr.org/proceedings/papers/v28/pascanu13.pdf", "most_common": ["model", "gradients", "recurrent", "term", "one", "gradient", "state", "neural", "problem", "networks", "exploding", "wrec", "norm", "vanishing", "time", "training", "long", "error", "clipping", "use", "learning", "see", "order", "network", "bengio", "step", "input", "regularization", "length", "problems", "attractor", "unit", "would", "mikolov", "temporal", "large", "rate", "jaeger", "change", "two", "dynamical", "systems", "hidden", "sequence", "boundary", "sequences", "direction", "descent", "task", "success", "doya", "results", "win", "explode", "also", "art", "hypothesis", "basins", "used", "sutskever", "matrix", "msgd", "behaviour", "train", "attraction", "crossing", "given", "jacobian", "bifurcation", "tanh", "value", "components", "proposed", "rnn", "using", "though", "test", "pathological", "asymptotic", "therefore", "curvature", "figure", "information", "maps", "derivative", "practice", "language", "note", "deal", "schmidhuber", "single", "models", "case", "matrices", "diag", "address", "values", "learn", "means", "short"], "authors": ["Razvan Pascanu", "Tomas Mikolov", "Yoshua Bengio"], "thumbnail_path": "thumbnails/On the difficulty of training Recurrent Neural Networks.jpg"}, {"title": "Maxout Networks", "topics": [0.14367381371238061, 0.02155476977309272, 0.77010178125762185, 0.021554256868200981, 0.021556890426658225, 0.02155848796204559], "pdf_url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf", "most_common": ["maxout", "dropout", "training", "model", "set", "error", "units", "networks", "test", "averaging", "best", "mnist", "function", "pooling", "network", "learning", "validation", "deep", "gradient", "linear", "state", "models", "activation", "two", "hidden", "layer", "layers", "neural", "number", "optimization", "large", "approximation", "trained", "hinton", "may", "performance", "many", "using", "methods", "approximate", "convolutional", "rate", "continuous", "well", "use", "dataset", "weights", "applied", "unit", "train", "figure", "max", "art", "table", "conference", "bagging", "obtained", "parameters", "likelihood", "stochastic", "international", "softmax", "inputs", "given", "also", "arbitrarily", "pooled", "fergus", "sgd", "zeiler", "krizhevsky", "new", "method", "value", "bengio", "used", "obtain", "convex", "mask", "results", "small", "prediction", "connected", "positive", "times", "feature", "data", "rates", "proceedings", "geometric", "piecewise", "digits", "srivastava", "mlp", "make", "architectures", "input", "provided", "single", "consists"], "authors": ["Ian Goodfellow", "David Warde-Farley", "Mehdi Mirza", "Aaron Courville", "Yoshua Bengio"], "thumbnail_path": "thumbnails/Maxout Networks.jpg"}, {"title": "Collaborative hyperparameter tuning", "topics": [0.019579141884040013, 0.019579444491233035, 0.90210388722794077, 0.019578925322680539, 0.019579473037638177, 0.019579128036467351], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/bardenet13.pdf", "most_common": ["tuning", "hyperparameter", "optimization", "hyperparameters", "algorithm", "number", "collaborative", "learning", "error", "function", "problems", "section", "figure", "surrogate", "problem", "scot", "methods", "two", "model", "ranking", "log", "average", "set", "similar", "machine", "datasets", "search", "rankings", "validation", "results", "experiment", "point", "default", "space", "also", "smbo", "terms", "used", "dataset", "global", "setup", "experiments", "quality", "random", "new", "conference", "feature", "training", "rank", "given", "target", "note", "common", "method", "criterion", "gaussian", "features", "points", "adaboost", "best", "described", "strategy", "value", "using", "posterior", "separate", "applied", "choice", "sequential", "international", "algorithms", "better", "since", "one", "errors", "means", "kernel", "bayesian", "thus", "user", "grid", "step", "bergstra", "presented", "past", "prior", "descriptors", "propose", "optimal", "research", "strategies", "proceedings", "principal", "knowledge", "automatic", "see", "available", "three", "journal", "use"], "authors": ["Rmi Bardenet", "Mtys Brendel", "Balazs Kegl", "Michele Sebag"], "thumbnail_path": "thumbnails/Collaborative hyperparameter tuning.jpg"}, {"title": "Learning midlevel representations of objects by harnessing the aperture problem", "topics": [0.016146977536069709, 0.016146865487577315, 0.9192639462024399, 0.016146981744163586, 0.016146891398925309, 0.016148337630824228], "pdf_url": "http://jmlr.org/proceedings/papers/v28/memisevic13.pdf", "most_common": ["features", "learning", "images", "invariant", "aperture", "training", "videos", "model", "learn", "data", "complex", "using", "transformations", "motion", "set", "memisevic", "cell", "figure", "subspace", "models", "pooling", "fourier", "components", "problem", "image", "approach", "objects", "example", "transformation", "object", "video", "work", "show", "use", "two", "one", "also", "input", "frames", "representation", "shows", "energy", "multiple", "layer", "neural", "test", "computation", "subspaces", "trained", "shown", "across", "invariance", "form", "harnessing", "feature", "natural", "rotations", "makes", "representations", "used", "related", "autoencoder", "recognition", "encode", "amounts", "matrix", "translations", "bilinear", "since", "may", "hoyer", "olshausen", "class", "random", "vincent", "vision", "frame", "see", "fleet", "code", "norb", "allows", "cadieu", "hinton", "factored", "still", "rotation", "linear", "top", "extracting", "rao", "note", "phase", "typically", "based", "responses", "noisy", "independent", "well", "possible"], "authors": ["Roland Memisevic", "Georgios Exarchakis"], "thumbnail_path": "thumbnails/Learning midlevel representations of objects by harnessing the aperture problem.jpg"}, {"title": "Approximation properties of DBNs with binary hidden units and realvalued visible units", "topics": [0.019908035954116516, 0.019796674408096092, 0.90085518304407697, 0.019799548016016882, 0.019796261003334432, 0.019844297574359081], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/krause13.pdf", "most_common": ["pmix", "distributions", "binary", "visible", "mixture", "units", "distribution", "hidden", "approximation", "dbns", "family", "properties", "log", "variables", "qmix", "mixtures", "bound", "exp", "gaussian", "let", "mix", "arbitrarily", "thus", "model", "theorem", "rbms", "hinton", "given", "exponential", "conditional", "results", "neural", "every", "compact", "dbn", "exists", "deep", "restricted", "belief", "probability", "roux", "networks", "lemma", "rbm", "follows", "layers", "show", "equation", "one", "variance", "learning", "well", "positive", "following", "furthermore", "bengio", "constant", "computation", "case", "copenhagen", "vectors", "two", "get", "holds", "energy", "number", "parameters", "joint", "corresponding", "layer", "normalization", "components", "strictly", "dvj", "models", "upper", "subset", "approximated", "continuous", "boltzmann", "densities", "written", "however", "salakhutdinov", "independent", "used", "density", "representational", "power", "step", "universal", "second", "machines", "information", "element", "practice", "shown", "formula", "kldivergence", "proceedings"], "authors": ["Oswin Krause", "Asja Fischer", "Tobias Glasmachers", "Christian Igel"], "thumbnail_path": "thumbnails/Approximation properties of DBNs with binary hidden units and realvalued visible units.jpg"}, {"title": "Better Mixing via Deep Representations", "topics": [0.016237019891423256, 0.016224702880101756, 0.91884288482602583, 0.01622542323400614, 0.016224576677715111, 0.016245392490728025], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/bengio13.pdf", "most_common": ["samples", "learning", "better", "deep", "mixing", "representations", "one", "modes", "would", "deeper", "algorithms", "levels", "input", "bengio", "distribution", "factors", "sampling", "higher", "volume", "space", "data", "representation", "layer", "interpolating", "manifold", "markov", "disentangling", "features", "classes", "also", "hypothesis", "hinton", "good", "used", "model", "mnist", "using", "manifolds", "via", "cae", "raw", "dbn", "rifai", "pages", "layers", "hidden", "mode", "another", "proceedings", "tfd", "experiments", "underlying", "examples", "associated", "chain", "likely", "example", "machine", "lecun", "quality", "top", "obtained", "points", "tend", "models", "depth", "results", "rbm", "may", "hypotheses", "mcmc", "idea", "training", "object", "various", "many", "density", "conference", "near", "report", "noise", "generated", "international", "technical", "two", "correspond", "interpolation", "could", "unlikely", "boltzmann", "vincent", "second", "lower", "mix", "image", "nearest", "whereas", "variation", "faster", "neighbors"], "authors": ["Yoshua Bengio", "Gregoire Mesnil", "Yann Dauphin", "Salah Rifai"], "thumbnail_path": "thumbnails/Better Mixing via Deep Representations.jpg"}, {"title": "Fast dropout training", "topics": [0.20619916462659404, 0.029414543389850962, 0.67614449633454143, 0.029414117566224824, 0.029413276008744337, 0.029414402074044655], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wang13a.pdf", "most_common": ["dropout", "training", "fast", "neural", "gaussian", "time", "approximation", "using", "objective", "real", "log", "data", "hidden", "loss", "function", "unit", "random", "variance", "sampling", "input", "noise", "test", "table", "gradient", "features", "networks", "regression", "samples", "validation", "error", "proceedings", "used", "trained", "let", "also", "logistic", "manning", "see", "learning", "respect", "datasets", "variable", "results", "errors", "hinton", "train", "wang", "figure", "feature", "still", "shown", "network", "normal", "methods", "computed", "approach", "plain", "units", "without", "output", "approximate", "applied", "exact", "method", "instead", "directly", "inputs", "linear", "one", "performance", "show", "expectation", "distribution", "taking", "case", "mnist", "less", "dimensions", "much", "faster", "small", "maxout", "sgd", "integrating", "regularization", "may", "number", "softmax", "mean", "idea", "sentiment", "since", "performs", "times", "rate", "empirically", "set", "label", "make", "several"], "authors": ["Sida Wang", "Christopher Manning"], "thumbnail_path": "thumbnails/Fast dropout training.jpg"}, {"title": "Feature Selection in HighDimensional Classification", "topics": [0.017590093355902888, 0.01758940057908976, 0.91204982058528639, 0.017591414428519983, 0.017589502856744176, 0.017589768194456817], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kolar13.pdf", "most_common": ["problem", "log", "sample", "set", "theorem", "size", "sign", "selection", "road", "discriminant", "optimization", "analysis", "solution", "conditions", "sparsity", "variable", "matrix", "lemma", "linear", "distance", "hamming", "let", "min", "constant", "results", "vector", "scaled", "section", "feature", "result", "procedure", "regime", "estimator", "scaling", "recover", "denote", "given", "equal", "consistency", "version", "following", "proof", "high", "sharp", "parameter", "support", "subplot", "corresponds", "independent", "three", "fan", "sublinear", "paper", "show", "estimation", "dimensional", "characterize", "power", "fractional", "second", "theoretical", "least", "observe", "simulation", "oracle", "risk", "condition", "behavior", "two", "particular", "figure", "information", "max", "provide", "correlation", "kkt", "denotes", "probability", "class", "covariance", "used", "identity", "lower", "components", "sparse", "provides", "toeplitz", "assume", "consider", "multivariate", "next", "cai", "recovery", "recovers", "mai", "data", "characterizes", "shows", "population", "liu"], "authors": ["Mladen Kolar", "Han Liu"], "thumbnail_path": "thumbnails/Feature Selection in HighDimensional Classification.jpg"}, {"title": "Markov Network Estimation From Multiattribute Data", "topics": [0.017903049313094787, 0.017902587585029731, 0.9104737807678116, 0.017914228524490223, 0.017902618894159748, 0.017903734915413812], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kolar13a.pdf", "most_common": ["graph", "matrix", "distance", "estimation", "hamming", "nodes", "procedure", "network", "covariance", "data", "precision", "partial", "canonical", "sample", "log", "chain", "markov", "blocks", "results", "nearest", "correlation", "estimate", "graphical", "neighbor", "block", "estimating", "set", "based", "method", "given", "one", "random", "model", "using", "following", "gaussian", "size", "number", "selection", "conditions", "problem", "attributes", "node", "max", "diagonal", "nodal", "networks", "however", "independent", "update", "glasso", "multivariate", "two", "attribute", "also", "optimization", "chiquet", "kolar", "sparse", "guo", "let", "obtained", "vectors", "gene", "penalized", "likelihood", "variables", "graphs", "penalty", "descent", "yuan", "structure", "assume", "inverse", "vector", "consistent", "current", "theoretical", "figure", "provide", "paper", "university", "note", "objective", "multiple", "learning", "corresponding", "proposed", "step", "methods", "single", "models", "follow", "estimates", "zero", "new", "usa", "lemma", "known", "example"], "authors": ["Mladen Kolar", "Han Liu", "Eric Xing"], "thumbnail_path": "thumbnails/Markov Network Estimation From Multiattribute Data.jpg"}, {"title": "Exact Rule Learning via Boolean Compressed Sensing", "topics": [0.020830010991136842, 0.020830061953165318, 0.89584745742670757, 0.0208321233284991, 0.020829790754352769, 0.020830555546138368], "pdf_url": "http://jmlr.org/proceedings/papers/v28/malioutov13.pdf", "most_common": ["rule", "learning", "boolean", "set", "rules", "problem", "compressed", "data", "group", "decision", "sets", "sensing", "testing", "accuracy", "via", "approach", "exact", "using", "sparse", "matrix", "training", "features", "recovery", "one", "also", "section", "individual", "columns", "optimization", "proposed", "samples", "algorithm", "combinatorial", "solution", "covering", "results", "learned", "relaxation", "clauses", "boosting", "binary", "interpretability", "signal", "interpretable", "conjunctive", "use", "example", "better", "approaches", "number", "lists", "single", "work", "malyutov", "conditions", "error", "consider", "linear", "apply", "learn", "thresholds", "analytics", "however", "malioutov", "property", "petal", "heuristic", "possible", "nonzero", "vector", "second", "feature", "paper", "since", "programming", "probability", "clause", "cohen", "min", "objective", "continuous", "show", "based", "best", "terms", "two", "simple", "subjects", "tests", "would", "ixj", "small", "learner", "satisfy", "table", "known", "machine", "may", "recover", "note"], "authors": ["Dmitry Malioutov", "Kush Varshney"], "thumbnail_path": "thumbnails/Exact Rule Learning via Boolean Compressed Sensing.jpg"}, {"title": "Sparse Recovery under Linear Transformation", "topics": [0.017220508697573529, 0.017220573531645415, 0.91389680311555466, 0.017220919304747298, 0.0172204605732552, 0.017220734777223853], "pdf_url": "http://jmlr.org/proceedings/papers/v28/liu13.pdf", "most_common": ["number", "condition", "log", "case", "matrix", "random", "error", "lasso", "sparse", "estimate", "one", "probability", "signal", "bounded", "recovery", "problem", "gaussian", "min", "linear", "fused", "analysis", "consider", "high", "measurement", "transformation", "two", "following", "noisy", "bound", "true", "noiseless", "let", "given", "entries", "consistent", "verify", "paper", "special", "assumption", "section", "consistency", "guaranteed", "constant", "assume", "results", "upper", "term", "statistics", "converges", "model", "theorem", "using", "sparsity", "graph", "theoretical", "cases", "since", "least", "recover", "result", "measurements", "existing", "total", "tao", "large", "relative", "set", "see", "learning", "general", "value", "property", "formulation", "zhang", "vector", "max", "ieee", "theory", "recovered", "second", "note", "edge", "annals", "numerical", "use", "journal", "norm", "solution", "zero", "larger", "work", "information", "machine", "main", "free", "standard", "tibshirani", "part", "transactions", "considered"], "authors": ["Ji Liu", "Lei Yuan", "Jieping Ye"], "thumbnail_path": "thumbnails/Sparse Recovery under Linear Transformation.jpg"}, {"title": "Noisy and Missing Data Regression DistributionOblivious Support Recovery", "topics": [0.01810785922152167, 0.018108038055665274, 0.90945516976520324, 0.018108789110153116, 0.01810818746000635, 0.018111956387450435], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/chen13d.pdf", "most_common": ["support", "noise", "algorithm", "recovery", "missing", "results", "theorem", "data", "wainwright", "knowledge", "loh", "performance", "omp", "error", "bounds", "show", "regression", "covariance", "rosenbaum", "tsybakov", "noisy", "consider", "two", "work", "standard", "case", "use", "log", "provide", "independent", "model", "method", "additive", "proof", "algorithms", "selector", "covariate", "columns", "obtain", "sparse", "even", "information", "matrix", "guarantees", "matching", "setting", "parameter", "problem", "using", "methods", "ieee", "one", "require", "note", "set", "seems", "minimax", "inner", "simulations", "theory", "known", "following", "figure", "gaussian", "covariates", "estimate", "probability", "improved", "lower", "moreover", "dantzig", "zit", "estimator", "bound", "correlated", "assume", "orthogonal", "design", "particular", "product", "condition", "also", "simple", "analysis", "without", "lasso", "either", "let", "pursuit", "via", "control", "better", "good", "gradient", "projected", "shows", "greedy", "seem", "grad", "estimation"], "authors": ["Yudong Chen", "Constantine Caramanis"], "thumbnail_path": "thumbnails/Noisy and Missing Data Regression DistributionOblivious Support Recovery.jpg"}, {"title": "Learning Policies for Contextual Submodular Prediction", "topics": [0.016784762430543155, 0.016795810290666281, 0.91604279118448495, 0.016803398516011672, 0.016786369023609696, 0.01678686855468425], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ross13b.pdf", "most_common": ["list", "learning", "submodular", "online", "policies", "scp", "loss", "features", "policy", "contextual", "algorithm", "performance", "prediction", "using", "training", "item", "distribution", "optimization", "items", "approach", "use", "set", "state", "problem", "learner", "let", "weighted", "reduction", "sequence", "construct", "best", "guarantees", "dey", "data", "predict", "greedy", "conseqopt", "lists", "function", "convex", "denote", "update", "cti", "work", "example", "one", "lin", "user", "also", "setting", "regret", "streeter", "guestrin", "good", "yue", "min", "expected", "thus", "regression", "document", "reward", "examples", "functions", "consider", "golovin", "goal", "may", "value", "probability", "directly", "class", "result", "clairvoyant", "initial", "single", "test", "section", "bilmes", "agnostic", "learn", "vti", "linear", "bagnell", "length", "multiple", "rouge", "maximize", "trajectory", "case", "wti", "trajectories", "position", "via", "often", "submodularity", "problems", "joachims", "taskar", "new", "pick"], "authors": ["Stephane Ross", "Jiaji Zhou", "Yisong Yue", "Debadeepta Dey", "Drew Bagnell"], "thumbnail_path": "thumbnails/Learning Policies for Contextual Submodular Prediction.jpg"}, {"title": "Learning an Internal Dynamics Model from Control Demonstration", "topics": [0.028264788124776147, 0.028265634712058101, 0.85860597076818823, 0.028264692131958546, 0.028264691319906377, 0.02833422294311284], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/golub13.pdf", "most_common": ["internal", "model", "cursor", "control", "plant", "state", "dynamics", "bmi", "ime", "feedback", "subject", "timestep", "actual", "learning", "estimates", "may", "target", "position", "cost", "neural", "estimate", "current", "data", "aiming", "function", "trial", "delay", "parameters", "sensory", "latent", "motor", "estimation", "visual", "task", "demonstration", "true", "problem", "models", "section", "states", "framework", "angular", "drive", "across", "graphical", "work", "training", "given", "trajectory", "straight", "error", "goals", "likelihood", "machine", "optimal", "abbeel", "trajectories", "variables", "probabilistic", "international", "activity", "commands", "recorded", "algorithm", "inverse", "errors", "figure", "belief", "system", "note", "knowledge", "available", "due", "timesteps", "seek", "input", "predictions", "form", "line", "time", "applied", "demonstrations", "along", "use", "would", "mismatch", "known", "schwartz", "previously", "extract", "red", "toward", "access", "black", "observed", "see", "points", "movements", "signals", "using"], "authors": ["Matthew Golub", "Steven Chase", "Byron Yu"], "thumbnail_path": "thumbnails/Learning an Internal Dynamics Model from Control Demonstration.jpg"}, {"title": "Safe Policy Iteration", "topics": [0.024253268894435832, 0.024252792384187115, 0.87873017871084158, 0.024258347454185637, 0.024252586173870549, 0.024252826382479345], "pdf_url": "http://jmlr.org/proceedings/papers/v28/pirotta13.pdf", "most_common": ["policy", "state", "iteration", "improvement", "algorithms", "bound", "policies", "two", "value", "following", "one", "function", "uspi", "mspi", "safe", "cpi", "greedy", "performance", "iterations", "amspi", "kakade", "algorithm", "auspi", "states", "advantage", "number", "approximate", "corollary", "theorem", "distribution", "consider", "values", "optimal", "since", "figure", "matrix", "using", "starting", "set", "case", "step", "chain", "may", "paper", "target", "proposed", "approximation", "current", "spi", "improving", "approaches", "new", "taking", "section", "derivative", "langford", "transition", "given", "bounds", "action", "lower", "stationary", "acpi", "api", "approximated", "maximizes", "gradient", "estimate", "size", "parr", "future", "proceedings", "lemma", "factor", "approach", "expected", "larger", "guaranteed", "blackjack", "follows", "convex", "discount", "initial", "whose", "worse", "version", "use", "better", "return", "domain", "space", "card", "considered", "problem", "perform", "discounted", "model", "reward", "learning", "possible"], "authors": ["Matteo Pirotta", "Marcello Restelli", "Alessio Pecorino", "Daniele Calandriello"], "thumbnail_path": "thumbnails/Safe Policy Iteration.jpg"}, {"title": "Temporal Difference Methods for the Variance of the Reward To Go", "topics": [0.017296852946642665, 0.017297203153918934, 0.91351088009840986, 0.017297279342154522, 0.017297080494766488, 0.01730070396410751], "pdf_url": "http://jmlr.org/proceedings/papers/v28/tamar13.pdf", "most_common": ["variance", "may", "state", "approximation", "equation", "policy", "let", "function", "reward", "algorithm", "bertsekas", "lstd", "denote", "proposition", "solution", "projected", "evaluation", "methods", "linear", "point", "learning", "following", "assumption", "using", "norm", "second", "matrix", "vector", "value", "algorithms", "space", "standard", "show", "based", "exists", "trajectories", "convergence", "temporal", "lemma", "reinforcement", "barto", "large", "mdp", "also", "sutton", "respect", "thus", "guarantees", "unique", "decision", "deviation", "consider", "stochastic", "section", "onto", "features", "given", "result", "approach", "estimation", "moment", "projection", "obtained", "positive", "known", "process", "assumptions", "propose", "framework", "inequality", "weighted", "estimate", "probability", "continuous", "terminal", "mannor", "theorem", "step", "approximate", "distribution", "markov", "version", "estimates", "even", "method", "equations", "domains", "next", "therefore", "criteria", "appendix", "states", "proof", "control", "figure", "machine", "tsitsiklis", "mapping", "used", "denotes"], "authors": ["Aviv Tamar", "Dotan Di Castro", "Shie Mannor"], "thumbnail_path": "thumbnails/Temporal Difference Methods for the Variance of the Reward To Go.jpg"}, {"title": "Value Iteration with incremental representation learning for continuous POMDPs", "topics": [0.016524415286370577, 0.016524803996706815, 0.91734671977496762, 0.016554949180596322, 0.016524971859397514, 0.0165241399019611], "pdf_url": "http://jmlr.org/proceedings/papers/v28/brechtel13.pdf", "most_common": ["value", "continuous", "representation", "belief", "discrete", "space", "backup", "iteration", "state", "learning", "bound", "pomdps", "beliefs", "problem", "pomdp", "function", "every", "solving", "lower", "upper", "optimal", "using", "decision", "thus", "policy", "samples", "results", "presented", "planning", "process", "solver", "implementation", "porta", "observations", "problems", "algorithm", "represent", "concept", "states", "incremental", "observation", "set", "obstacle", "case", "must", "poupart", "particles", "approaches", "also", "new", "solve", "step", "idea", "intelligence", "time", "linear", "even", "represented", "agent", "end", "corridor", "number", "tree", "used", "sparse", "operator", "bounds", "functions", "monte", "approximation", "evaluated", "carlo", "values", "machine", "robot", "research", "smc", "one", "need", "expectation", "observable", "according", "systems", "procedure", "reward", "intersection", "arbitrary", "journal", "basis", "approximate", "partially", "general", "novel", "second", "use", "next", "therefore", "known", "information", "shows"], "authors": ["Sebastian Brechtel", "Tobias Gindele", "R diger Dillmann"], "thumbnail_path": "thumbnails/Value Iteration with incremental representation learning for continuous POMDPs.jpg"}, {"title": "The SampleComplexity of General Reinforcement Learning", "topics": [0.02008418582438963, 0.02008425288831021, 0.89957895912899311, 0.020084465900471662, 0.020084088196746178, 0.020084048061089186], "pdf_url": "http://jmlr.org/proceedings/papers/v28/lattimore13.pdf", "most_common": ["exploration", "learning", "phase", "environments", "environment", "merl", "bound", "emax", "lemma", "let", "number", "bounds", "reinforcement", "general", "since", "policy", "phases", "set", "gmax", "algorithm", "class", "case", "probability", "hutter", "optimal", "log", "true", "history", "model", "failure", "lower", "theorem", "classes", "proper", "follows", "start", "therefore", "high", "show", "mdps", "proof", "given", "also", "exists", "lattimore", "union", "upper", "work", "proceedings", "conference", "value", "used", "exploiting", "statistics", "results", "international", "known", "rather", "machine", "one", "respect", "sequence", "time", "compact", "finally", "martingale", "regret", "end", "return", "least", "nearly", "state", "policies", "discounted", "reward", "either", "function", "apply", "probabilities", "values", "example", "write", "complexity", "algorithms", "large", "see", "close", "would", "expected", "without", "strehl", "arbitrary", "within", "samplecomplexity", "problem", "maximum", "bandits", "never", "explore", "logarithmic"], "authors": ["Tor Lattimore", "Marcus Hutter", "Peter Sunehag"], "thumbnail_path": "thumbnails/The SampleComplexity of General Reinforcement Learning.jpg"}, {"title": "Online Feature Selection for Modelbased Reinforcement Learning", "topics": [0.01607993141827092, 0.016077595789229928, 0.91960798855505577, 0.016078546040831414, 0.016077969967523805, 0.016077968229088153], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/nguyen13.pdf", "most_common": ["learning", "state", "transition", "features", "feature", "model", "online", "lorerl", "regression", "optimal", "action", "logistic", "selection", "reinforcement", "frmax", "reward", "function", "factored", "also", "method", "multinomial", "however", "dynamics", "proceedings", "fepsg", "time", "environment", "learn", "states", "algorithm", "may", "policy", "small", "figure", "dbn", "data", "mdp", "based", "relevant", "conference", "structure", "agent", "machine", "matrix", "space", "rmax", "robot", "average", "exploration", "let", "actions", "accumulated", "parameter", "cmdp", "world", "models", "large", "regret", "binary", "vector", "random", "using", "stone", "episodes", "still", "group", "number", "structures", "mdagl", "set", "irrelevant", "value", "near", "manually", "used", "task", "sparse", "four", "international", "work", "table", "information", "regularization", "framework", "since", "probability", "without", "knowledge", "parameters", "experiments", "capture", "changes", "lasso", "often", "regularized", "predicting", "methods", "blorerl", "michael", "selected"], "authors": ["Trung Nguyen", "Zhuoru Li", "Tomi Silander", "Tze Yun Leong"], "thumbnail_path": "thumbnails/Online Feature Selection for Modelbased Reinforcement Learning.jpg"}, {"title": "Bayesian Learning of Recursively Factored Environments", "topics": [0.019122162474507196, 0.019122076129664003, 0.90438847669736144, 0.019122301571485593, 0.019122193327291721, 0.019122789799690041], "pdf_url": "http://jmlr.org/proceedings/papers/v28/bellemare13.pdf", "most_common": ["model", "environment", "learning", "space", "recursively", "factored", "factorization", "reinforcement", "set", "factorizations", "bayesian", "observation", "models", "decomposable", "veness", "atari", "qtf", "used", "given", "dim", "conference", "using", "nesting", "prior", "number", "best", "averaging", "possible", "time", "equation", "depth", "example", "base", "spaces", "intelligence", "log", "bellemare", "tree", "class", "patch", "environments", "image", "large", "section", "percept", "information", "recursive", "silver", "size", "factor", "algorithm", "joel", "cts", "domains", "notation", "many", "context", "denote", "hutter", "factors", "patches", "technique", "string", "larger", "product", "introduce", "denoted", "one", "probabilistic", "techniques", "case", "action", "also", "game", "loss", "describe", "whose", "international", "allows", "two", "particular", "weighting", "machine", "algorithms", "paper", "bowling", "performance", "frame", "approach", "games", "general", "neural", "processing", "within", "frames", "corresponding", "results", "planning", "sequential", "logarithmic"], "authors": ["Marc Bellemare", "Joel Veness", "Michael Bowling"], "thumbnail_path": "thumbnails/Bayesian Learning of Recursively Factored Environments.jpg"}, {"title": "Copy or Coincidence A Model for Detecting Social Influence and Duplication Events", "topics": [0.015703274811684043, 0.015702653160151788, 0.92148542944837952, 0.015702834734311305, 0.015703149757610963, 0.01570265808786217], "pdf_url": "http://jmlr.org/proceedings/papers/v28/friedland13.pdf", "most_common": ["pairs", "data", "model", "cij", "number", "social", "positive", "one", "pair", "performance", "section", "similarity", "points", "score", "ratio", "using", "likelihood", "task", "dij", "distance", "set", "sets", "distributions", "auc", "twins", "method", "inference", "figure", "negative", "generative", "mij", "function", "true", "events", "detecting", "also", "two", "distribution", "would", "generate", "copy", "normal", "duplication", "entities", "point", "coincidence", "increases", "parameters", "values", "process", "parameter", "measure", "since", "could", "mining", "rarity", "detection", "almost", "measures", "form", "synthetic", "shows", "phone", "information", "ranking", "experiments", "baseline", "national", "estimate", "use", "science", "work", "links", "may", "lines", "paper", "matches", "always", "singleton", "variables", "instances", "given", "individual", "linked", "real", "know", "methods", "similar", "generated", "jensen", "turns", "large", "small", "contains", "entity", "ieee", "list", "network", "probability", "mixture"], "authors": ["Lisa Friedland", "David Jensen", "Michael Lavine"], "thumbnail_path": "thumbnails/Copy or Coincidence A Model for Detecting Social Influence and Duplication Events.jpg"}, {"title": "Mixture of Mutually Exciting Processes for Viral Diffusion", "topics": [0.019418267673401112, 0.019418277061852011, 0.90275041484915408, 0.019420823090679988, 0.019572720679105537, 0.019419496645807357], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/yang13a.pdf", "most_common": ["network", "meme", "model", "inference", "viral", "memes", "events", "mixture", "algorithm", "process", "one", "models", "event", "time", "exciting", "mutually", "hawkes", "social", "two", "processes", "set", "point", "variational", "figure", "data", "hidden", "content", "log", "node", "rate", "use", "number", "note", "also", "modeling", "tracking", "fast", "nodes", "future", "based", "infected", "prior", "example", "inferred", "intensity", "snowsill", "using", "netrate", "simultaneously", "latent", "work", "history", "infectivity", "algorithms", "evolution", "probabilistic", "mhps", "mhp", "twitter", "cascades", "single", "structure", "matrix", "results", "tasks", "mmhp", "another", "shows", "contents", "multiple", "experiments", "kernel", "learning", "sparsity", "assuming", "comparison", "sequence", "function", "true", "existing", "large", "current", "causality", "parameters", "usually", "known", "rmse", "challenges", "used", "trends", "variables", "given", "elbo", "blogosphere", "involving", "terms", "genetic", "dag", "independent", "identify"], "authors": ["Shuang-Hong Yang", "Hongyuan Zha"], "thumbnail_path": "thumbnails/Mixture of Mutually Exciting Processes for Viral Diffusion.jpg"}, {"title": "Dynamic Probabilistic Models for Latent Feature Propagation in Social Networks", "topics": [0.019209740292616288, 0.019209823129577648, 0.90394747599482606, 0.019210161423601536, 0.019212848817536946, 0.019209950341841822], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/heaukulani13.pdf", "most_common": ["latent", "feature", "social", "network", "model", "time", "hik", "data", "propagation", "networks", "features", "dataset", "dynamic", "markov", "nips", "lfp", "drift", "models", "see", "lfrm", "state", "parameters", "also", "distribution", "probability", "given", "using", "actor", "space", "variables", "structure", "current", "two", "following", "representations", "baseline", "one", "relational", "observed", "infocom", "use", "matrix", "observations", "set", "future", "samples", "link", "ghahramani", "results", "auc", "particular", "work", "parameter", "transition", "however", "previous", "methods", "prediction", "states", "number", "section", "statistically", "forecasting", "test", "method", "inference", "order", "hidden", "bernoulli", "training", "authors", "point", "snijders", "xing", "based", "foulds", "datasets", "chain", "miller", "prior", "sample", "example", "links", "information", "used", "mcmc", "interests", "probabilistic", "modelling", "hmm", "perform", "edges", "sequence", "year", "stochastic", "large", "interactions", "unobserved", "figure", "next"], "authors": ["Creighton Heaukulani", "Ghahramani Zoubin"], "thumbnail_path": "thumbnails/Dynamic Probabilistic Models for Latent Feature Propagation in Social Networks.jpg"}, {"title": "Modeling Information Propagation with Survival Theory", "topics": [0.021302988943522023, 0.021305430275741121, 0.8934812793947301, 0.021303187201565037, 0.021304044562763517, 0.02130306962167814], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gomez-rodriguez13.pdf", "most_common": ["node", "cascade", "model", "nodes", "additive", "network", "information", "infected", "multiplicative", "time", "hazard", "infection", "models", "set", "propagation", "risk", "cascades", "test", "inference", "using", "likelihood", "consider", "networks", "survival", "function", "rate", "edge", "parameters", "times", "also", "contagion", "previously", "one", "leskovec", "observation", "proceedings", "sets", "infer", "theory", "accuracy", "modeling", "conference", "window", "given", "shaping", "methods", "mse", "therefore", "increase", "number", "size", "ccdf", "international", "independent", "edges", "duration", "two", "general", "optimal", "data", "performance", "several", "underlying", "memes", "log", "however", "learning", "acm", "vector", "decrease", "negative", "wang", "process", "parameter", "term", "used", "show", "observed", "real", "evaluate", "compute", "problem", "functions", "generated", "synthetic", "convexity", "solution", "knowledge", "apply", "training", "particular", "example", "machine", "synthetically", "since", "first", "mining", "continuous", "random", "sites"], "authors": ["Manuel Gomez-Rodriguez", "Jure Leskovec", "Bernhard Schlkopf"], "thumbnail_path": "thumbnails/Modeling Information Propagation with Survival Theory.jpg"}, {"title": "Learning Triggering Kernels for Multidimensional Hawkes Processes", "topics": [0.019625518436490751, 0.019626888814512848, 0.90186821538798667, 0.01962551367023678, 0.019628302172810096, 0.019625561517962783], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhou13.pdf", "most_common": ["kernels", "triggering", "kernel", "data", "hawkes", "base", "performance", "processes", "mmel", "figure", "learning", "true", "estimated", "loglik", "proposed", "events", "equation", "number", "problem", "method", "respect", "function", "parameters", "process", "set", "training", "algorithm", "follows", "work", "used", "measured", "smoothing", "nonparametric", "estimate", "dimensional", "exponential", "model", "samples", "two", "log", "time", "synthetic", "plot", "use", "estmated", "observed", "observe", "journal", "test", "dynamics", "particular", "better", "related", "linear", "quite", "intensity", "show", "thus", "real", "ijd", "moreover", "general", "models", "section", "optimizing", "following", "machine", "parameter", "paper", "propose", "splines", "constraints", "generate", "another", "also", "auuc", "based", "experiments", "case", "value", "optimization", "sets", "dimension", "world", "point", "functional", "distribution", "consider", "social", "positive", "values", "information", "end", "temporal", "event", "large", "relatively", "lewis", "estimation", "trigger"], "authors": ["Ke Zhou", "Le Song", "Hongyuan Zha"], "thumbnail_path": "thumbnails/Learning Triggering Kernels for Multidimensional Hawkes Processes.jpg"}, {"title": "Modeling Temporal Evolution and Multiscale Structure in Networks", "topics": [0.01792366023383845, 0.017923669239657509, 0.9103804150765793, 0.017924129960960766, 0.017924462330300216, 0.017923663158663745], "pdf_url": "http://jmlr.org/proceedings/papers/v28/herlau13.pdf", "most_common": ["temporal", "model", "vertices", "networks", "network", "tree", "structure", "hierarchical", "epoch", "vertex", "models", "change", "giant", "two", "using", "multiscale", "relational", "evolution", "epochs", "gibbs", "states", "irm", "modeling", "time", "democrats", "republicans", "fragmentation", "schmidt", "leafs", "set", "hierarchies", "consider", "thrm", "number", "see", "organization", "nips", "changes", "hrm", "complex", "shown", "issn", "considered", "information", "senators", "hierarchy", "jit", "distributed", "present", "right", "prior", "data", "onto", "voting", "trees", "new", "according", "modelling", "moves", "edge", "proposed", "senate", "results", "matrix", "construction", "enron", "binary", "may", "systems", "one", "given", "beta", "aij", "edges", "subtree", "unique", "methods", "bottom", "properties", "mccullagh", "single", "dynamic", "roy", "auc", "indicating", "let", "social", "type", "science", "process", "processes", "level", "probability", "illustrate", "top", "observations", "inferred", "multifurcating", "corresponds", "community"], "authors": ["Tue Herlau", "Morten Mrup", "Mikkel Schmidt"], "thumbnail_path": "thumbnails/Modeling Temporal Evolution and Multiscale Structure in Networks.jpg"}, {"title": "Scalable Optimization of Neighbor Embedding for Visualization", "topics": [0.01723344178820926, 0.017062524186675445, 0.91452334150554115, 0.017058378757360843, 0.017064654277801634, 0.017057659484411593], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/yang13b.pdf", "most_common": ["data", "methods", "embedding", "neighbor", "points", "visualization", "approximated", "fast", "optimization", "approximation", "learning", "cost", "large", "exact", "gradient", "objective", "method", "mnist", "using", "subset", "qij", "time", "computation", "information", "scalable", "sets", "pij", "hinton", "tree", "computed", "point", "classes", "function", "even", "figure", "machine", "algorithms", "new", "approach", "algorithm", "small", "hours", "sne", "size", "one", "group", "computational", "also", "der", "relative", "conference", "van", "maaten", "datasets", "compared", "original", "results", "stochastic", "bounding", "shows", "international", "box", "larger", "example", "complexity", "experiments", "systems", "uci", "mean", "matrix", "space", "linear", "timit", "neighborhood", "quality", "set", "whole", "nerv", "nldr", "several", "well", "samples", "output", "node", "images", "log", "approximate", "structure", "technique", "subsampling", "smaller", "nonlinear", "contains", "two", "covertype", "shown", "dataset", "divergence", "another", "pairwise"], "authors": ["Zhirong Yang", "Jaakko Peltonen", "Samuel Kaski"], "thumbnail_path": "thumbnails/Scalable Optimization of Neighbor Embedding for Visualization.jpg"}, {"title": "Learning the Structure of SumProduct Networks", "topics": [0.016920295710051495, 0.016920646692203639, 0.91539195328909462, 0.01692171721976676, 0.016924560825475006, 0.016920826263408479], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gens13.pdf", "most_common": ["learning", "variables", "spn", "spns", "structure", "networks", "number", "instances", "query", "algorithm", "learnspn", "set", "learned", "evidence", "inference", "sum", "markov", "partition", "domingos", "graphical", "datasets", "models", "subsets", "test", "function", "distribution", "cll", "node", "variable", "time", "likelihood", "also", "used", "univariate", "using", "nodes", "network", "probability", "returns", "instance", "independent", "model", "pll", "product", "independence", "winmine", "davis", "computed", "bayesian", "cluster", "split", "lowd", "weights", "recursive", "xij", "return", "similar", "distributions", "wij", "clusters", "weight", "linear", "comparable", "table", "step", "fraction", "poon", "advantage", "splitting", "large", "let", "normalized", "root", "sij", "data", "found", "since", "mixture", "tractable", "many", "sampling", "corresponding", "case", "splits", "value", "della", "proposed", "leaf", "pietra", "dataset", "conditional", "deep", "compared", "results", "webkb", "gens", "use", "dna", "two", "values"], "authors": ["Robert Gens", "Domingos Pedro"], "thumbnail_path": "thumbnails/Learning the Structure of SumProduct Networks.jpg"}, {"title": "Deep learning with COTS HPC systems", "topics": [0.014986753755455481, 0.014984427973326194, 0.92485057376780888, 0.014984823179192017, 0.014984415518624436, 0.01520900580559289], "pdf_url": "http://jmlr.org/proceedings/papers/v28/coates13.pdf", "most_common": ["gpu", "gpus", "learning", "deep", "network", "neural", "systems", "large", "networks", "neurons", "figure", "use", "training", "using", "billion", "code", "size", "system", "train", "layer", "input", "computation", "parameters", "many", "hpc", "array", "receptive", "computing", "found", "krizhevsky", "implementation", "neuron", "cluster", "images", "number", "gradient", "cots", "much", "responses", "used", "local", "image", "compute", "larger", "pooling", "parameter", "also", "distributed", "results", "layers", "international", "blocks", "shown", "though", "optimized", "set", "infrastructure", "conference", "make", "dean", "scale", "processing", "communication", "single", "mpi", "contrast", "must", "one", "best", "lecun", "several", "output", "recognition", "block", "software", "trained", "memory", "information", "machine", "inputs", "paper", "window", "linear", "features", "normalization", "approach", "communications", "sparse", "coates", "matrix", "section", "obtained", "hinton", "convolutional", "scaling", "need", "able", "performance", "nvidia", "unsupervised"], "authors": ["Adam Coates", "Brody Huval", "Tao Wang", "David Wu", "Bryan Catanzaro", "Ng Andrew"], "thumbnail_path": "thumbnails/Deep learning with COTS HPC systems.jpg"}, {"title": "Learning and Selecting Features Jointly with Pointwise Gated Boltzmann Machines", "topics": [0.017780282580608819, 0.01774492655198948, 0.91122731896890374, 0.01774694373910141, 0.017744416388367257, 0.01775611177102911], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/sohn13.pdf", "most_common": ["units", "pgbm", "hidden", "features", "learning", "feature", "visible", "model", "switch", "unit", "using", "data", "object", "boltzmann", "selection", "rbm", "supervised", "training", "irrelevant", "patterns", "deep", "two", "raw", "images", "learn", "generative", "used", "gated", "section", "component", "layer", "background", "convolutional", "figure", "group", "bengio", "models", "machines", "machine", "propose", "bounding", "lee", "network", "mixture", "neural", "performance", "jointly", "hinton", "foreground", "class", "larochelle", "cpgdn", "components", "follows", "second", "use", "unsupervised", "corresponding", "unlabeled", "recognition", "selecting", "large", "activations", "representations", "given", "one", "table", "accuracy", "label", "useful", "algorithm", "method", "groups", "imrbm", "sohn", "perform", "complex", "robust", "discriminative", "building", "learned", "train", "example", "may", "dataset", "shown", "shows", "show", "joint", "however", "box", "conditional", "examples", "block", "icml", "also", "inference", "distribution", "caltech", "test"], "authors": ["Kihyuk Sohn", "Guanyu Zhou", "Chansoo Lee", "Honglak Lee"], "thumbnail_path": "thumbnails/Learning and Selecting Features Jointly with Pointwise Gated Boltzmann Machines.jpg"}, {"title": "Regularization of Neural Networks using DropConnect", "topics": [0.14442486918207978, 0.021449105074175464, 0.76976355132771479, 0.021448824999691651, 0.021448945229273233, 0.021464704187065076], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wan13.pdf", "most_common": ["dropconnect", "dropout", "layer", "network", "training", "feature", "model", "using", "error", "fully", "connected", "networks", "neural", "output", "mask", "input", "function", "images", "extractor", "weight", "rate", "learning", "matrix", "activation", "performance", "parameters", "table", "hinton", "softmax", "gpu", "set", "test", "weights", "regularization", "complexity", "voting", "random", "layers", "data", "train", "size", "lemma", "results", "example", "previous", "loss", "use", "relu", "generalization", "show", "rademacher", "units", "applied", "krizhevsky", "large", "activations", "unit", "memory", "experiments", "implementation", "ciresan", "mnist", "methods", "bound", "initial", "models", "convolutional", "rather", "zeiler", "features", "number", "result", "used", "epochs", "image", "single", "elements", "section", "experiment", "fergus", "inference", "trained", "element", "dataset", "mean", "shows", "randomly", "computer", "described", "tanh", "lecun", "biases", "functions", "consider", "two", "equation", "ieee", "bernoulli", "since", "standard"], "authors": ["Li Wan", "Matthew Zeiler", "Sixin Zhang", "Yann Le Cun", "Rob Fergus"], "thumbnail_path": "thumbnails/Regularization of Neural Networks using DropConnect.jpg"}, {"title": "Thurstonian Boltzmann Machines Learning from Multiple Inequalities", "topics": [0.015185438478229167, 0.015152178340680443, 0.92419249177303309, 0.015161585633096289, 0.015153034381889368, 0.015155271393071601], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/tran13.pdf", "most_common": ["boltzmann", "tbm", "data", "variables", "gaussian", "hidden", "constraints", "model", "machines", "binary", "one", "learning", "thus", "distribution", "thurstonian", "using", "categories", "rbm", "probit", "ordinal", "evidences", "statistics", "information", "types", "rank", "continuous", "set", "collaborative", "pages", "evidence", "case", "analysis", "models", "section", "salakhutdinov", "machine", "inequality", "used", "point", "samples", "standard", "observed", "see", "underlying", "layer", "per", "survey", "hinton", "particular", "figure", "categorical", "probability", "units", "without", "input", "boxed", "ranking", "processing", "subset", "ordered", "multivariate", "unit", "two", "applications", "truyen", "matrix", "posteriors", "restricted", "given", "need", "proceedings", "inequalities", "however", "simple", "inference", "normal", "due", "chain", "markov", "example", "parameter", "max", "tran", "category", "since", "xil", "countries", "constrained", "min", "multiple", "latent", "learned", "best", "user", "boundaries", "many", "much", "systems", "general", "neural"], "authors": ["Truyen Tran", "Dinh Phung", "Svetha Venkatesh"], "thumbnail_path": "thumbnails/Thurstonian Boltzmann Machines Learning from Multiple Inequalities.jpg"}, {"title": "Iterative Learning and Denoising in Convolutional Neural Associative Memories", "topics": [0.017114236500143404, 0.017109471290014965, 0.91425136364498294, 0.017109892349656448, 0.017109353569515109, 0.017305682645687229], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/karbasi13.pdf", "most_common": ["learning", "algorithm", "neural", "pattern", "patterns", "set", "network", "capacity", "recall", "associative", "error", "cluster", "noise", "one", "phase", "neurons", "degree", "convolutional", "iterative", "number", "graph", "denoising", "work", "ieee", "proposed", "input", "constraint", "vectors", "figure", "constraints", "also", "noisy", "single", "results", "linear", "among", "neuron", "theorem", "memories", "vector", "learn", "algorithms", "correct", "retrieval", "size", "given", "sparsity", "matrix", "orthogonal", "entries", "small", "training", "iteration", "networks", "local", "memorized", "performance", "fraction", "large", "shown", "note", "threshold", "state", "subspace", "dual", "let", "dbns", "redundancy", "weight", "probability", "bipartite", "show", "oja", "case", "exponential", "model", "errors", "section", "kumar", "following", "proof", "order", "clusters", "furthermore", "features", "correction", "able", "new", "considered", "based", "lausanne", "used", "overlapping", "similar", "salavati", "assume", "since", "consider", "nodes", "method"], "authors": ["Amin Karbasi", "Amir Hesam Salavati", "Amin Shokrollahi,"], "thumbnail_path": "thumbnails/Iterative Learning and Denoising in Convolutional Neural Associative Memories.jpg"}, {"title": "No more pesky learning rates", "topics": [0.017979710272679802, 0.017980772175342462, 0.91010230575408413, 0.017978958009994751, 0.017979319903560196, 0.017978933884338664], "pdf_url": "http://jmlr.org/proceedings/papers/v28/schaul13.pdf", "most_common": ["learning", "rate", "sgd", "loss", "rates", "gradient", "adaptive", "one", "parameter", "diagonal", "training", "method", "optimal", "hessian", "error", "algorithm", "stochastic", "neural", "parameters", "best", "lecun", "estimates", "table", "samples", "test", "hidden", "performance", "tuning", "using", "quadratic", "update", "global", "pesky", "curvature", "adagrad", "used", "case", "bottou", "almeida", "figure", "machine", "algorithms", "smd", "number", "note", "average", "local", "settings", "set", "problem", "variance", "vsgd", "expected", "value", "amari", "methods", "schedule", "two", "sample", "data", "formula", "small", "given", "need", "mnist", "optimum", "across", "terms", "online", "layer", "see", "supplementary", "network", "time", "layers", "large", "approximation", "reconstruction", "use", "compare", "natural", "better", "denoted", "function", "new", "approach", "changes", "scale", "automatically", "dataset", "approximate", "form", "distribution", "deep", "single", "benchmark", "results", "norm", "every", "updates"], "authors": ["Tom Schaul", "Sixin Zhang", "Yann LeCun"], "thumbnail_path": "thumbnails/No more pesky learning rates.jpg"}, {"title": "Making a Science of Model Search Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures", "topics": [0.01766917120605381, 0.017669148865479149, 0.91165438620087247, 0.017669173017819, 0.017668988368985741, 0.017669132340789817], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/bergstra13.pdf", "most_common": ["search", "model", "optimization", "random", "hyperparameter", "tpe", "algorithm", "pinto", "bergstra", "approach", "cox", "used", "vision", "data", "performance", "work", "best", "image", "hyperparameters", "set", "within", "making", "algorithms", "found", "space", "computer", "models", "science", "feature", "many", "learning", "loss", "images", "recognition", "trials", "svm", "test", "machine", "lfw", "features", "one", "class", "components", "function", "pooling", "two", "figure", "null", "error", "parameters", "view", "bayesian", "value", "coates", "spatial", "results", "parameter", "bank", "training", "language", "object", "experiments", "automatic", "lnorm", "expression", "choose", "task", "using", "tuning", "validation", "include", "values", "research", "given", "system", "face", "fbncc", "new", "distribution", "thousand", "neural", "hutter", "carried", "choice", "uniform", "particular", "history", "dihist", "better", "settings", "gaussian", "operation", "approaches", "typically", "distributed", "local", "prior", "patch", "three", "applied"], "authors": ["James Bergstra", "Daniel Yamins", "David Cox"], "thumbnail_path": "thumbnails/Making a Science of Model Search Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures.jpg"}, {"title": "Learning Heteroscedastic Models by Convex Programming under Group Sparsity", "topics": [0.015500802271851877, 0.015500668944827418, 0.92249537206265853, 0.015500951725950384, 0.015501335630902852, 0.015500869363808827], "pdf_url": "http://jmlr.org/proceedings/papers/v28/dalalyan13.pdf", "most_common": ["scheds", "group", "convex", "one", "lasso", "sparsity", "noise", "functions", "vector", "heteroscedastic", "assumption", "estimation", "procedure", "regression", "linear", "variance", "conditional", "function", "mean", "methods", "log", "programming", "learning", "model", "dantzig", "problem", "risk", "let", "theoretical", "estimating", "set", "theorem", "sparse", "models", "matrix", "case", "time", "large", "method", "scaled", "two", "selector", "new", "tuning", "optimization", "level", "constraints", "may", "result", "well", "also", "estimator", "bounded", "results", "covariates", "zhang", "prediction", "temperatures", "standard", "values", "data", "order", "used", "unknown", "optimal", "point", "proposed", "bounds", "constant", "paris", "every", "even", "use", "additive", "assumptions", "parameter", "propose", "gaussian", "since", "card", "number", "given", "std", "ofo", "interior", "sun", "based", "means", "joint", "terms", "bias", "dimensional", "denote", "ave", "temperature", "using", "condition", "diag", "obtained", "parameters"], "authors": ["Arnak Dalalyan", "Mohamed Hebiri", "Katia Meziani", "Joseph Salmon"], "thumbnail_path": "thumbnails/Learning Heteroscedastic Models by Convex Programming under Group Sparsity.jpg"}, {"title": "Noisy Sparse Subspace Clustering", "topics": [0.019663759901216937, 0.019663264959458568, 0.90167372001544877, 0.01966735457752402, 0.019668284299843249, 0.019663616246508482], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wang13.pdf", "most_common": ["subspace", "noise", "clustering", "data", "noisy", "ssc", "random", "theorem", "analysis", "subspaces", "sparse", "log", "figure", "property", "matrix", "dual", "model", "problem", "min", "vidal", "detection", "soltanolkotabi", "lasso", "results", "solution", "ieee", "rank", "candes", "remark", "max", "points", "geometric", "let", "inradius", "deterministic", "proof", "magnitude", "lemma", "samples", "range", "algorithm", "even", "guarantee", "number", "relviolation", "dimension", "convex", "bound", "robustness", "requires", "two", "recovery", "machine", "motion", "spectral", "columns", "set", "sep", "see", "point", "margin", "incoherence", "elhamifar", "constant", "case", "projection", "transactions", "holds", "exact", "furthermore", "conditions", "error", "singapore", "robust", "supplementary", "practical", "also", "denote", "uniformly", "consider", "condition", "noiseless", "vector", "version", "increasing", "method", "segmentation", "theoretical", "following", "paper", "perfect", "optimal", "fully", "gaussian", "projected", "note", "face", "trivial", "intelligence", "drawn"], "authors": ["Yu-Xiang Wang", "Huan Xu"], "thumbnail_path": "thumbnails/Noisy Sparse Subspace Clustering.jpg"}, {"title": "OneBit Compressed Sensing Provable Support and Vector Recovery", "topics": [0.022332527622868206, 0.022332499748771484, 0.8883363467159846, 0.022333206894823966, 0.022332682126131067, 0.022332736891420575], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gopi13.pdf", "most_common": ["algorithm", "recovery", "support", "log", "using", "sensing", "measurements", "matrix", "measurement", "vector", "compressed", "sign", "recover", "problem", "theorem", "approximate", "uff", "number", "based", "set", "methods", "section", "probability", "note", "plan", "see", "signal", "sparse", "baraniuk", "vershynin", "given", "design", "provable", "algorithms", "also", "compressive", "method", "error", "universal", "existing", "let", "following", "twostage", "supplementary", "sets", "expanders", "results", "matrices", "provide", "material", "denotes", "linear", "standard", "however", "present", "several", "robust", "signals", "output", "two", "supp", "time", "solution", "figure", "complexity", "ieee", "expander", "yes", "input", "constructed", "elements", "large", "vectors", "family", "high", "end", "free", "random", "approach", "union", "well", "underlying", "stage", "next", "parameters", "use", "haupt", "known", "tao", "information", "better", "optimal", "used", "transactions", "richard", "laska", "learning", "larger", "propose", "varying"], "authors": ["Sivakant Gopi", "Praneeth Netrapalli", "Prateek Jain", "Aditya Nori"], "thumbnail_path": "thumbnails/OneBit Compressed Sensing Provable Support and Vector Recovery.jpg"}, {"title": "Smooth Sparse Coding via Marginal Regression for Learning Sparse Representations", "topics": [0.021793528313103876, 0.021793401148484853, 0.89103190316404035, 0.02179366722372162, 0.02179402585729983, 0.021793474293349602], "pdf_url": "http://jmlr.org/proceedings/papers/v28/balasubramanian13.pdf", "most_common": ["sparse", "coding", "dictionary", "smooth", "regression", "learning", "marginal", "data", "using", "standard", "kernel", "approach", "based", "set", "proposed", "step", "codes", "method", "lasso", "error", "sample", "feature", "used", "function", "representations", "accuracy", "local", "theorem", "reconstruction", "update", "algorithm", "similarity", "use", "image", "problem", "one", "see", "corresponds", "samples", "table", "space", "experiments", "optimization", "convergence", "time", "norm", "two", "following", "example", "complexity", "propose", "gradient", "could", "features", "alternative", "recognition", "smoothing", "bounds", "results", "statistical", "matrix", "size", "also", "advantage", "projection", "information", "may", "temporal", "might", "training", "generalization", "min", "respect", "corresponding", "several", "leads", "better", "main", "framework", "term", "related", "given", "rates", "distance", "note", "class", "traditional", "speedup", "covering", "score", "previous", "procedure", "descent", "obtain", "bandwidth", "comparison", "videos", "functions", "test", "vector"], "authors": ["Krishnakumar Balasubramanian", "Kai Yu", "Guy Lebanon"], "thumbnail_path": "thumbnails/Smooth Sparse Coding via Marginal Regression for Learning Sparse Representations.jpg"}, {"title": "Sparse projections onto the simplex", "topics": [0.01745564506633002, 0.017455656255242941, 0.91266923901387953, 0.017457085178459054, 0.017506359214915362, 0.017456015271172989], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kyrillidis13.pdf", "most_common": ["approach", "problem", "convex", "algorithm", "sparse", "onto", "solution", "let", "simplex", "true", "since", "projections", "estimated", "rank", "kernel", "measurements", "projection", "figure", "given", "pdf", "means", "matrix", "portfolio", "set", "quantum", "number", "also", "learning", "tomography", "constraints", "density", "support", "vector", "via", "use", "following", "hence", "relative", "using", "constraint", "index", "projector", "recovery", "one", "gradient", "approaches", "solutions", "case", "loss", "parzen", "sparsity", "argmin", "assume", "results", "cardinality", "result", "based", "liu", "euclidean", "optimization", "error", "rip", "function", "supp", "time", "approximation", "proof", "sample", "element", "gaussian", "shows", "greedy", "probability", "gssp", "trace", "estimation", "thus", "minimize", "nonconvex", "obtain", "guarantees", "quadratic", "cevher", "kyrillidis", "consider", "norm", "even", "hyperplane", "order", "eigenvalue", "operator", "restricted", "note", "random", "gshp", "knowledge", "experiments", "argmax", "avg", "descent"], "authors": ["Anastasios Kyrillidis", "Stephen Becker", "Volkan Cevher", "Christoph Koch"], "thumbnail_path": "thumbnails/Sparse projections onto the simplex.jpg"}, {"title": "Intersecting singularities for multistructured estimation", "topics": [0.01621851087307646, 0.016218369384834615, 0.91890566251924866, 0.016218780794598823, 0.016219338204748378, 0.016219338223493061], "pdf_url": "http://jmlr.org/proceedings/papers/v28/richard13.pdf", "most_common": ["norm", "rank", "sparse", "trace", "matrix", "estimation", "convex", "matrices", "singularities", "using", "penalty", "linear", "ranksity", "case", "noise", "vec", "two", "intersecting", "regularizers", "span", "log", "optimization", "block", "problem", "algorithm", "following", "new", "function", "index", "singular", "lifting", "algorithms", "supp", "consider", "lifted", "one", "given", "point", "dimension", "orthogonal", "penalties", "chandrasekaran", "penalized", "cases", "min", "points", "set", "see", "value", "learning", "regularizer", "dense", "values", "diag", "component", "objects", "theoretical", "space", "robust", "normal", "sum", "instance", "operator", "results", "level", "respectively", "compressed", "subgradient", "nonsmooth", "least", "observation", "norms", "subspaces", "experiments", "cone", "used", "analysis", "sensing", "sparsity", "inf", "entries", "dim", "unit", "use", "call", "information", "vandergheynst", "machine", "estimating", "structural", "denotes", "onto", "multiple", "bound", "state", "written", "tuning", "numerical", "intersection", "bach"], "authors": ["Emile Richard", "Francis BACH", "Jean-Philippe Vert"], "thumbnail_path": "thumbnails/Intersecting singularities for multistructured estimation.jpg"}, {"title": "Sparse Uncorrelated Linear Discriminant Analysis", "topics": [0.022941073942568467, 0.022932920452075376, 0.88532215585099361, 0.022934252304948138, 0.022936448024431271, 0.022933149424983323], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/zhang13.pdf", "most_common": ["sparse", "data", "lda", "discriminant", "solution", "sulda", "ulda", "class", "problem", "analysis", "linear", "uncorrelated", "optimization", "trace", "solutions", "slda", "orthogonal", "transformation", "minimum", "matrix", "generalized", "plda", "dimension", "sparsity", "rank", "bregman", "results", "number", "space", "scatter", "optimal", "linearized", "features", "extracted", "column", "algorithm", "accelerated", "algorithms", "yin", "journal", "let", "two", "tibshirani", "computed", "characterization", "theorem", "classical", "matrices", "vector", "gene", "statistical", "based", "method", "arg", "using", "section", "selected", "chu", "applications", "machine", "denotes", "training", "table", "accuracy", "set", "learning", "mutually", "compute", "implies", "cai", "max", "solving", "fukunaga", "one", "paper", "satisfying", "however", "huang", "many", "experimental", "thus", "reduced", "hastie", "srbct", "existing", "solved", "international", "test", "following", "feature", "experiments", "jin", "since", "projected", "directly", "classes", "null", "min", "also", "penalty"], "authors": ["Xiaowei Zhang", "Delin Chu"], "thumbnail_path": "thumbnails/Sparse Uncorrelated Linear Discriminant Analysis.jpg"}, {"title": "Estimating Unknown Sparsity in Compressed Sensing", "topics": [0.016262758598945271, 0.016262057333041337, 0.91868859563797722, 0.01626230734015971, 0.016262022313036112, 0.016262258776840205], "pdf_url": "http://jmlr.org/proceedings/papers/v28/lopes13.pdf", "most_common": ["sparsity", "measurements", "estimating", "estimate", "error", "rank", "section", "matrix", "unknown", "recovery", "problem", "value", "parameter", "relative", "signal", "stable", "compressed", "ieee", "also", "vectors", "sensing", "theorem", "bound", "log", "number", "random", "set", "measurement", "theory", "choice", "procedure", "deterministic", "small", "reconstruction", "order", "since", "show", "estimation", "noise", "gaussian", "case", "coordinate", "using", "sparse", "measure", "matrices", "level", "large", "vector", "based", "known", "figure", "transactions", "coordinates", "note", "distribution", "linear", "let", "parameters", "high", "values", "assumptions", "given", "one", "result", "many", "well", "dimension", "left", "signals", "estimator", "function", "depend", "standard", "two", "theoretical", "information", "may", "shows", "computed", "property", "used", "sets", "right", "scale", "additional", "true", "journal", "important", "assume", "interval", "results", "entries", "approximation", "estimated", "following", "obtained", "plotted", "use", "cauchy"], "authors": ["Miles Lopes"], "thumbnail_path": "thumbnails/Estimating Unknown Sparsity in Compressed Sensing.jpg"}, {"title": "Concurrent Reinforcement Learning from Customer Interaction Sequences", "topics": [0.023314138278230329, 0.023273784431949478, 0.88302105664389041, 0.023842956514348101, 0.023274836662074333, 0.023273227469507211], "pdf_url": "http://jmlr.org/proceedings/papers/v28/silver13.pdf", "most_common": ["customer", "learning", "concurrent", "reinforcement", "interaction", "customers", "interactions", "algorithm", "online", "actions", "time", "updates", "function", "real", "example", "concurrency", "company", "may", "algorithms", "action", "variables", "null", "bandit", "decision", "contextual", "decisions", "one", "email", "given", "sutton", "however", "many", "sequences", "policy", "using", "learn", "history", "data", "response", "observations", "rewards", "applied", "batch", "value", "update", "environment", "sequential", "performance", "interacting", "reward", "sequence", "scenarios", "agent", "work", "occur", "parallel", "internet", "also", "measured", "simulator", "setting", "abe", "prior", "two", "optimal", "event", "note", "pages", "distributed", "conference", "partial", "large", "new", "figure", "high", "times", "framework", "typically", "international", "subsequent", "requests", "used", "levels", "opportunity", "problem", "single", "compared", "requested", "options", "total", "therefore", "feature", "might", "number", "immediate", "observation", "request", "histories", "state", "approach"], "authors": ["David Silver", "Leonard Newnham", "David Barker", "Suzanne Weller", "Jason McFall"], "thumbnail_path": "thumbnails/Concurrent Reinforcement Learning from Customer Interaction Sequences.jpg"}, {"title": "Modelling Sparse Dynamical Systems with Compressed Predictive State Representations", "topics": [0.017729687351502595, 0.017729713133205791, 0.91135104119118593, 0.017729967016131307, 0.017729847128322571, 0.017729744179651813], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/hamilton13.pdf", "most_common": ["cpsr", "algorithm", "tests", "compressed", "learning", "systems", "observation", "model", "error", "tpsr", "large", "prediction", "set", "matrices", "used", "matrix", "state", "dynamical", "models", "space", "probability", "one", "also", "observable", "using", "boots", "projection", "vector", "random", "sparse", "domain", "number", "history", "algorithms", "histories", "thus", "dimension", "psr", "empirical", "domains", "predictive", "however", "results", "estimates", "would", "sample", "observations", "bound", "modelling", "possible", "mol", "psrs", "spectral", "method", "work", "representation", "compression", "gordon", "regression", "analysis", "partially", "use", "probabilities", "distribution", "figure", "information", "representations", "size", "able", "pocman", "variance", "theorem", "present", "test", "assume", "include", "learned", "therefore", "reduce", "since", "linear", "target", "projections", "approach", "estimation", "col", "sparsity", "veness", "column", "case", "let", "parameters", "particular", "feature", "shows", "length", "maillard", "singh", "spaces", "many"], "authors": ["William Hamilton", "Mahdi Milani Fard,", "Joelle Pineau,"], "thumbnail_path": "thumbnails/Modelling Sparse Dynamical Systems with Compressed Predictive State Representations.jpg"}, {"title": "CocoQ Learning in Stochastic Games with Side Payments", "topics": [0.020110421335960825, 0.02011053250761885, 0.89944717080313674, 0.020110751133012167, 0.0201105846848522, 0.020110539535419147], "pdf_url": "http://jmlr.org/proceedings/papers/v28/sodomka13.pdf", "most_common": ["coco", "values", "game", "games", "goal", "figure", "side", "learning", "stochastic", "value", "agents", "trajectory", "grid", "payments", "step", "two", "agent", "ego", "move", "minmax", "one", "operator", "players", "kalai", "left", "maxmax", "nash", "policy", "probability", "friend", "reach", "set", "shared", "solution", "possible", "time", "alter", "joint", "goals", "littman", "action", "proceedings", "player", "would", "machine", "square", "shown", "conference", "reward", "algorithm", "play", "equilibrium", "actions", "expected", "also", "turkey", "convergence", "moves", "incredible", "foe", "michael", "sum", "international", "since", "converges", "converge", "state", "unique", "right", "moving", "pays", "transfer", "concept", "team", "policies", "total", "use", "operators", "example", "states", "greenwald", "shows", "illustrate", "note", "without", "payment", "solutions", "symmetric", "however", "second", "corresponding", "prisoner", "made", "sticks", "functions", "correlated", "stick", "markov", "equation", "following"], "authors": ["Elizabeth Hilliard", "Eric Sodomka", "Michael Littman", "Amy Greenwald"], "thumbnail_path": "thumbnails/CocoQ Learning in Stochastic Games with Side Payments.jpg"}, {"title": "Guided Policy Search", "topics": [0.020892743590595109, 0.020891775200015762, 0.8955394916368794, 0.020891907588537963, 0.020891797507827221, 0.020892284476144555], "pdf_url": "http://jmlr.org/proceedings/papers/v28/levine13.pdf", "most_common": ["policy", "samples", "guiding", "ddp", "search", "learning", "initial", "methods", "used", "tbdp", "gps", "policies", "also", "reward", "guided", "method", "use", "trajectory", "using", "distributions", "prior", "importance", "distribution", "optimization", "neural", "example", "new", "gradient", "test", "sample", "algorithm", "current", "learn", "optimal", "systems", "international", "conference", "figure", "since", "sampling", "rollouts", "learned", "work", "adaptive", "variant", "local", "line", "states", "abbeel", "good", "mean", "gaussian", "iteration", "show", "complex", "actions", "previous", "humanoid", "examples", "log", "making", "high", "hidden", "shown", "could", "walking", "set", "often", "estimator", "dynamic", "stochastic", "section", "approach", "regions", "one", "given", "exp", "state", "tang", "well", "peters", "low", "reinforcement", "single", "walker", "suitable", "machine", "return", "term", "found", "trajectories", "standard", "training", "require", "hopper", "schaal", "best", "units", "terrains", "sampled"], "authors": ["Sergey Levine", "Vladlen Koltun"], "thumbnail_path": "thumbnails/Guided Policy Search.jpg"}, {"title": "The CrossEntropy Method Optimizes for Quantiles", "topics": [0.015819962577450702, 0.01582104252295834, 0.92088590215217836, 0.015820181774267469, 0.015832895500641972, 0.015820015472503342], "pdf_url": "http://jmlr.org/proceedings/papers/v28/goschin13.pdf", "most_common": ["proportional", "distribution", "policy", "algorithm", "value", "method", "mce", "quantile", "quantiles", "convergence", "values", "optimization", "generation", "optimizes", "set", "algorithms", "results", "two", "expected", "reward", "one", "policies", "input", "noise", "distributions", "setting", "parameters", "optimal", "standard", "szita", "rubinstein", "search", "inputs", "evaluations", "space", "rho", "solutions", "game", "tetris", "function", "number", "experiment", "mannor", "samples", "noisy", "particular", "according", "learning", "initial", "maximum", "properties", "control", "stock", "profile", "goal", "paper", "also", "performance", "case", "problem", "empirical", "thus", "bernoulli", "used", "blackjack", "using", "goschin", "stochastic", "section", "version", "example", "machine", "operations", "kroese", "reasonable", "research", "stage", "population", "determined", "ran", "show", "experiments", "state", "various", "simple", "inventory", "well", "repeated", "time", "second", "even", "theoretical", "parameter", "variant", "executed", "weight", "ordering", "selection", "phenomenon", "converge"], "authors": ["Sergiu Goschin", "Ari Weinstein", "Michael Littman"], "thumbnail_path": "thumbnails/The CrossEntropy Method Optimizes for Quantiles.jpg"}, {"title": "A Practical Algorithm for Topic Modeling with Provable Guarantees", "topics": [0.018643229663945278, 0.018643407624142287, 0.90678306307677592, 0.018643516403954404, 0.018643449462347129, 0.018643333768834938], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/arora13.pdf", "most_common": ["algorithm", "topic", "anchor", "matrix", "algorithms", "documents", "words", "topics", "recover", "error", "word", "model", "arora", "gibbs", "data", "recovery", "points", "set", "rows", "provable", "using", "use", "recoverkl", "models", "results", "given", "vertices", "new", "modeling", "document", "guarantees", "distributions", "nips", "linear", "sampling", "step", "synthetic", "parameters", "corpora", "practical", "found", "number", "blei", "point", "learning", "hull", "time", "dirichlet", "times", "corpus", "close", "distribution", "coherence", "convex", "shown", "running", "probability", "zzz", "simplex", "whose", "even", "mccallum", "two", "work", "one", "performance", "selection", "many", "present", "sample", "david", "mcmc", "likelihood", "separability", "show", "based", "mimno", "empirical", "zero", "used", "analysis", "solve", "lda", "supplementary", "log", "generated", "large", "learned", "method", "let", "latent", "least", "also", "three", "procedure", "input", "real", "span", "vertex", "row"], "authors": ["Sanjeev Arora", "Rong Ge", "Yonatan Halpern", "David Mimno", "Ankur Moitra", "David Sontag", "Yichen Wu", "Michael Zhu"], "thumbnail_path": "thumbnails/A Practical Algorithm for Topic Modeling with Provable Guarantees.jpg"}, {"title": "Online Latent Dirichlet Allocation with Infinite Vocabulary", "topics": [0.019842505113795303, 0.019842793945213127, 0.90078704933478648, 0.019842462143589409, 0.019842673864012794, 0.019842515598602894], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhai13.pdf", "most_common": ["topic", "words", "distribution", "models", "model", "online", "vocabulary", "infvoc", "dirichlet", "variational", "blei", "inference", "word", "topics", "minibatch", "latent", "pmi", "truncation", "process", "better", "tos", "settings", "section", "documents", "parameters", "use", "distributions", "algorithms", "set", "bayesian", "allocation", "figure", "parameter", "base", "david", "score", "wang", "nonparametric", "new", "however", "learning", "coherence", "lda", "scale", "newsgroups", "reordering", "probability", "dtm", "two", "delay", "used", "language", "jordan", "approach", "modeling", "document", "streaming", "minibatches", "algorithm", "consider", "large", "zdn", "rank", "vocabularies", "later", "capture", "higher", "uses", "possible", "dynamic", "stochastic", "index", "instead", "size", "corpus", "accuracy", "values", "mimno", "batch", "underlying", "within", "conditional", "hybrid", "strings", "level", "multinomial", "based", "approaches", "contains", "must", "information", "hierarchical", "data", "allow", "choose", "reasonable", "log", "training", "length", "number"], "authors": ["KE ZHAI", "Jordan Boyd-Graber"], "thumbnail_path": "thumbnails/Online Latent Dirichlet Allocation with Infinite Vocabulary.jpg"}, {"title": "Gibbs MaxMargin Topic Models with Fast Sampling Algorithms", "topics": [0.01739992432811013, 0.017399757374038375, 0.91299969430783179, 0.017400825879351038, 0.017399822644034162, 0.017399975466634625], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/zhu13.pdf", "most_common": ["gibbs", "topic", "medlda", "distribution", "data", "posterior", "expected", "sampling", "training", "max", "gibbsmedlda", "model", "time", "set", "loss", "models", "exp", "using", "learning", "algorithms", "problem", "binary", "topics", "accuracy", "zhu", "prediction", "supervised", "performance", "margin", "regression", "vmedlda", "solve", "lda", "svm", "methods", "fast", "variational", "collapsed", "min", "also", "latent", "see", "inference", "term", "multiple", "lemma", "testing", "augmentation", "results", "sample", "machine", "gaussian", "zdn", "standard", "one", "given", "seconds", "draw", "existing", "large", "prior", "research", "figure", "assumptions", "shows", "estimate", "variables", "number", "need", "words", "experiments", "bayesian", "document", "uses", "hinge", "conditional", "inverse", "assignments", "vector", "upper", "word", "reviews", "learn", "numbers", "information", "response", "jiang", "since", "likelihood", "dirichlet", "maximum", "restricting", "due", "new", "used", "without", "scale", "journal", "distributions", "log"], "authors": ["Jun Zhu", "Ning Chen", "Hugh Perkins", "Bo Zhang"], "thumbnail_path": "thumbnails/Gibbs MaxMargin Topic Models with Fast Sampling Algorithms.jpg"}, {"title": "Modeling Musical Influence with Topic Models", "topics": [0.024752322571719856, 0.024752061194911832, 0.76314326342125904, 0.024757924763806397, 0.024750974201944054, 0.13784345384635871], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/shalit13.pdf", "most_common": ["songs", "topic", "model", "musical", "rock", "song", "music", "jazz", "innovation", "artists", "models", "modeling", "using", "dataset", "metal", "time", "blei", "blues", "artist", "audio", "features", "classic", "later", "scores", "use", "hop", "ranked", "one", "hip", "international", "proceedings", "pop", "genres", "folk", "information", "years", "topics", "genre", "epoch", "used", "figure", "data", "gerrish", "measure", "median", "conference", "epochs", "popular", "year", "structure", "two", "spearman", "score", "several", "found", "dim", "indie", "earlier", "innovative", "number", "mean", "content", "electronic", "overall", "evolution", "retrieval", "approach", "many", "learning", "baseline", "early", "distribution", "acoustic", "since", "rap", "considered", "across", "described", "much", "funk", "study", "ismir", "tags", "known", "soul", "correlation", "research", "shows", "million", "language", "rank", "given", "top", "new", "available", "examples", "table", "single", "results", "include"], "authors": ["Uri Shalit", "Daphna Weinshall", "Gal Chechik"], "thumbnail_path": "thumbnails/Modeling Musical Influence with Topic Models.jpg"}, {"title": "Nested Chinese Restaurant Franchise Process Applications to User Tracking and Document Modeling", "topics": [0.016699662547443022, 0.016699302668232309, 0.91650000600169568, 0.016699265245842702, 0.016702202639106822, 0.016699560897679471], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ahmed13.pdf", "most_common": ["model", "process", "node", "hierarchical", "tree", "restaurant", "distribution", "chinese", "location", "user", "topics", "nested", "sampling", "structure", "topic", "language", "child", "global", "franchise", "table", "models", "new", "modeling", "document", "path", "words", "algorithm", "use", "sample", "probability", "regions", "dirichlet", "set", "using", "moreover", "data", "assume", "inference", "tweets", "hong", "documents", "two", "since", "given", "ncrf", "tweet", "exact", "root", "eisenstein", "content", "variables", "number", "microblogs", "ahmed", "users", "roj", "results", "nips", "hpam", "blei", "terms", "methods", "nodes", "regional", "dir", "teh", "usa", "figure", "hierarchy", "generative", "paths", "generating", "thus", "used", "ncrp", "object", "vertex", "dataset", "associated", "distributions", "test", "xoj", "method", "full", "represented", "want", "rather", "one", "need", "note", "best", "approach", "component", "however", "region", "obtain", "twitter", "zoj", "existing", "pachinko"], "authors": ["Amr Ahmed", "Liangjie Hong", "Alexander Smola"], "thumbnail_path": "thumbnails/Nested Chinese Restaurant Franchise Process Applications to User Tracking and Document Modeling.jpg"}, {"title": "Parallel Markov Chain Monte Carlo for Nonparametric Mixture Models", "topics": [0.016817910029661529, 0.016817885545173883, 0.91588262076478388, 0.016843830067926818, 0.016819816251627595, 0.016817937340826365], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/williamson13.pdf", "most_common": ["dirichlet", "data", "inference", "cluster", "process", "processor", "time", "parallel", "using", "models", "mixture", "hdp", "model", "number", "gibbs", "processors", "monte", "carlo", "nonparametric", "allocations", "distribution", "sampling", "auxiliary", "clusters", "one", "variational", "sampler", "methods", "points", "distributed", "local", "global", "markov", "avparallel", "random", "used", "approximate", "single", "algorithm", "chain", "teh", "described", "set", "conditional", "gamma", "variable", "algorithms", "synch", "independence", "given", "according", "steps", "existing", "method", "obtained", "figure", "probability", "observations", "measures", "xmi", "approach", "conditioned", "perform", "split", "perplexity", "implemented", "sequential", "introducing", "representation", "since", "quality", "performance", "eight", "point", "bayesian", "particle", "nips", "appropriate", "hierarchical", "resulting", "parameter", "four", "paper", "assignments", "smc", "concentration", "note", "based", "processes", "learning", "gap", "independent", "dpmm", "without", "obtain", "xing", "step", "true", "minutes", "independently"], "authors": ["Sinead Williamson", "Avinava Dubey", "Eric Xing"], "thumbnail_path": "thumbnails/Parallel Markov Chain Monte Carlo for Nonparametric Mixture Models.jpg"}, {"title": "MADBayes MAPbased Asymptotic Derivations from Bayes", "topics": [0.014920838479331958, 0.014921193647561332, 0.92537033988787687, 0.014945391308632483, 0.014921210178961843, 0.014921026497635523], "pdf_url": "http://jmlr.org/proceedings/papers/v28/broderick13.pdf", "most_common": ["feature", "data", "algorithm", "objective", "cluster", "number", "features", "clustering", "algorithms", "one", "row", "clusters", "means", "jordan", "map", "new", "learning", "bayesian", "random", "may", "function", "four", "ibp", "probability", "kulis", "problem", "gibbs", "model", "collapsed", "let", "gaussian", "point", "case", "prior", "process", "znk", "ghahramani", "index", "base", "values", "estimate", "given", "allocation", "using", "posterior", "consider", "via", "pictures", "run", "second", "nonparametric", "broderick", "mean", "matrix", "shows", "likelihood", "also", "set", "initializations", "asymptotics", "tabletop", "picture", "appear", "counts", "parameter", "note", "stepwise", "latent", "penalty", "local", "mixture", "crp", "faces", "optimization", "initialization", "obtain", "models", "choice", "customer", "optimal", "statistical", "framework", "since", "combinatorial", "nth", "log", "assign", "hyperparameter", "beta", "show", "text", "equal", "sampling", "sampler", "value", "assigned", "pitman", "form", "similar", "even"], "authors": ["Tamara Broderick", "Brian Kulis", "Michael Jordan"], "thumbnail_path": "thumbnails/MADBayes MAPbased Asymptotic Derivations from Bayes.jpg"}, {"title": "Topic Model Diagnostics Assessing Domain Relevance via Topical Alignment", "topics": [0.018346276526763235, 0.018346164371826033, 0.9082662558333563, 0.018348058748548716, 0.018346529024081591, 0.018346715495424219], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chuang13.pdf", "most_common": ["topic", "topical", "topics", "models", "concepts", "latent", "reference", "model", "measures", "figure", "junk", "lda", "using", "fused", "domain", "resolved", "matching", "similarity", "alignment", "scores", "concept", "values", "david", "human", "two", "matches", "number", "correspondence", "ramage", "word", "also", "dot", "set", "optimization", "rescaled", "via", "product", "hyperparameter", "blei", "assessing", "newman", "evaluation", "likelihood", "pairs", "probability", "score", "intrinsic", "stanford", "based", "information", "introduce", "framework", "one", "matrix", "chart", "diagnostics", "coherence", "relevance", "repeated", "research", "large", "work", "correlation", "misalignment", "modeling", "mccallum", "experts", "within", "provide", "parameter", "steyvers", "wallach", "likelihoods", "corpus", "considered", "text", "manning", "mimno", "observe", "user", "analysis", "match", "range", "examine", "results", "plda", "entries", "missing", "marked", "trained", "process", "axis", "may", "measure", "daniel", "diagnostic", "rank", "quality", "built", "random"], "authors": ["Jason Chuang", "Sonal Gupta", "Christopher Manning", "Jeffrey Heer"], "thumbnail_path": "thumbnails/Topic Model Diagnostics Assessing Domain Relevance via Topical Alignment.jpg"}, {"title": "On the importance of initialization and momentum in deep learning", "topics": [0.075302684049439503, 0.017117024745494754, 0.85622872543294992, 0.017116429057092306, 0.017117282182494808, 0.01711785453252852], "pdf_url": "http://jmlr.org/proceedings/papers/v28/sutskever13.pdf", "most_common": ["momentum", "learning", "nag", "deep", "methods", "neural", "results", "training", "martens", "gradient", "convergence", "networks", "optimization", "initialization", "use", "rate", "method", "problems", "used", "sutskever", "directions", "hinton", "random", "local", "see", "table", "performance", "using", "rnns", "stochastic", "along", "may", "error", "previous", "particular", "parameter", "found", "standard", "achieve", "update", "even", "type", "information", "initializations", "objective", "importance", "recurrent", "convex", "scale", "certain", "sgd", "thus", "train", "large", "also", "however", "many", "bengio", "problem", "tasks", "accelerated", "one", "phase", "velocity", "set", "descent", "units", "like", "experiments", "nesterov", "cient", "quadratic", "constant", "better", "curvature", "given", "coe", "much", "schedule", "appendix", "dynamics", "errors", "work", "values", "temporal", "across", "dnns", "larger", "make", "without", "seems", "classical", "models", "initialized", "reported", "allows", "hidden", "spectral", "proceedings", "achieved"], "authors": ["Ilya Sutskever", "James Martens", "George Dahl", "Geoffrey Hinton"], "thumbnail_path": "thumbnails/On the importance of initialization and momentum in deep learning.jpg"}, {"title": "A nonIID Framework for Collaborative Filtering with Restricted Boltzmann Machines", "topics": [0.019848266785381808, 0.019670201118762221, 0.90145730771459331, 0.019674266438161191, 0.019671389067346248, 0.019678568875755226], "pdf_url": "http://jmlr.org/proceedings/papers/v28/georgiev13.pdf", "most_common": ["model", "rbm", "visible", "ratings", "models", "hidden", "collaborative", "layer", "results", "two", "prediction", "rating", "also", "hybrid", "user", "multinomial", "items", "training", "using", "better", "framework", "units", "matrix", "users", "mae", "order", "quality", "given", "learning", "item", "boltzmann", "movielens", "machines", "proceedings", "values", "data", "one", "best", "yields", "datasets", "unit", "figure", "restricted", "sarwar", "salakhutdinov", "predictions", "original", "number", "filtering", "rbms", "algorithms", "used", "evaluation", "average", "correlations", "nodes", "truyen", "use", "performance", "based", "modeling", "value", "real", "standalone", "weights", "layers", "finally", "new", "trained", "weight", "shows", "could", "see", "however", "similar", "single", "compared", "latent", "opposed", "work", "information", "correlation", "features", "table", "latter", "joint", "set", "binary", "previous", "right", "usa", "generated", "wij", "related", "shown", "linear", "yum", "connected", "sum", "comparable"], "authors": ["Kostadin Georgiev", "Preslav Nakov"], "thumbnail_path": "thumbnails/A nonIID Framework for Collaborative Filtering with Restricted Boltzmann Machines.jpg"}, {"title": "Parsing epileptic events using a Markov switching process model for correlated time series", "topics": [0.018980579007116648, 0.018980114149589708, 0.9050489953900055, 0.018980146950810316, 0.019021335850846938, 0.01898882865163103], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wulsin13.pdf", "most_common": ["state", "channel", "event", "channels", "model", "time", "events", "series", "process", "seizure", "eeg", "markov", "epileptic", "sample", "ieeg", "clinical", "data", "transition", "using", "dynamics", "states", "parsing", "parameters", "innovations", "three", "fox", "correlated", "seizures", "modeling", "structure", "supplement", "feature", "switching", "dynamic", "bursts", "set", "electrode", "prior", "one", "conditional", "chains", "sampling", "number", "analysis", "similar", "graph", "innovation", "multivariate", "via", "given", "jordan", "sequences", "conference", "graphical", "heldout", "two", "also", "sparse", "models", "denotes", "vector", "onset", "end", "nonparametric", "mcmc", "observations", "beta", "proceedings", "correlations", "individual", "learning", "covariance", "hmm", "bayesian", "middle", "capture", "sequence", "use", "statistics", "posterior", "spatial", "consider", "large", "work", "example", "machine", "factorial", "recordings", "features", "observation", "conditioned", "left", "dependency", "shared", "distributions", "important", "independently", "red", "independencies", "predictions"], "authors": ["Drausin Wulsin", "Emily Fox", "Brian Litt"], "thumbnail_path": "thumbnails/Parsing epileptic events using a Markov switching process model for correlated time series.jpg"}, {"title": "Exploring the Mind Integrating Questionnaires and fMRI", "topics": [0.015008734819417764, 0.015009305926439483, 0.92495411434671426, 0.015009565776283679, 0.015009286649287912, 0.015008992481856817], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/salazar13.pdf", "most_common": ["model", "data", "matrix", "sparse", "binary", "fmri", "real", "questions", "questionnaires", "text", "topic", "amygdala", "distribution", "associated", "graphical", "prior", "latent", "models", "learned", "ordered", "proposed", "precision", "consider", "use", "figure", "categorical", "people", "features", "analysis", "also", "questionnaire", "answers", "via", "panel", "section", "probit", "integrating", "joint", "stimuli", "using", "two", "related", "exploring", "topics", "mind", "reactivity", "performance", "multiple", "considered", "network", "covariance", "within", "expressions", "construction", "vector", "based", "yij", "salazar", "factor", "modeling", "bayesian", "results", "groups", "predict", "brain", "yoshida", "average", "factorization", "responses", "west", "used", "question", "posterior", "four", "types", "relationships", "zero", "ibp", "parameters", "visual", "may", "response", "meeds", "representation", "shows", "connectivity", "given", "note", "measured", "learning", "employ", "modeled", "subjects", "yields", "algorithm", "structure", "finally", "updated", "every", "component"], "authors": ["Esther Salazar", "Ryan Bogdan", "Adam Gorka", "Ahmad Hariri", "Lawrence Carin"], "thumbnail_path": "thumbnails/Exploring the Mind Integrating Questionnaires and fMRI.jpg"}, {"title": "Gated Autoencoders with Tied Input Weights", "topics": [0.017610684901416436, 0.017608369479395543, 0.91195363995590839, 0.01760896050237986, 0.017608577888401974, 0.017609767272497766], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/alain13.pdf", "most_common": ["factor", "units", "network", "mapping", "layer", "images", "gated", "learning", "transformations", "cga", "rotations", "autoencoders", "matrix", "transformation", "angle", "input", "rotation", "memisevic", "one", "weights", "reconstruction", "error", "activation", "since", "given", "complex", "size", "two", "values", "representation", "pairs", "case", "image", "set", "see", "algorithm", "degree", "use", "projections", "real", "tied", "mathematical", "represent", "learned", "product", "number", "orthogonal", "hinton", "training", "particular", "pixels", "eigenvalues", "figure", "better", "also", "networks", "mean", "cross", "classical", "inner", "work", "numbers", "corresponding", "neural", "quadrature", "matrices", "section", "algorithms", "diagonal", "detection", "fact", "eigenvectors", "would", "parameters", "action", "unit", "multiplication", "representations", "weight", "spectrum", "performance", "proceedings", "thus", "approach", "however", "fny", "fnx", "cosine", "used", "less", "compared", "like", "recognition", "imaginary", "comparison", "deep", "commuting", "whereas", "test", "layers"], "authors": ["Alain Droniou", "Olivier Sigaud"], "thumbnail_path": "thumbnails/Gated Autoencoders with Tied Input Weights.jpg"}, {"title": "Simple Sparsification Improves Sparse Denoising Autoencoders in Denoising Highly Corrupted Images", "topics": [0.02078535894445243, 0.020783211720461343, 0.89607742274446978, 0.020783286770047954, 0.020784600311835426, 0.020786119508733224], "pdf_url": "http://jmlr.org/proceedings/papers/v28/cho13.pdf", "most_common": ["image", "denoising", "dae", "simple", "sparse", "noise", "latent", "hidden", "sparsity", "spdae", "encoder", "trained", "proposed", "sample", "error", "images", "reconstruction", "decoder", "representation", "test", "autoencoders", "performance", "patches", "given", "see", "noisy", "level", "improves", "denoised", "set", "using", "deep", "corrupted", "one", "coding", "white", "average", "case", "used", "spdaes", "model", "data", "gaussian", "learning", "units", "without", "function", "layers", "obtained", "two", "activation", "daes", "patch", "layer", "neural", "samples", "use", "small", "space", "training", "number", "xie", "target", "explicitly", "instance", "regularizer", "also", "applied", "burger", "component", "maps", "representations", "explicit", "clean", "approach", "however", "improvement", "input", "larger", "discriminative", "type", "following", "regularization", "found", "especially", "models", "code", "shrinkage", "large", "conventional", "additive", "cho", "information", "max", "ieee", "approaches", "levels", "nonlinearity", "pixels", "autoencoder"], "authors": ["Kyunghyun Cho"], "thumbnail_path": "thumbnails/Simple Sparsification Improves Sparse Denoising Autoencoders in Denoising Highly Corrupted Images.jpg"}, {"title": "Natural Image Bases to Represent Neuroimaging Data", "topics": [0.021380476135386316, 0.021379390451851187, 0.8930863358333393, 0.021385725136078136, 0.021387228140001859, 0.021380844303343048], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gupta13b.pdf", "most_common": ["mri", "bases", "data", "natural", "image", "feature", "using", "figure", "used", "set", "neuroimaging", "mci", "images", "brain", "shows", "disease", "represent", "pooling", "features", "performance", "learning", "learned", "visual", "basis", "early", "table", "representation", "approach", "adni", "patches", "activations", "method", "learn", "neural", "dementia", "parameters", "however", "analysis", "sparse", "algorithm", "results", "matsuda", "two", "convolutional", "sigmoid", "structural", "autoencoder", "imabayashi", "slice", "inspection", "information", "lesions", "binary", "lecun", "research", "accuracy", "sensitivity", "thus", "journal", "validation", "activation", "convolution", "stereotactic", "diagnostic", "kloppel", "clinical", "scans", "sae", "class", "yang", "ica", "median", "network", "various", "extraction", "layer", "surface", "normalization", "also", "input", "three", "test", "computerized", "progression", "teh", "autoencoders", "clinicians", "section", "search", "healthy", "scan", "hinton", "high", "work", "values", "following", "collection", "statistical", "university", "shown"], "authors": ["Ashish Gupta", "Murat Ayhan", "Anthony Maida"], "thumbnail_path": "thumbnails/Natural Image Bases to Represent Neuroimaging Data.jpg"}, {"title": "Direct Modeling of Complex Invariances for Visual Object Features", "topics": [0.017581139060091913, 0.017580797640153776, 0.912092683607726, 0.017580787200145206, 0.01758072533514737, 0.017583867156735895], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/yuhui13.pdf", "most_common": ["complex", "invariance", "learning", "dictionary", "feature", "would", "pooling", "features", "invariances", "object", "data", "modeling", "direct", "using", "visual", "training", "size", "image", "receptive", "view", "layer", "system", "set", "coates", "representation", "base", "accuracy", "results", "algorithm", "networks", "case", "amount", "labeled", "approach", "one", "result", "performance", "local", "patch", "simple", "table", "unsupervised", "deep", "rotation", "additional", "see", "transforms", "like", "output", "layers", "patches", "experiment", "method", "network", "coding", "knowledge", "sparse", "recognition", "similar", "activation", "full", "prior", "vik", "also", "best", "strategy", "neural", "per", "spatial", "large", "learn", "example", "dataset", "related", "directly", "zou", "class", "invariant", "recent", "competitive", "improvement", "works", "pooled", "appear", "highly", "use", "two", "convolutional", "give", "good", "beyond", "could", "encoding", "believe", "dtk", "say", "gains", "however", "much", "lecun"], "authors": ["Ka Yu Hui"], "thumbnail_path": "thumbnails/Direct Modeling of Complex Invariances for Visual Object Features.jpg"}, {"title": "Spectral Compressed Sensing via Structured Matrix Completion", "topics": [0.017437782902130598, 0.017437891969446898, 0.91281037037910473, 0.017438206955589185, 0.017437878253286774, 0.01743786954044152], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chen13g.pdf", "most_common": ["matrix", "hankel", "completion", "emac", "enhanced", "algorithm", "spectral", "sensing", "compressed", "via", "data", "frequency", "recovery", "incoherence", "structured", "matrices", "frequencies", "object", "model", "samples", "theorem", "form", "number", "one", "condition", "set", "signal", "candes", "entries", "theoretical", "observation", "problem", "ieee", "random", "conditions", "norm", "following", "based", "lemma", "observed", "sparse", "processing", "results", "small", "let", "information", "singular", "algorithms", "rank", "order", "value", "underlying", "noise", "denote", "obtained", "projection", "exact", "reconstruction", "harmonic", "suppose", "numerical", "possible", "minimization", "true", "time", "consider", "phase", "chi", "guarantee", "max", "imaging", "onto", "locations", "transactions", "section", "ground", "however", "sampling", "recht", "location", "sparsity", "super", "noisy", "gross", "models", "resolution", "partial", "stable", "rate", "method", "thresholding", "applications", "nonparametric", "denotes", "probability", "size", "given", "constant", "approach", "experiments"], "authors": ["Yuxin Chen", "Yuejie Chi"], "thumbnail_path": "thumbnails/Spectral Compressed Sensing via Structured Matrix Completion.jpg"}, {"title": "Sparse PCA through Lowrank Approximations", "topics": [0.016559544547353668, 0.016559587145843456, 0.91720154245838614, 0.016559697378605881, 0.01655977975392196, 0.016559848715888944], "pdf_url": "http://jmlr.org/proceedings/papers/v28/papailiopoulos13.pdf", "most_common": ["sparse", "algorithm", "pca", "data", "approximation", "principal", "set", "support", "matrix", "vector", "obtain", "component", "max", "largest", "vectors", "two", "zhang", "intersection", "optimal", "decay", "candidate", "sparsity", "spannogram", "case", "sets", "eigenvalue", "entries", "use", "one", "fullpath", "supports", "twitter", "eigenvector", "method", "approximations", "performance", "words", "step", "elimination", "tpower", "curves", "used", "analysis", "possible", "ghaoui", "unit", "main", "absolute", "fact", "eigenvectors", "using", "papailiopoulos", "constant", "elements", "international", "end", "machine", "experiments", "pcs", "exactly", "show", "covariance", "opt", "running", "power", "journal", "time", "moghaddam", "desired", "table", "greek", "ieee", "tweets", "matrices", "given", "scheme", "points", "google", "equal", "simply", "learning", "observe", "yuan", "guarantees", "output", "bound", "log", "problem", "test", "microsoft", "maximum", "greeceg", "solution", "indices", "eigenvalues", "love", "work", "compare", "information", "feature"], "authors": ["Dimitris Papailiopoulos", "Alexandros Dimakis", "Stavros Korokythakis"], "thumbnail_path": "thumbnails/Sparse PCA through Lowrank Approximations.jpg"}, {"title": "Efficient Sparse Group Feature Selection via Nonconvex Optimization", "topics": [0.033348017933007158, 0.01943023800963704, 0.88892758682762585, 0.019431229559230392, 0.019431281638368922, 0.019431646032130486], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/xiang13.pdf", "most_common": ["group", "selection", "sparse", "feature", "nonconvex", "method", "projection", "lasso", "convex", "algorithm", "optimization", "following", "methods", "groups", "solution", "optimal", "parameter", "via", "algorithms", "features", "results", "set", "huang", "proposed", "section", "data", "number", "oracle", "two", "statistical", "performance", "learning", "zhang", "max", "journal", "estimator", "admm", "constraints", "table", "however", "moreover", "model", "theorem", "constraint", "log", "function", "problem", "formulation", "parameters", "end", "gradient", "given", "also", "objective", "result", "approach", "tuning", "mcp", "shen", "step", "therefore", "accelerated", "breheny", "solving", "since", "bridge", "boyd", "based", "minimize", "nonzero", "global", "whose", "consistent", "selected", "composite", "hold", "values", "machine", "may", "minimizer", "paper", "programming", "assumption", "note", "bisection", "subject", "sglp", "due", "value", "return", "used", "less", "agm", "time", "computation", "high", "discussion", "theory", "accuracy", "addition"], "authors": ["Shuo Xiang", "Xiaotong Shen", "Jieping Ye"], "thumbnail_path": "thumbnails/Efficient Sparse Group Feature Selection via Nonconvex Optimization.jpg"}, {"title": "A General Iterative Shrinkage and Thresholding Algorithm for Nonconvex Regularized Optimization Problems", "topics": [0.018491931095132742, 0.018491845615274661, 0.90754027968567008, 0.018492104092693126, 0.018491736966313111, 0.018492102544916175], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/gong13a.pdf", "most_common": ["algorithm", "problem", "min", "line", "search", "function", "gist", "objective", "criterion", "arg", "iterative", "general", "value", "convex", "log", "shrinkage", "following", "thresholding", "sparse", "proposed", "sequence", "step", "convergence", "cpu", "time", "analysis", "problems", "zhang", "sign", "scaled", "max", "data", "size", "seconds", "monotone", "lemma", "optimization", "solve", "learning", "solution", "two", "proof", "used", "initialize", "iteration", "thus", "sets", "theorem", "journal", "via", "propose", "many", "point", "proximal", "using", "wright", "critical", "bounded", "commonly", "outer", "solving", "university", "assumption", "obtain", "operator", "limit", "gong", "rule", "scp", "monotonically", "penalties", "satisfy", "let", "assumptions", "algorithms", "paper", "class", "based", "tmin", "regularizers", "points", "solves", "hold", "machine", "applications", "ieee", "easily", "related", "regularizer", "experiments", "however", "table", "present", "also", "follows", "signal", "transactions", "considering", "processing", "computational"], "authors": ["Pinghua Gong", "Changshui Zhang", "Zhaosong Lu", "Jianhua Huang", "Jieping Ye"], "thumbnail_path": "thumbnails/A General Iterative Shrinkage and Thresholding Algorithm for Nonconvex Regularized Optimization Problems.jpg"}, {"title": "Robust Sparse Regression under Adversarial Corruption", "topics": [0.017765751307821157, 0.017762800294758629, 0.91117929367174533, 0.017765353830994032, 0.017763203677014741, 0.017763597217666006], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chen13h.pdf", "most_common": ["robust", "regression", "corruption", "algorithm", "corrupted", "support", "sparse", "lasso", "model", "recovery", "matrix", "number", "algorithms", "outliers", "one", "log", "consider", "even", "standard", "dantzig", "force", "convex", "brute", "entries", "rotr", "following", "show", "response", "selector", "performance", "many", "theorem", "noise", "inner", "high", "outlier", "linear", "also", "error", "guarantees", "adversarial", "setting", "least", "approach", "simple", "optimization", "note", "using", "rows", "covariates", "case", "results", "chen", "use", "ieee", "trimmed", "correct", "recover", "output", "design", "pursuit", "particular", "figure", "parameter", "might", "statistics", "covariate", "min", "distributed", "set", "well", "loss", "methods", "caramanis", "problem", "problems", "random", "second", "section", "approaches", "product", "natural", "may", "data", "observations", "transactions", "let", "handle", "fail", "tsybakov", "true", "models", "assume", "row", "errors", "two", "example", "thresholding", "gaussian", "parameters"], "authors": ["Yudong Chen", "Constantine Caramanis", "Shie Mannor"], "thumbnail_path": "thumbnails/Robust Sparse Regression under Adversarial Corruption.jpg"}, {"title": "ABC Reinforcement Learning", "topics": [0.018297269301437203, 0.018297383159689179, 0.9085095525756961, 0.018299556571685804, 0.018298018632292218, 0.018298219759199378], "pdf_url": "http://jmlr.org/proceedings/papers/v28/dimitrakakis13.pdf", "most_common": ["abc", "reinforcement", "learning", "policy", "bayesian", "approximate", "posterior", "model", "statistic", "environment", "value", "number", "good", "using", "prior", "may", "use", "however", "lspi", "inference", "sampling", "samples", "sampled", "simple", "utility", "parameters", "history", "data", "class", "pendulum", "used", "computation", "probability", "trajectories", "even", "optimal", "ntrj", "framework", "policies", "ndat", "problem", "algorithm", "markov", "sample", "better", "lagoudakis", "given", "simulators", "thompson", "set", "dimitrakakis", "approach", "rollouts", "general", "bertsekas", "theorem", "simulator", "decision", "additional", "time", "via", "goal", "parametrised", "since", "sequence", "distribution", "expected", "methods", "simulation", "function", "models", "problems", "finally", "case", "results", "two", "car", "statistical", "standard", "estimate", "need", "icml", "also", "fact", "well", "real", "statistics", "generated", "consider", "vlassis", "dynamic", "advantage", "strens", "approximation", "action", "proof", "would", "process", "particular", "poupart"], "authors": ["Christos Dimitrakakis", "Nikolaos Tziortziotis"], "thumbnail_path": "thumbnails/ABC Reinforcement Learning.jpg"}, {"title": "Mean Reversion with a Variance Threshold", "topics": [0.015810031414003438, 0.015809827154696473, 0.92094206919945498, 0.01581354171609143, 0.015812451508101868, 0.015812079007651705], "pdf_url": "http://jmlr.org/proceedings/papers/v28/cuturi13.pdf", "most_common": ["variance", "mean", "trading", "problem", "using", "reversion", "basket", "process", "baskets", "costs", "threshold", "time", "vector", "optimal", "portmanteau", "crossing", "given", "transaction", "series", "box", "minimize", "predictability", "solution", "figure", "solving", "sharpe", "techniques", "statistic", "section", "criteria", "matrix", "cointegration", "stationary", "assets", "order", "eigenvalue", "tiao", "subject", "show", "minimizing", "three", "two", "weights", "program", "multivariate", "unit", "asset", "one", "average", "ratio", "volatility", "contract", "johansen", "ols", "problems", "results", "def", "sample", "matrices", "yang", "solutions", "computed", "nemirovski", "convex", "relaxation", "strategy", "mathematical", "per", "noise", "form", "consider", "cost", "cents", "following", "jurek", "variables", "relaxations", "estimation", "thus", "analysis", "solve", "also", "arbitrage", "classical", "bound", "detailed", "variable", "reverting", "exact", "resulting", "programming", "write", "produce", "data", "paper", "since", "autoregressive", "hence", "generalized", "measures"], "authors": ["Marco Cuturi", "Alexandre dAspremont"], "thumbnail_path": "thumbnails/Mean Reversion with a Variance Threshold.jpg"}, {"title": "Gaussian Process Kernels for Pattern Discovery and Extrapolation", "topics": [0.016628974961151507, 0.016628818723100323, 0.91685366457970841, 0.016629336496436251, 0.016629869766943677, 0.016629335472659896], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wilson13.pdf", "most_common": ["kernel", "kernels", "gaussian", "data", "process", "spectral", "pattern", "function", "figure", "using", "training", "functions", "covariance", "used", "density", "squared", "rasmussen", "exponential", "patterns", "learned", "learning", "williams", "shown", "discovery", "predictive", "processes", "sinc", "stationary", "extrapolation", "mean", "popular", "peak", "mixture", "long", "machine", "correlation", "simple", "bayesian", "inference", "discover", "one", "performance", "neural", "components", "model", "airline", "periodic", "marginal", "red", "negative", "likelihood", "months", "passenger", "structure", "term", "extrapolate", "could", "points", "black", "densities", "human", "distribution", "covariances", "small", "trend", "hyperparameters", "features", "given", "exp", "however", "many", "mixtures", "rational", "large", "expressive", "section", "component", "frequency", "shows", "log", "also", "region", "proposed", "adams", "noise", "quadratic", "true", "models", "every", "positive", "gaussians", "standard", "number", "gps", "wilson", "class", "closed", "moreover", "empirical", "blue"], "authors": ["Andrew Wilson", "Ryan Adams"], "thumbnail_path": "thumbnails/Gaussian Process Kernels for Pattern Discovery and Extrapolation.jpg"}, {"title": "Average Reward Optimization Objective In Partially Observable Domains", "topics": [0.019247639035662935, 0.019247566812425957, 0.90376053176318172, 0.019247864007121598, 0.019247727908310069, 0.019248670473297674], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/grinberg13.pdf", "most_common": ["reward", "policy", "state", "linear", "average", "psr", "function", "stationary", "process", "prp", "system", "action", "let", "distribution", "systems", "representation", "predictive", "pomdp", "states", "observable", "behavior", "represented", "example", "one", "markov", "control", "framework", "probability", "partially", "psrs", "stochastic", "based", "domains", "following", "hidden", "optimization", "actions", "examples", "two", "represent", "search", "rational", "given", "result", "theorem", "vector", "objective", "fact", "learning", "without", "dimension", "using", "memory", "since", "induced", "number", "observations", "rewards", "planning", "parameters", "conference", "policies", "setting", "whose", "changes", "might", "evolution", "matrix", "future", "singh", "proceedings", "international", "sequences", "corresponding", "underlying", "properties", "consider", "particular", "figure", "mean", "hence", "also", "observation", "processes", "ergodic", "property", "well", "analysis", "model", "appropriate", "sequence", "called", "section", "jaeger", "respect", "obtained", "mao", "complexity", "james", "show"], "authors": ["Yuri Grinberg", "Doina Precup"], "thumbnail_path": "thumbnails/Average Reward Optimization Objective In Partially Observable Domains.jpg"}, {"title": "Planning by Prioritized Sweeping with Small Backups", "topics": [0.022153923088458, 0.022152844502696636, 0.8892344341919679, 0.022152937343754432, 0.022153017105236469, 0.022152843767886354], "pdf_url": "http://jmlr.org/proceedings/papers/v28/vanseijen13.pdf", "most_common": ["backup", "backups", "full", "small", "state", "time", "successor", "value", "planning", "model", "reversed", "per", "update", "usa", "one", "performance", "nsa", "cient", "method", "action", "learning", "using", "number", "states", "based", "methods", "sample", "prioritized", "optimal", "policy", "rsa", "psa", "step", "performs", "task", "reinforcement", "moore", "algorithm", "values", "used", "computation", "complexity", "computational", "mdps", "equation", "sweeping", "estimate", "pair", "reward", "function", "estimates", "second", "section", "initialize", "priority", "note", "demonstrate", "new", "since", "average", "predecessor", "case", "single", "queue", "memory", "following", "figure", "performed", "episodes", "transition", "version", "error", "equal", "atkeson", "results", "evaluation", "large", "current", "domains", "composite", "agent", "peng", "return", "introduce", "instead", "pairs", "times", "hence", "wiering", "williams", "observed", "cycles", "require", "expected", "decision", "use", "goal", "greedy", "top", "rewards"], "authors": ["Harm van Seijen", "Rich Sutton"], "thumbnail_path": "thumbnails/Planning by Prioritized Sweeping with Small Backups.jpg"}, {"title": "Dynamic Covariance Models for Multivariate Financial Time Series", "topics": [0.018675024686655613, 0.01867551999570603, 0.90523326950263971, 0.018700169661918585, 0.020040541227024731, 0.018675474926055331], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wu13.pdf", "most_common": ["bekk", "bmdc", "time", "model", "models", "predictive", "particle", "multivariate", "series", "dynamic", "covariance", "method", "data", "parameters", "performance", "inference", "likelihood", "number", "bayesian", "methods", "process", "parameter", "experiments", "mean", "gwp", "daily", "section", "returns", "average", "posterior", "aud", "standard", "used", "figure", "financial", "particles", "wishart", "generalized", "proposed", "regularized", "matrices", "cost", "table", "rapf", "dataset", "gaussian", "previous", "journal", "ghahramani", "market", "garch", "eur", "wilson", "equity", "case", "using", "step", "finally", "stochastic", "estimates", "prediction", "engle", "brl", "predictions", "values", "shows", "diagonal", "volatility", "statistical", "best", "however", "empirical", "jpy", "computational", "distribution", "auxiliary", "algorithm", "results", "novel", "large", "sequential", "shown", "training", "autoregressive", "times", "also", "set", "importance", "analyzed", "comparison", "datasets", "maximum", "shrinkage", "zero", "heteroscedastic", "changes", "plot", "given", "following", "performed"], "authors": ["Yue Wu", "Jose Miguel Hernandez-Lobato", "Ghahramani Zoubin"], "thumbnail_path": "thumbnails/Dynamic Covariance Models for Multivariate Financial Time Series.jpg"}, {"title": "Learning Sparse Penalties for Changepoint Detection using Max Margin Interval Regression", "topics": [0.019812151308545699, 0.019812087919897171, 0.90090764450113692, 0.01981247921523023, 0.01981189360475652, 0.019843743450433313], "pdf_url": "http://jmlr.org/proceedings/papers/v28/hocking13.pdf", "most_common": ["using", "model", "log", "data", "annotation", "penalty", "learning", "loss", "function", "interval", "error", "signal", "regression", "number", "surrogate", "detection", "table", "optimal", "term", "problem", "figure", "annotated", "smoothing", "penalties", "target", "margin", "signals", "learn", "set", "use", "convex", "functions", "features", "algorithm", "annotations", "complexity", "shown", "since", "exp", "models", "segments", "feature", "max", "used", "noise", "variance", "sparse", "one", "arg", "plausiblek", "calculate", "two", "selection", "minimizing", "several", "changes", "sets", "bic", "kmax", "constant", "every", "panel", "visual", "may", "regions", "estimate", "mbic", "points", "line", "four", "vector", "estimated", "section", "learned", "method", "segmentation", "size", "changepoint", "min", "show", "however", "many", "uses", "results", "exact", "relaxation", "training", "criterion", "propose", "found", "separable", "note", "algorithms", "multiple", "lavielle", "expert", "drawn", "limits", "hocking", "database"], "authors": ["Toby Hocking", "Guillem Rigaill", "Jean-Philippe VERT", "Francis BACH"], "thumbnail_path": "thumbnails/Learning Sparse Penalties for Changepoint Detection using Max Margin Interval Regression.jpg"}, {"title": "Hierarchicallycoupled hidden Markov models for learning kinetic rates from singlemolecule data", "topics": [0.016067142823342401, 0.016065910736850503, 0.91966935255908977, 0.016065839144066993, 0.016065924595906507, 0.016065830140743927], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/willemvandemeent13.pdf", "most_common": ["time", "states", "model", "data", "inference", "series", "bayes", "set", "state", "models", "number", "log", "estimation", "learning", "variational", "empirical", "posterior", "veb", "analysis", "hyperparameters", "kinetic", "lower", "markov", "ensemble", "hidden", "experimental", "results", "rates", "simulated", "bound", "parameters", "transition", "single", "two", "experiments", "shows", "inferred", "selection", "hmms", "prior", "figure", "approach", "terms", "maximum", "distribution", "type", "known", "lveb", "likelihood", "means", "expectation", "individual", "bayesian", "procedure", "used", "methods", "graphical", "method", "conformational", "gonzalez", "molecule", "smfret", "consensus", "form", "similar", "use", "machine", "transitions", "shown", "could", "histograms", "hyperparameter", "show", "mixture", "using", "respect", "distributions", "bishop", "whereas", "algorithm", "biophysical", "maximization", "obtained", "parameter", "energy", "given", "observations", "jordan", "also", "shared", "error", "parametric", "bronson", "yields", "observables", "level", "experiment", "along", "fei", "equation"], "authors": ["Jan-Willem Van de Meent", "Jonathan Bronson", "Frank Wood", "Ruben Gonzalez, Jr.", "Chris Wiggins"], "thumbnail_path": "thumbnails/Hierarchicallycoupled hidden Markov models for learning kinetic rates from singlemolecule data.jpg"}, {"title": "Learning Connections in Financial Time Series", "topics": [0.021227841690249522, 0.0212284059428136, 0.79839714163272646, 0.021228446322282841, 0.11669013762420348, 0.021228026787724154], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/ganeshapillai13.pdf", "most_common": ["returns", "return", "model", "equities", "portfolio", "correlation", "matrix", "using", "method", "daily", "connectedness", "time", "market", "portfolios", "learning", "expected", "series", "risk", "large", "use", "two", "equity", "extreme", "used", "given", "factor", "connections", "weights", "financial", "day", "methods", "learn", "sharpe", "table", "events", "journal", "covariance", "positive", "therefore", "figure", "sector", "set", "cov", "optimization", "multivariate", "values", "map", "days", "historical", "cumulative", "negative", "problem", "partial", "learned", "losses", "ratio", "data", "sectors", "energy", "since", "least", "also", "construction", "fac", "cost", "minimum", "based", "statistical", "among", "precision", "regression", "built", "maximum", "results", "list", "active", "crisis", "information", "may", "pcr", "companies", "evcr", "measures", "sensitivity", "variance", "build", "average", "models", "relationships", "solnik", "work", "analysis", "squares", "estimate", "investors", "min", "performance", "bac", "parameters", "new"], "authors": ["Gartheeban Ganeshapillai", "John Guttag", "Andrew Lo"], "thumbnail_path": "thumbnails/Learning Connections in Financial Time Series.jpg"}, {"title": "The Extended Parameter Filter", "topics": [0.018286793040347922, 0.018286897506063288, 0.90851465292027578, 0.018327144997789212, 0.018297148765523425, 0.018287362770000228], "pdf_url": "http://jmlr.org/proceedings/papers/v28/bugraerol13.pdf", "most_common": ["parameter", "model", "time", "approximation", "transition", "density", "particles", "particle", "algorithm", "gibbs", "mean", "approximate", "epf", "figure", "order", "models", "parameters", "polynomial", "extended", "function", "taylor", "section", "state", "sampling", "may", "distribution", "process", "sample", "values", "static", "true", "kalman", "filter", "converges", "statistics", "separable", "variables", "note", "observation", "storvik", "carlo", "method", "following", "sir", "one", "system", "converge", "approach", "arbitrary", "posterior", "deviation", "update", "monte", "let", "use", "sin", "statistical", "matrix", "space", "shows", "case", "bayesian", "step", "general", "degeneracy", "standard", "data", "series", "gaussian", "given", "estimation", "learning", "value", "theorem", "using", "per", "problem", "sequential", "inference", "known", "equation", "dynamical", "complexity", "markov", "however", "approximations", "doucet", "show", "respect", "applied", "sequence", "supplementary", "statistic", "log", "form", "constant", "assume", "cauchy", "requires", "dynamic"], "authors": ["Yusuf Bugra Erol", ""], "thumbnail_path": "thumbnails/The Extended Parameter Filter.jpg"}, {"title": "Transition Matrix Estimation in High Dimensional Time Series", "topics": [0.019186730620692101, 0.019186673010749857, 0.90406492961651541, 0.019187037169687192, 0.019187376011073266, 0.019187253571282079], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/han13a.pdf", "most_common": ["matrix", "transition", "var", "method", "data", "let", "equation", "estimation", "time", "lasso", "models", "vector", "high", "series", "dimensional", "autoregressive", "model", "methods", "paper", "ridge", "represent", "section", "max", "new", "norm", "following", "log", "norms", "proposed", "estimator", "matrices", "covariance", "sparsity", "stationary", "averaged", "frobenius", "estimating", "linear", "penalty", "respect", "three", "analysis", "liu", "using", "problem", "results", "synthetic", "entries", "level", "analyzing", "sample", "theoretical", "provide", "stock", "lag", "propose", "induced", "result", "pattern", "nonzero", "provided", "convergence", "argmin", "existing", "dimensionality", "multivariate", "table", "brain", "statistical", "number", "one", "minj", "points", "subject", "losses", "empirical", "optimization", "error", "journal", "han", "moreover", "comparison", "compared", "prediction", "sign", "marginal", "work", "figure", "process", "introduce", "gaussian", "support", "size", "asymptotic", "doubly", "maxj", "performance", "selection", "show", "set"], "authors": ["Fang Han", "Han Liu"], "thumbnail_path": "thumbnails/Transition Matrix Estimation in High Dimensional Time Series.jpg"}, {"title": "Dependent Normalized Random Measures", "topics": [0.017051740790518494, 0.01705232030118442, 0.91473496859888459, 0.017051955233312967, 0.017056680557600075, 0.017052334518499423], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chen13i.pdf", "most_common": ["random", "normalized", "qrt", "process", "measures", "dependent", "sampler", "time", "gamma", "models", "slice", "number", "hmngg", "marginal", "topic", "probability", "set", "measure", "atoms", "htngg", "datasets", "parameter", "region", "dirichlet", "posterior", "see", "nrms", "crm", "mngg", "also", "independent", "teh", "tngg", "crms", "tnrm", "distribution", "two", "zrtk", "wrk", "distributed", "mnrm", "documents", "poisson", "appendix", "thinning", "variables", "observations", "construction", "nrm", "used", "samplers", "weights", "following", "stl", "intensity", "thus", "model", "lin", "thinned", "ess", "work", "times", "mixture", "vtl", "using", "spatial", "test", "larger", "sample", "xtl", "data", "nonparametric", "training", "rao", "constructions", "generalized", "class", "ngg", "words", "associated", "bayesian", "hdp", "assigned", "follows", "icml", "hierarchical", "atom", "hmngp", "allowing", "tpami", "index", "rate", "base", "resulting", "inference", "call", "marginally", "values", "regions", "james"], "authors": ["Changyou Chen", "Vinayak Rao", "Yee Whye Teh", "Wray Buntine"], "thumbnail_path": "thumbnails/Dependent Normalized Random Measures.jpg"}, {"title": "Topic Discovery through Data Dependent and Random Projections", "topics": [0.018271120785096656, 0.018271359968923508, 0.90861596772113129, 0.018271161278371799, 0.018299277214757877, 0.0182711130317188], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ding13.pdf", "most_common": ["novel", "topic", "words", "algorithm", "matrix", "word", "topics", "random", "ddp", "arora", "set", "gibbs", "algorithms", "data", "points", "projections", "extreme", "document", "convex", "dataset", "two", "number", "documents", "dependent", "nmf", "distinct", "clustering", "complexity", "error", "proposition", "given", "also", "approach", "discovery", "extracted", "since", "probability", "blei", "learning", "steyvers", "maximum", "table", "iid", "training", "ground", "modeling", "swimmer", "patterns", "image", "zzz", "provable", "projection", "work", "following", "example", "figure", "sample", "end", "correspond", "shown", "one", "separability", "multiple", "based", "direction", "truth", "distribution", "estimated", "method", "latent", "parameters", "apply", "positive", "values", "tan", "dirichlet", "nonnegative", "show", "asymptotically", "present", "empirical", "analysis", "proposed", "input", "using", "output", "images", "similar", "associated", "single", "clean", "synthetic", "condition", "diag", "section", "body", "let", "machine", "order", "positions"], "authors": ["Weicong Ding", "Mohammad Hossein Rohban", "Prakash Ishwar", "Venkatesh Saligrama"], "thumbnail_path": "thumbnails/Topic Discovery through Data Dependent and Random Projections.jpg"}, {"title": "Factorial MultiTask Learning  A Bayesian Nonparametric Approach", "topics": [0.016627578034938261, 0.016625746483637616, 0.91686769535060231, 0.016626326894179248, 0.016627093935353308, 0.016625559301289183], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gupta13a.pdf", "most_common": ["tasks", "learning", "task", "model", "process", "subspace", "groups", "data", "using", "beta", "number", "group", "hierarchical", "prior", "predictors", "bayesian", "regression", "nonparametric", "bases", "posterior", "factor", "shared", "set", "training", "used", "dirichlet", "use", "datasets", "machine", "factorial", "framework", "related", "joint", "across", "sampling", "analysis", "gupta", "varying", "iii", "given", "performance", "relatedness", "distribution", "results", "synthetic", "dataset", "however", "real", "sharing", "multiple", "modeling", "second", "proposed", "index", "degree", "allows", "figure", "rmse", "inferred", "approach", "basis", "gibbs", "school", "method", "multitask", "passos", "individual", "conference", "bernoulli", "journal", "two", "jointly", "inference", "applications", "experiments", "one", "argyriou", "stl", "see", "problem", "automatically", "research", "unrelated", "ztk", "construction", "hbp", "therefore", "kumar", "xti", "share", "sample", "feature", "kang", "matrix", "partition", "mixture", "written", "fut", "zgt", "examples"], "authors": ["Sunil Gupta", "Dinh Phung", "Svetha Venkatesh"], "thumbnail_path": "thumbnails/Factorial MultiTask Learning  A Bayesian Nonparametric Approach.jpg"}, {"title": "Scaling the Indian Buffet Process via Submodular Maximization", "topics": [0.018847316184219774, 0.018868157858053198, 0.90574048114635342, 0.018849697148347454, 0.018847272535492746, 0.018847075127533502], "pdf_url": "http://jmlr.org/proceedings/papers/v28/reed13.pdf", "most_common": ["submodular", "ibp", "inference", "meibp", "latent", "variational", "models", "methods", "dataset", "model", "algorithm", "nonnegative", "maximization", "data", "function", "indian", "priors", "solution", "via", "process", "feature", "map", "complexity", "ghahramani", "matrix", "features", "evidence", "using", "distribution", "time", "prior", "ugibbs", "znk", "bnmf", "gaussian", "show", "solutions", "converged", "lower", "aibp", "bound", "true", "mfvb", "sampling", "results", "likelihood", "given", "optimization", "binary", "used", "factors", "updates", "large", "test", "akd", "scaling", "kan", "random", "local", "rvs", "synthetic", "figure", "optimal", "number", "also", "set", "however", "convergence", "equivalence", "following", "vibp", "kbn", "obtains", "shows", "piano", "columns", "flickr", "bayesian", "obtain", "sparse", "assignments", "submodularity", "maximum", "global", "welling", "small", "let", "kurihara", "larger", "use", "framework", "space", "see", "optimum", "terms", "independent", "maximizing", "yields", "truncated", "approximate"], "authors": ["Colorado Reed", "Ghahramani Zoubin"], "thumbnail_path": "thumbnails/Scaling the Indian Buffet Process via Submodular Maximization.jpg"}, {"title": "A Variational Approximation for Topic Modeling of Hierarchical Corpora", "topics": [0.018857515131902272, 0.018857546820369046, 0.90571166224605126, 0.018857482819890106, 0.018857354424169293, 0.018858438557618065], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kim13.pdf", "most_common": ["topic", "variational", "corpora", "dirichlet", "tilda", "model", "hierarchical", "hdps", "models", "proportions", "approximation", "corpus", "inference", "topics", "documents", "number", "results", "lda", "document", "parameters", "latent", "one", "blackhatworld", "teh", "section", "also", "blei", "modeling", "gibbs", "bound", "categories", "variables", "approach", "sampling", "learning", "figure", "subcategories", "wang", "category", "log", "freelancer", "large", "prior", "two", "nonparametric", "online", "proceedings", "job", "distribution", "lower", "deep", "nodes", "work", "root", "paper", "parent", "conference", "levels", "algorithm", "represent", "zdn", "machine", "applications", "developed", "main", "approaches", "international", "see", "terms", "however", "attached", "many", "procedure", "nips", "describes", "structure", "finally", "postings", "use", "information", "collection", "inequality", "related", "used", "special", "internet", "tokens", "note", "words", "set", "graphical", "bayesian", "web", "opt", "articles", "methods", "form", "node", "draw", "four"], "authors": ["Do-kyum Kim", "Geoffrey Voelker", "Lawrence Saul"], "thumbnail_path": "thumbnails/A Variational Approximation for Topic Modeling of Hierarchical Corpora.jpg"}, {"title": "Manifold Preserving Hierarchical Topic Models for Quantization and Approximation", "topics": [0.019816294895097626, 0.019815490159874324, 0.90091718328546366, 0.019816893643692327, 0.019815209661741499, 0.019818928354130565], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kim13a.pdf", "most_common": ["manifold", "data", "samples", "sampling", "quantization", "input", "topic", "source", "figure", "plsi", "mixture", "proposed", "topics", "training", "interpolation", "sparse", "number", "preserving", "models", "convex", "separation", "using", "random", "overcomplete", "hull", "model", "latent", "parameters", "set", "hierarchical", "method", "neighbors", "approximation", "use", "two", "points", "also", "sparsity", "results", "better", "one", "layer", "cross", "speech", "variable", "original", "second", "learned", "vectors", "rates", "entropy", "ordinary", "parameter", "corners", "linear", "sum", "selection", "reconstruct", "rate", "case", "representation", "note", "probabilistic", "estimation", "best", "sources", "digit", "provide", "systems", "matrix", "nts", "estimate", "sets", "class", "neighboring", "proceedings", "whole", "analysis", "provides", "additional", "weights", "four", "blue", "reconstruction", "inputs", "performance", "combination", "shows", "first", "instance", "get", "new", "result", "terms", "however", "smaragdis", "learning", "conference", "three", "less"], "authors": ["Minje Kim", "Paris Smaragdis"], "thumbnail_path": "thumbnails/Manifold Preserving Hierarchical Topic Models for Quantization and Approximation.jpg"}, {"title": "Subtle Topic Models and Discovering Subtly Manifested Software Concerns Automatically ", "topics": [0.020439539793418535, 0.020439576314959608, 0.89780024085428078, 0.020440052630536557, 0.020441107203214171, 0.020439483203590438], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/das13.pdf", "most_common": ["topic", "topics", "subtle", "software", "concerns", "stm", "models", "document", "dirichlet", "process", "ftm", "hdp", "number", "discovering", "detect", "coherence", "vectors", "used", "using", "code", "subtly", "words", "gsbp", "automatically", "distribution", "word", "recall", "concern", "proceedings", "inference", "may", "documents", "manifested", "dataset", "two", "sample", "standard", "corpus", "sentences", "also", "generalized", "however", "problem", "conference", "model", "source", "rare", "discover", "perplexity", "use", "detected", "detecting", "across", "level", "international", "jhotdraw", "sentence", "one", "table", "approach", "distributions", "berkeleydb", "section", "prior", "stick", "breaking", "bdai", "note", "average", "case", "thus", "binary", "important", "program", "small", "rarely", "example", "occur", "propose", "probability", "dos", "datasets", "observed", "ability", "extent", "well", "keywords", "latent", "cases", "end", "nips", "engineering", "denotes", "top", "gold", "text", "conditional", "due", "empirical", "lda"], "authors": ["Mrinal Das", "Suparna Bhattacharya", "Chiranjib Bhattacharyya", "Gopinath Kanchi"], "thumbnail_path": "thumbnails/Subtle Topic Models and Discovering Subtly Manifested Software Concerns Automatically .jpg"}, {"title": "Latent Dirichlet Allocation Topic Model with Soft Assignment of Descriptors to Words", "topics": [0.019621081910471839, 0.019621022328773195, 0.90189394954111202, 0.019621045626530255, 0.019621874787080874, 0.019621025806031794], "pdf_url": "http://jmlr.org/proceedings/papers/v28/weinshall13.pdf", "most_common": ["model", "words", "lda", "assignment", "dictionary", "word", "video", "soft", "descriptors", "topic", "events", "log", "using", "probability", "variational", "generative", "detection", "represented", "parameter", "one", "documents", "mixture", "described", "distribution", "descriptor", "learning", "document", "extended", "use", "set", "inference", "algorithm", "given", "blei", "estimation", "vector", "order", "original", "mahadevan", "section", "data", "hard", "latent", "novelty", "parameters", "representation", "used", "size", "state", "bag", "bags", "fdn", "similar", "models", "novel", "fdnj", "following", "collection", "hidden", "training", "dirichlet", "features", "observed", "online", "exp", "dataset", "dynamic", "obtained", "probabilities", "visual", "event", "topics", "frame", "respect", "thus", "cvpr", "performance", "method", "therefore", "may", "likelihood", "isa", "corpus", "continuous", "sivic", "vision", "achieved", "modeling", "lower", "identify", "fdna", "image", "methods", "function", "histogram", "update", "patches", "level", "discrete", "new"], "authors": ["Daphna Weinshall", "Gal Levi", "Dmitri Hanukaev"], "thumbnail_path": "thumbnails/Latent Dirichlet Allocation Topic Model with Soft Assignment of Descriptors to Words.jpg"}, {"title": "Efficient Multilabel Classification with Many Labels", "topics": [0.017711699409011222, 0.017711733677214982, 0.91138197760505757, 0.017717681929298769, 0.017711686762711523, 0.017765220616705896], "pdf_url": "http://jmlr.org/proceedings/papers/v28/bi13.pdf", "most_common": ["label", "number", "labels", "data", "sampling", "matrix", "proposed", "columns", "error", "log", "algorithm", "boutsidis", "learning", "time", "plst", "section", "encoding", "cssp", "set", "many", "probability", "table", "cplst", "large", "approximation", "moplms", "rank", "training", "selected", "also", "using", "methods", "dmoz", "machine", "selection", "algorithms", "proceedings", "thus", "subset", "rmse", "lin", "best", "much", "drineas", "output", "results", "use", "sample", "shows", "however", "conference", "trials", "proposition", "full", "sets", "kernel", "binary", "used", "analysis", "desc", "column", "delicious", "problem", "svd", "prediction", "international", "method", "may", "space", "performance", "various", "optimization", "perform", "obtain", "transformation", "takes", "problems", "vector", "obtained", "ndk", "computationally", "approach", "moreover", "transformed", "lebanon", "step", "compute", "balasubramanian", "zhang", "hyc", "even", "vectors", "select", "following", "tai", "multilabel", "randomized", "given", "testing", "rrqr"], "authors": ["Wei Bi", "James Kwok"], "thumbnail_path": "thumbnails/Efficient Multilabel Classification with Many Labels.jpg"}, {"title": "A Randomized Mirror Descent Algorithm for Large Scale Multiple Kernel Learning", "topics": [0.01602879199158256, 0.016028732760338105, 0.91985644425186563, 0.016028765660439249, 0.01602857153068173, 0.01602869380509268], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/afkanpour13.pdf", "most_common": ["algorithm", "kernel", "learning", "kernels", "method", "gradient", "descent", "large", "let", "randomized", "note", "mirror", "set", "methods", "problem", "number", "mkl", "convex", "multiple", "case", "kloft", "algorithms", "section", "sampling", "polynomial", "also", "scale", "machine", "space", "see", "time", "estimate", "example", "complexity", "base", "one", "based", "however", "input", "weights", "stochastic", "product", "notation", "coordinate", "computational", "function", "use", "iteration", "pages", "cortes", "results", "degree", "compare", "sample", "standard", "performance", "distribution", "optimization", "thus", "journal", "underlying", "bach", "convergence", "assume", "consider", "research", "cost", "training", "experiments", "given", "importance", "conference", "empirical", "predictor", "denote", "vector", "uniform", "holds", "data", "shown", "shows", "proceedings", "approach", "paper", "terms", "value", "depends", "using", "loss", "works", "nesterov", "form", "volume", "fact", "solution", "penalized", "linearly", "particular", "learn", "following"], "authors": ["Arash Afkanpour", "Andras Gyorgy", "Csaba Szepesvari", "Michael Bowling"], "thumbnail_path": "thumbnails/A Randomized Mirror Descent Algorithm for Large Scale Multiple Kernel Learning.jpg"}, {"title": "MILEAGE Multiple Instance LEArning with Global Embedding", "topics": [0.017149575586009096, 0.017148644337272381, 0.91425507257241645, 0.017148611693472357, 0.017149166965442674, 0.017148928845387084], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhang13a.pdf", "most_common": ["global", "method", "local", "instance", "positive", "learning", "proposed", "example", "methods", "representation", "bundle", "instances", "multiple", "problem", "feature", "bag", "mileage", "bij", "two", "mil", "experiments", "better", "used", "one", "objective", "function", "representations", "dataset", "misvm", "traditional", "embedding", "optimization", "solve", "theorem", "convex", "max", "based", "negative", "bags", "andrews", "set", "remp", "cutting", "however", "log", "results", "ratio", "fuduli", "considered", "also", "image", "datasets", "svm", "solving", "training", "features", "given", "iteration", "min", "maxj", "accuracy", "text", "parts", "whether", "large", "insider", "information", "complexity", "shown", "threat", "rademacher", "please", "margin", "proximity", "research", "joachims", "vector", "approximation", "labeled", "optimal", "parameter", "derived", "framework", "conducted", "employed", "paper", "detection", "otherwise", "unlabeled", "lower", "icml", "planes", "novel", "solution", "section", "parameters", "ratios", "following", "proof", "machine"], "authors": ["Dan Zhang", "Jingrui He", "Luo Si", "Richard Lawrence"], "thumbnail_path": "thumbnails/MILEAGE Multiple Instance LEArning with Global Embedding.jpg"}, {"title": "Online Kernel Learning with a Near Optimal Sparsity Bound", "topics": [0.022176495848630011, 0.022176710184794675, 0.88911621742117952, 0.022177828510692776, 0.022176323492990702, 0.022176424541712387], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhang13c.pdf", "most_common": ["kernel", "learning", "online", "support", "number", "vectors", "sparse", "loss", "bound", "algorithm", "budget", "sparsity", "proposed", "training", "function", "vector", "algorithms", "table", "optimal", "data", "derivative", "using", "sampling", "oskl", "bounded", "average", "approach", "near", "time", "regret", "probability", "lemma", "set", "analysis", "gradient", "used", "smooth", "similar", "zhang", "solution", "work", "following", "least", "intermediate", "bounds", "results", "example", "gzt", "shows", "also", "based", "last", "forgetron", "methods", "sequence", "assume", "svs", "condition", "magic", "domain", "size", "performance", "exp", "logistic", "result", "descent", "sets", "theorem", "nips", "generated", "smaller", "allows", "proof", "adult", "wang", "parameter", "developed", "since", "standard", "singer", "key", "second", "covtype", "margin", "examples", "inequality", "two", "compared", "stochastic", "large", "upper", "burges", "section", "pegasos", "china", "perceptron", "control", "give", "machine", "baseline"], "authors": ["Lijun Zhang", "Rong Jin", "Xiaofei He"], "thumbnail_path": "thumbnails/Online Kernel Learning with a Near Optimal Sparsity Bound.jpg"}, {"title": "On the Generalization Ability of Online Learning Algorithms for Pairwise Loss Functions", "topics": [0.016574963197167971, 0.016574860617796883, 0.91712567611656259, 0.016574875589664393, 0.016574763505512798, 0.016574860973295164], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kar13.pdf", "most_common": ["learning", "online", "loss", "bounds", "algorithm", "regret", "algorithms", "function", "functions", "generalization", "bound", "pairwise", "log", "policy", "rademacher", "section", "proof", "wang", "using", "risk", "convex", "provide", "problems", "update", "technique", "use", "able", "order", "zhao", "give", "analysis", "input", "results", "lbuf", "used", "given", "see", "step", "auc", "appendix", "following", "stream", "batch", "also", "ensemble", "probability", "conversion", "ability", "strongly", "theorem", "guarantees", "dependence", "convergence", "let", "hypothesis", "kakade", "bounded", "excess", "oamgra", "symmetrization", "require", "classes", "points", "techniques", "metric", "several", "similar", "dimensionality", "randomness", "complexities", "allows", "working", "training", "size", "penalty", "lemma", "however", "present", "error", "obtain", "olp", "fast", "icml", "problem", "case", "empirical", "rbuf", "nips", "since", "note", "tewari", "show", "based", "suppose", "higher", "tighter", "samples", "regularized", "analyze", "form"], "authors": ["Prateek Jain", "Bharath Sriperumbudur", "Purushottam Kar", "Harish Karnick"], "thumbnail_path": "thumbnails/On the Generalization Ability of Online Learning Algorithms for Pairwise Loss Functions.jpg"}, {"title": "Thompson Sampling for Contextual Bandits with Linear Payoffs", "topics": [0.023401411674065425, 0.023402049917624065, 0.88298465232118817, 0.023403848326861616, 0.023406552538913022, 0.023401485221347915], "pdf_url": "http://jmlr.org/proceedings/papers/v28/agrawal13.pdf", "most_common": ["regret", "arm", "time", "contextual", "thompson", "arms", "algorithm", "sampling", "problem", "bandits", "probability", "linear", "bounds", "bandit", "bound", "unsaturated", "lemma", "reward", "distribution", "theorem", "proof", "gaussian", "setting", "appendix", "used", "mab", "given", "every", "optimal", "parameter", "saturated", "also", "mean", "context", "learning", "bayesian", "stochastic", "standard", "best", "using", "inequality", "true", "set", "basic", "played", "auer", "likelihood", "playing", "vectors", "analysis", "prior", "prove", "colt", "version", "provided", "deviation", "results", "learner", "let", "chu", "feature", "paper", "one", "chapelle", "play", "techniques", "contexts", "supplementary", "step", "bounded", "total", "use", "theoretical", "high", "provide", "may", "hence", "rewards", "see", "goyal", "many", "agrawal", "case", "empirical", "lower", "predictor", "therefore", "posterior", "general", "functions", "details", "problems", "vector", "along", "parameters", "useful", "history", "sample", "machine", "better"], "authors": ["Shipra Agrawal", "Navin Goyal"], "thumbnail_path": "thumbnails/Thompson Sampling for Contextual Bandits with Linear Payoffs.jpg"}, {"title": "Online Learning under Delayed Feedback", "topics": [0.02189863418989825, 0.021903344927564676, 0.89050152162392993, 0.021898715963981099, 0.021898705646345541, 0.021899077648280422], "pdf_url": "http://jmlr.org/proceedings/papers/v28/joulani13.pdf", "most_common": ["feedback", "delayed", "time", "base", "regret", "prediction", "algorithm", "learning", "information", "delays", "online", "setting", "instant", "reward", "stochastic", "case", "side", "bound", "algorithms", "problem", "forecaster", "expected", "adversarial", "partial", "let", "number", "sequence", "log", "section", "monitoring", "also", "bandit", "instance", "delay", "may", "feedbacks", "set", "weinberger", "consider", "additive", "fbase", "note", "ordentlich", "predictions", "assume", "full", "paper", "used", "rewards", "new", "denote", "bold", "function", "bounds", "results", "upper", "work", "optimal", "independent", "way", "environment", "use", "mesterharm", "end", "times", "hence", "one", "maximum", "ucb", "run", "problems", "instances", "showed", "version", "previous", "theorem", "multiplicative", "info", "made", "assumptions", "provide", "given", "performance", "average", "penalty", "lemma", "value", "make", "increases", "ipm", "constant", "general", "existing", "waiting", "sup", "langford", "outcomes", "give", "predict", "inequality"], "authors": ["Pooria Joulani", "Andras Gyorgy", "Csaba Szepesvari"], "thumbnail_path": "thumbnails/Online Learning under Delayed Feedback.jpg"}, {"title": "Almost Optimal Exploration in MultiArmed Bandits", "topics": [0.025453739062569276, 0.025454395714240387, 0.8727294336902558, 0.025453853269708823, 0.025454448578732761, 0.025454129684492958], "pdf_url": "http://jmlr.org/proceedings/papers/v28/karnin13.pdf", "most_common": ["arm", "arms", "algorithm", "probability", "best", "log", "budget", "number", "setting", "round", "algorithms", "pulls", "problem", "optimal", "setup", "given", "least", "lemma", "exploration", "bound", "bandits", "eliminated", "gap", "elimination", "upper", "exp", "learning", "reward", "logarithmic", "almost", "lower", "analysis", "bounds", "complexity", "suboptimal", "adaptive", "error", "player", "sequential", "mab", "experiments", "see", "two", "medianelimination", "results", "empirical", "section", "total", "prove", "end", "machine", "one", "successive", "set", "conference", "required", "international", "let", "high", "following", "sample", "goal", "order", "better", "times", "target", "proceedings", "settings", "halving", "bandit", "expected", "previous", "theorem", "bubeck", "audibert", "setups", "consider", "auer", "theoretical", "seqhalving", "maximal", "gabillon", "also", "average", "factor", "fixed", "follows", "successiverejects", "assume", "presented", "must", "work", "inequality", "since", "rewards", "performance", "considered", "approach", "simple", "mannor"], "authors": ["Zohar Karnin", "Tomer Koren", "Oren Somekh"], "thumbnail_path": "thumbnails/Almost Optimal Exploration in MultiArmed Bandits.jpg"}, {"title": "Forecastable Component Analysis", "topics": [0.017369105694172132, 0.017367329400055937, 0.91280865757338725, 0.017368392628198927, 0.017717600492440966, 0.017368914211744729], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/goerg13.pdf", "most_common": ["time", "series", "forecastable", "foreca", "entropy", "forec", "analysis", "component", "forecastability", "lag", "spectral", "measure", "since", "spectrum", "thus", "signals", "pca", "white", "density", "also", "sfa", "process", "using", "noise", "log", "multivariate", "sample", "data", "mining", "function", "rate", "water", "particular", "used", "ieee", "energy", "returns", "however", "estimation", "forecasting", "signal", "autocorrelation", "frequencies", "use", "example", "figure", "india", "loga", "estimate", "uncertainty", "variance", "stationary", "important", "consider", "international", "let", "china", "fourier", "work", "max", "mean", "shows", "linear", "standard", "temperature", "future", "contrary", "gold", "show", "based", "uncorrelated", "acvf", "growth", "ica", "acf", "fast", "structure", "algorithm", "results", "large", "estimates", "section", "makes", "applications", "correlation", "indeed", "better", "frequency", "loadings", "rates", "predictable", "second", "even", "average", "proceedings", "problem", "conference", "independent", "cycle", "model"], "authors": ["Georg Goerg"], "thumbnail_path": "thumbnails/Forecastable Component Analysis.jpg"}, {"title": "Discriminatively Activated Sparselets", "topics": [0.016678991256322766, 0.016678697344011312, 0.91660586969673674, 0.01667838682901408, 0.016678462924204999, 0.016679591949709981], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/girshick13.pdf", "most_common": ["sparselets", "activation", "part", "object", "sparselet", "detection", "sparsity", "multiclass", "feature", "model", "learning", "song", "models", "vector", "linear", "dictionary", "felzenszwalb", "classes", "vectors", "discriminatively", "generalized", "set", "sparse", "image", "two", "speedup", "discriminative", "deformable", "ieee", "structured", "activated", "blocks", "training", "methods", "consider", "pascal", "output", "results", "prediction", "learned", "method", "reconstructive", "shared", "slots", "computational", "problem", "large", "regularization", "map", "number", "approach", "used", "dpms", "new", "parameter", "show", "dpm", "algorithm", "original", "leads", "cost", "root", "example", "paper", "features", "one", "objective", "accuracy", "imagenet", "class", "average", "factor", "girshick", "error", "input", "nonzero", "block", "function", "setting", "tpami", "reconstruction", "trained", "variables", "given", "everingham", "penalty", "local", "experiments", "responses", "however", "applied", "task", "subvector", "computing", "generalize", "selected", "parameters", "steerable", "mairal", "descent"], "authors": ["Ross Girshick", "Hyun Oh Song", "Trevor Darrell"], "thumbnail_path": "thumbnails/Discriminatively Activated Sparselets.jpg"}, {"title": "MultiView Clustering and Feature Learning via Structured Sparsity", "topics": [0.016771463760898934, 0.016771343328998822, 0.9161418217475118, 0.016772672488527363, 0.016771313557400691, 0.016771385116662197], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wang13c.pdf", "most_common": ["data", "method", "clustering", "features", "learning", "feature", "type", "methods", "matrix", "mkl", "algorithm", "sparsity", "via", "multiple", "view", "svm", "one", "following", "structured", "new", "weights", "proposed", "weight", "regularization", "individual", "views", "framework", "objective", "kernel", "cluster", "table", "group", "heng", "learn", "diagonal", "importance", "thus", "nie", "compared", "results", "spectral", "discriminative", "two", "wang", "types", "clusters", "used", "joint", "set", "huang", "color", "solve", "sets", "using", "supervised", "image", "problem", "large", "implement", "machine", "feiping", "given", "text", "lssvm", "concatenation", "also", "heterogeneous", "solution", "vector", "hua", "norms", "many", "protein", "upon", "sources", "tasks", "use", "information", "better", "min", "performance", "lanckriet", "selection", "andrew", "model", "theorem", "relevance", "fusion", "step", "comparison", "three", "important", "svd", "multiview", "novel", "learned", "apply", "zii", "saykin", "proof"], "authors": ["Hua Wang", "Feiping Nie", "Heng Huang"], "thumbnail_path": "thumbnails/MultiView Clustering and Feature Learning via Structured Sparsity.jpg"}, {"title": "Connecting the Dots with Landmarks Discriminatively Learning DomainInvariant Features for Unsupervised Domain Adaptation", "topics": [0.020667391964681866, 0.020667284680242603, 0.89666330729347055, 0.020667282133996732, 0.020667219335079888, 0.020667514592528267], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/gong13.pdf", "most_common": ["domain", "landmarks", "target", "adaptation", "source", "learning", "auxiliary", "features", "use", "data", "tasks", "kernel", "instances", "domains", "images", "discriminatively", "landmark", "using", "method", "unsupervised", "blitzer", "original", "approach", "problem", "scale", "multiple", "section", "two", "feature", "gfk", "one", "object", "thus", "analysis", "distribution", "results", "selected", "new", "webcam", "show", "labels", "pan", "samples", "similar", "gong", "similarity", "similarly", "points", "table", "recognition", "also", "saenko", "used", "labeled", "discriminative", "distributed", "amazon", "metric", "proposed", "dataset", "datasets", "distributions", "space", "accuracies", "gretton", "compare", "sentiment", "training", "selection", "solutions", "several", "similarities", "gopalan", "row", "huang", "invariant", "category", "approaches", "computed", "methods", "basis", "task", "kmm", "selecting", "often", "chen", "contrast", "shift", "study", "scales", "would", "positive", "benchmark", "visual", "work", "example", "including", "nips", "subset", "idea"], "authors": ["Boqing Gong", "Kristen Grauman", "Fei Sha"], "thumbnail_path": "thumbnails/Connecting the Dots with Landmarks Discriminatively Learning DomainInvariant Features for Unsupervised Domain Adaptation.jpg"}, {"title": "On Nonlinear Generalization of Sparse Coding and Dictionary Learning", "topics": [0.018932743237986119, 0.018932622446309087, 0.90533673940622961, 0.018932617497824999, 0.018932559268283092, 0.018932718143367208], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ho13a.pdf", "most_common": ["sparse", "dictionary", "learning", "using", "coding", "riemannian", "point", "vector", "data", "space", "atoms", "manifold", "two", "linear", "points", "generalization", "nonlinear", "euclidean", "feature", "geometry", "method", "problem", "wij", "function", "tangent", "methods", "geodesic", "given", "optimization", "critical", "three", "svm", "particular", "equation", "distance", "manifolds", "metric", "intrinsic", "proposed", "let", "oasis", "sphere", "matrix", "sparsity", "structure", "global", "following", "map", "used", "formula", "features", "considered", "general", "also", "constraint", "image", "algorithm", "existing", "exponential", "remark", "machine", "collection", "applications", "main", "dataset", "brodatz", "however", "logxi", "young", "gknn", "small", "second", "vectors", "number", "since", "min", "experiments", "set", "density", "important", "log", "form", "compute", "functions", "matrices", "section", "experiment", "texture", "known", "must", "information", "algorithms", "framework", "gradient", "training", "extrinsic", "notion", "joshi", "local", "symmetric"], "authors": ["Jeffrey Ho", "Yuchen Xie", "Baba Vemuri"], "thumbnail_path": "thumbnails/On Nonlinear Generalization of Sparse Coding and Dictionary Learning.jpg"}, {"title": "Feature MultiSelection among Subjective Features", "topics": [0.016997586243492568, 0.016997915098404141, 0.91499934976146247, 0.016997844189168908, 0.017005336079772573, 0.017001968627699281], "pdf_url": "http://jmlr.org/proceedings/papers/v28/sabato13.pdf", "most_common": ["feature", "judgments", "algorithm", "features", "number", "set", "attributes", "attribute", "training", "full", "scoring", "one", "algorithms", "budget", "vector", "estimate", "height", "subjective", "weight", "per", "problem", "labeled", "object", "matrix", "since", "selection", "among", "regression", "results", "objects", "let", "standard", "denote", "test", "repeat", "prediction", "work", "may", "correlation", "approach", "used", "variance", "loss", "learning", "estimates", "estimated", "use", "mean", "external", "error", "binary", "judgment", "using", "crowd", "examples", "subr", "convergence", "distribution", "small", "positive", "crowdsourcing", "figure", "sample", "data", "might", "linear", "diagonal", "assumption", "multiple", "based", "see", "label", "however", "possible", "copies", "also", "setting", "assume", "random", "large", "value", "selected", "total", "two", "goal", "rmse", "greedy", "times", "future", "zero", "objective", "labels", "experiments", "covariance", "input", "noisy", "predictor", "reliability", "rate", "diag"], "authors": ["Sivan Sabato", "Adam Kalai"], "thumbnail_path": "thumbnails/Feature MultiSelection among Subjective Features.jpg"}, {"title": "SparsityBased Generalization Bounds for Predictive Sparse Coding ", "topics": [0.021594351197479742, 0.021595839521952591, 0.89202311589354844, 0.021594330478678495, 0.021595357652694373, 0.021597005255646368], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/mehta13.pdf", "most_common": ["sparse", "coding", "stability", "theorem", "bound", "sample", "predictive", "margins", "dictionary", "learning", "ghost", "points", "training", "bounds", "let", "log", "setting", "learned", "probability", "small", "also", "result", "space", "set", "conditions", "margin", "proof", "linear", "generalization", "atoms", "empirical", "bounded", "reconstructive", "optimal", "hence", "least", "show", "lemma", "error", "loss", "encoder", "codes", "respect", "number", "sparsity", "functions", "overcomplete", "large", "second", "brd", "properties", "class", "hypothesis", "used", "dimension", "lasso", "proper", "proposition", "via", "use", "data", "mairal", "one", "min", "satisfying", "stable", "risk", "satisfy", "two", "hold", "high", "norm", "holds", "machine", "guarantee", "may", "representation", "good", "term", "vainsencher", "size", "perturbations", "objective", "prz", "point", "strategy", "much", "random", "using", "dictionaries", "dependence", "problem", "consider", "condition", "solution", "information", "complexity", "systems", "main", "level"], "authors": ["Nishant Mehta", "Alexander Gray"], "thumbnail_path": "thumbnails/SparsityBased Generalization Bounds for Predictive Sparse Coding .jpg"}, {"title": "A Unified Robust Regression Model for Lassolike Algorithms", "topics": [0.021506927337920576, 0.021506842469126361, 0.89246087081368564, 0.021510131511847084, 0.021507878709093434, 0.021507349158326843], "pdf_url": "http://jmlr.org/proceedings/papers/v28/yang13e.pdf", "most_common": ["lasso", "regression", "group", "robust", "linear", "set", "min", "equivalent", "uncertainty", "theorem", "max", "problem", "algorithms", "sparsity", "groups", "one", "regularized", "sparse", "formulation", "standard", "overlapping", "solution", "new", "robustness", "norm", "regularization", "solutions", "consider", "corollary", "following", "statistical", "matrix", "learning", "model", "tibshirani", "also", "show", "result", "suppose", "sets", "using", "denote", "let", "feature", "features", "consistency", "fused", "optimization", "provides", "implies", "vector", "interpretation", "see", "general", "convex", "results", "whose", "theory", "two", "information", "optimal", "ieee", "transactions", "exists", "case", "disturbance", "select", "cgi", "column", "statistics", "journal", "problems", "ith", "main", "framework", "constraints", "since", "shows", "lin", "encourages", "thus", "yuan", "proposed", "density", "generalized", "success", "properties", "appendix", "particular", "data", "paper", "xgi", "series", "hence", "given", "class", "section", "based", "observed", "notice"], "authors": ["Wenzhuo Yang", "Huan Xu"], "thumbnail_path": "thumbnails/A Unified Robust Regression Model for Lassolike Algorithms.jpg"}, {"title": "MultiClass Classification with Maximum Margin Multiple Kernel", "topics": [0.017510116337844786, 0.017510310465699019, 0.9124493988029484, 0.017510091215185944, 0.017510042364280446, 0.01751004081404136], "pdf_url": "http://jmlr.org/proceedings/papers/v28/cortes13.pdf", "most_common": ["kernel", "margin", "learning", "multiple", "algorithm", "problem", "max", "algorithms", "based", "set", "kernels", "optimization", "also", "generalization", "lemma", "maximum", "following", "training", "hypothesis", "empirical", "binary", "bound", "results", "regularization", "min", "datasets", "using", "cortes", "new", "case", "let", "binarymkl", "sample", "complexity", "combination", "setting", "consider", "table", "machine", "given", "note", "performance", "accuracy", "points", "orabona", "rademacher", "denote", "multiclass", "linear", "two", "kumar", "thus", "analysis", "function", "vector", "uniform", "values", "holds", "choice", "inequality", "found", "large", "research", "base", "class", "obscure", "bounds", "present", "several", "well", "loss", "dataset", "line", "zien", "performs", "presented", "use", "mcmkl", "proof", "experiments", "including", "jie", "standard", "ong", "improvements", "classes", "notion", "written", "general", "theorem", "constraint", "icml", "mohri", "biological", "maximization", "section", "family", "labeled", "report", "number"], "authors": ["Corinna Cortes", "Mehryar Mohri", "Afshin Rostamizadeh"], "thumbnail_path": "thumbnails/MultiClass Classification with Maximum Margin Multiple Kernel.jpg"}, {"title": "Topdown particle filtering for Bayesian decision trees", "topics": [0.020101016392851643, 0.020101363921729488, 0.89905986762622547, 0.020530426574910748, 0.020104873317938053, 0.020102452166344865], "pdf_url": "http://jmlr.org/proceedings/papers/v28/lakshminarayanan13.pdf", "most_common": ["smc", "prior", "decision", "node", "tree", "trees", "bayesian", "optimal", "test", "number", "proposal", "data", "particles", "expansion", "cart", "learning", "algorithms", "distribution", "model", "log", "algorithm", "nodes", "mcmc", "section", "given", "accuracy", "input", "stage", "two", "performance", "set", "cut", "results", "particle", "posterior", "figure", "chipman", "labels", "probability", "one", "leaf", "islands", "dataset", "monte", "choice", "time", "existing", "sequential", "use", "space", "likelihood", "note", "predictive", "see", "resampling", "rule", "random", "proposals", "carlo", "work", "block", "machine", "mean", "layer", "split", "approach", "empirical", "kernel", "dimension", "inference", "density", "would", "similar", "represent", "per", "children", "let", "vectors", "particular", "process", "order", "considered", "points", "used", "dimensions", "methods", "function", "consider", "along", "leaves", "training", "values", "root", "produce", "chosen", "stopped", "shown", "many", "choices", "left"], "authors": ["Balaji Lakshminarayanan", "Daniel Roy", "Yee Whye Teh"], "thumbnail_path": "thumbnails/Topdown particle filtering for Bayesian decision trees.jpg"}, {"title": "CostSensitive Tree of Classifiers", "topics": [0.017326344624270719, 0.017326439725009839, 0.91336741841844493, 0.017326821477309257, 0.017326359711352775, 0.017326616043612672], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/xu13.pdf", "most_common": ["cost", "tree", "cstc", "feature", "features", "input", "learning", "node", "inputs", "data", "set", "weak", "function", "nodes", "use", "loss", "figure", "space", "expected", "risk", "training", "time", "chen", "path", "along", "terminal", "evaluation", "ndcg", "based", "extraction", "regression", "single", "learner", "two", "work", "one", "ranking", "expensive", "early", "validation", "yahoo", "cascade", "algorithms", "machine", "shows", "accuracy", "chapelle", "extracted", "optimization", "used", "obtain", "using", "algorithm", "global", "relaxation", "root", "high", "element", "every", "term", "linear", "performance", "penalty", "label", "however", "evaluate", "exit", "predictions", "synthetic", "exact", "large", "small", "therefore", "derive", "extract", "paths", "friedman", "cheap", "minimizing", "trees", "many", "case", "child", "nips", "weight", "weinberger", "test", "computation", "norm", "focus", "vector", "paper", "introduce", "rank", "reduce", "gradient", "boosting", "probability", "instances", "exactly"], "authors": ["Zhixiang Xu", "Matt Kusner", "Kilian Weinberger", "Minmin Chen"], "thumbnail_path": "thumbnails/CostSensitive Tree of Classifiers.jpg"}, {"title": "On the Statistical Consistency of Algorithms for Binary Classification under Class Imbalance", "topics": [0.017107606573963305, 0.017107731502724176, 0.91446152501704114, 0.017107724972064406, 0.017107752214744407, 0.017107659719462424], "pdf_url": "http://jmlr.org/proceedings/papers/v28/menon13a.pdf", "most_common": ["class", "loss", "algorithms", "imbalance", "data", "consistency", "balanced", "performance", "proper", "let", "erm", "probability", "logistic", "empirical", "examples", "distribution", "learning", "algorithm", "lemma", "see", "function", "losses", "methods", "sign", "training", "regret", "positive", "bal", "theorem", "statistical", "measure", "assumption", "conditions", "true", "regretd", "chawla", "smote", "used", "using", "strongly", "parameter", "table", "results", "undersample", "negative", "hinge", "empirically", "measures", "satisfying", "problem", "plugin", "binary", "supplementary", "square", "erd", "sample", "converges", "two", "cost", "use", "following", "machine", "sets", "regretam", "fprd", "since", "given", "standard", "tpr", "random", "fnrd", "settings", "decomposition", "estimator", "imbalanced", "denote", "functions", "material", "learned", "proof", "regularization", "optimal", "minority", "number", "one", "show", "threshold", "reid", "experiments", "case", "error", "agarwal", "follows", "respect", "williamson", "icml", "also", "synthetic", "large", "rate"], "authors": ["Aditya Menon", "Harikrishna Narasimhan", "Shivani Agarwal", "Sanjay Chawla"], "thumbnail_path": "thumbnails/On the Statistical Consistency of Algorithms for Binary Classification under Class Imbalance.jpg"}, {"title": "Quickly Boosting Decision Trees  Pruning Underachieving Features Early", "topics": [0.017340263673114652, 0.017340209113499677, 0.91329902832645515, 0.01734025755000991, 0.017339990658977476, 0.017340250677943349], "pdf_url": "http://jmlr.org/proceedings/papers/v28/appel13.pdf", "most_common": ["training", "boosting", "error", "features", "feature", "trees", "samples", "decision", "using", "computational", "cost", "subset", "test", "data", "figure", "optimal", "method", "preliminary", "stump", "learning", "best", "used", "adaboost", "given", "lazyboost", "loss", "trained", "weak", "quickly", "relative", "performance", "bound", "parameters", "following", "one", "heuristics", "vision", "conference", "boosted", "train", "use", "work", "sample", "machine", "order", "weight", "number", "note", "friedman", "computer", "methods", "weights", "large", "information", "based", "roc", "datasets", "mass", "subsets", "section", "schapire", "propose", "iteration", "stochasticboost", "see", "pattern", "many", "among", "without", "underachieving", "performing", "recognition", "fast", "algorithm", "time", "computation", "quick", "smaller", "threshold", "errors", "learner", "international", "speeding", "may", "experiments", "hence", "top", "points", "approach", "case", "lower", "proposed", "speed", "although", "three", "statistics", "curve", "even", "increasing", "larger"], "authors": ["Ron Appel", "Thomas Fuchs", "Piotr Dollar", "Pietro Perona"], "thumbnail_path": "thumbnails/Quickly Boosting Decision Trees  Pruning Underachieving Features Early.jpg"}, {"title": "TreeIndependent DualTree Algorithms", "topics": [0.018047517617755124, 0.018046106787439949, 0.90976752052571441, 0.018046429743520925, 0.018045989846809461, 0.018046435478760021], "pdf_url": "http://jmlr.org/proceedings/papers/v28/curtin13.pdf", "most_common": ["algorithm", "tree", "algorithms", "point", "traversal", "node", "pruning", "trees", "score", "basecase", "space", "given", "query", "neighbor", "search", "gray", "points", "reference", "distance", "nearest", "dpq", "cover", "max", "return", "two", "function", "npq", "dmin", "bound", "problem", "use", "implementation", "combination", "using", "nodes", "list", "one", "range", "used", "example", "machine", "kernel", "set", "density", "moore", "computation", "min", "march", "fast", "case", "lee", "base", "neighbors", "information", "systems", "entirely", "also", "learning", "addition", "thus", "tighter", "input", "output", "beygelzimer", "maximum", "bounded", "process", "minimum", "data", "types", "representation", "class", "simple", "conference", "processing", "dataset", "rule", "four", "section", "international", "visit", "therefore", "correctness", "implementations", "subtrees", "instead", "pruned", "denoted", "dmax", "prune", "neural", "distributed", "component", "however", "advances", "mlpack", "nips", "acm", "existing", "children"], "authors": ["Ryan Curtin", "William March", "Parikshit Ram", "David Anderson", "Alexander Gray", "Charles Isbell"], "thumbnail_path": "thumbnails/TreeIndependent DualTree Algorithms.jpg"}, {"title": "LossProportional Subsampling for Subsequent ERM", "topics": [0.023568445024718786, 0.023568835230299737, 0.88100379273262108, 0.023572278266657247, 0.024718939083720737, 0.023567709661982336], "pdf_url": "http://jmlr.org/proceedings/papers/v28/mineiro13.pdf", "most_common": ["pmin", "empirical", "subsample", "set", "subsampling", "data", "hypothesis", "risk", "let", "model", "training", "sampling", "sample", "learning", "erm", "linear", "strategy", "results", "used", "trigram", "bound", "dataset", "test", "large", "minimum", "constant", "subsequent", "using", "loss", "original", "step", "random", "compressing", "probability", "selection", "auprc", "instances", "inequality", "size", "label", "compression", "particular", "minimizer", "bernstein", "logistic", "variance", "true", "active", "hypotheses", "machine", "variables", "least", "performance", "class", "gbm", "distribution", "mean", "due", "regression", "initial", "function", "deviations", "single", "entire", "excess", "would", "work", "complexity", "frequent", "labels", "best", "however", "procedure", "neural", "examples", "prior", "via", "sonnenburg", "wrt", "language", "unknown", "fraction", "rate", "range", "achieves", "approach", "conference", "subsampled", "previous", "theorem", "deviation", "yields", "associated", "time", "technique", "second", "minimization", "known", "values", "information"], "authors": ["Paul Mineiro", "Nikos Karampatziakis"], "thumbnail_path": "thumbnails/LossProportional Subsampling for Subsequent ERM.jpg"}, {"title": "Saving Evaluation Time for the Decision Function in Boosting Representation and Reordering Base Learner", "topics": [0.019342913686176733, 0.019344226643085254, 0.90328293299076112, 0.019342909664656748, 0.019343111867040724, 0.019343905148279373], "pdf_url": "http://jmlr.org/proceedings/papers/v28/sun13.pdf", "most_common": ["base", "decision", "level", "bdd", "learner", "bvt", "reordering", "learners", "time", "function", "figure", "evaluation", "nodes", "data", "order", "acc", "representation", "node", "training", "dataset", "path", "boosting", "epl", "work", "tree", "paths", "section", "example", "binary", "one", "two", "testing", "right", "examples", "fastexit", "structure", "computer", "error", "conference", "sifting", "graph", "swapping", "boolean", "kim", "left", "possible", "results", "three", "following", "methods", "algorithm", "dacc", "case", "method", "complexity", "ieee", "dbvt", "see", "however", "learning", "previous", "either", "output", "interval", "pbe", "sign", "sort", "since", "length", "show", "dbp", "vision", "expression", "thus", "edges", "proposed", "sorting", "lead", "portion", "international", "exact", "chen", "therefore", "information", "machine", "natural", "paper", "propose", "shown", "matas", "red", "table", "black", "new", "set", "sochman", "using", "bottom", "volume", "cost"], "authors": ["Peng Sun", "Jie Zhou"], "thumbnail_path": "thumbnails/Saving Evaluation Time for the Decision Function in Boosting Representation and Reordering Base Learner.jpg"}, {"title": "Safe Screening of NonSupport Vectors in Pathwise SVM Computation", "topics": [0.019706072328799978, 0.019700196619424768, 0.90148128133945327, 0.019712602654007618, 0.019699837751264073, 0.019700009307050525], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ogawa13b.pdf", "most_common": ["screening", "rule", "svm", "pathwise", "computation", "solution", "solutions", "optimal", "sec", "training", "data", "safe", "algorithm", "total", "feasible", "vector", "vectors", "two", "screened", "figure", "instances", "set", "approach", "problem", "time", "would", "naive", "regularization", "heuristic", "rules", "cost", "computed", "points", "learning", "using", "computing", "machine", "lemma", "following", "compute", "consider", "path", "indicates", "note", "section", "corresponding", "used", "see", "support", "one", "also", "dual", "instance", "often", "function", "let", "must", "ith", "since", "linear", "lin", "kernel", "optimization", "prior", "journal", "sets", "bound", "line", "applied", "advantage", "solver", "upper", "values", "end", "paper", "idea", "tibshirani", "need", "experiments", "away", "table", "task", "scenario", "primal", "hastie", "results", "entire", "rate", "suggests", "chang", "four", "solving", "rough", "lagrange", "sequence", "problems", "nonsv", "fan", "smaller", "evaluated"], "authors": ["Kohei Ogawa", "Yoshiki Suzuki", "Ichiro Takeuchi"], "thumbnail_path": "thumbnails/Safe Screening of NonSupport Vectors in Pathwise SVM Computation.jpg"}, {"title": "Convex formulations of radiusmargin based Support Vector Machines", "topics": [0.021120781717606254, 0.021120874073868919, 0.89439415041502646, 0.02112197559111979, 0.021120892605492811, 0.021121325596885791], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/do13.pdf", "most_common": ["radius", "svm", "feature", "selection", "approximation", "based", "learning", "optimization", "error", "two", "margin", "problem", "new", "convex", "data", "better", "bound", "linear", "also", "algorithms", "space", "vector", "instances", "used", "ratio", "sphere", "given", "one", "support", "sum", "features", "number", "metric", "since", "using", "performance", "function", "use", "maxk", "however", "value", "formulations", "spread", "datasets", "algorithm", "machines", "diagonal", "machine", "section", "show", "min", "problems", "results", "directly", "smallest", "transformation", "constraint", "original", "therefore", "control", "measure", "standard", "distance", "maximum", "corresponds", "solve", "cost", "selected", "method", "work", "following", "weighting", "scaling", "squared", "rmm", "kernel", "set", "thus", "uses", "transformed", "sparsity", "equivalent", "optimize", "formulation", "compared", "variable", "kernelized", "vapnik", "second", "score", "kalousis", "propose", "matrix", "svmrfe", "pairwise", "note", "class", "controls", "see", "several"], "authors": ["Huyen Do", "Alexandros Kalousis"], "thumbnail_path": "thumbnails/Convex formulations of radiusmargin based Support Vector Machines.jpg"}, {"title": "The Pairwise PiecewiseLinear Embedding for Efficient NonLinear Classification", "topics": [0.01885227974211089, 0.018855719530837863, 0.90573596450629168, 0.018852629066329205, 0.018851626288844587, 0.018851780865585598], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/pele13.pdf", "most_common": ["embedding", "linear", "features", "feature", "rbf", "using", "method", "methods", "second", "pairwise", "kernel", "see", "order", "also", "kernels", "time", "vector", "number", "model", "used", "outperformed", "datasets", "results", "values", "data", "training", "learning", "interpolation", "function", "chang", "polynomial", "irrelevant", "functions", "complexity", "set", "value", "learned", "use", "accuracy", "section", "resulting", "lin", "maji", "embeddings", "discretization", "single", "relationships", "pairs", "explicit", "dataset", "shows", "points", "approach", "approximate", "proposed", "finally", "two", "figure", "vedaldi", "one", "poly", "much", "vectors", "pele", "test", "algorithm", "spectf", "terms", "additive", "work", "werman", "zisserman", "exactly", "modeling", "piecewise", "thus", "several", "robust", "log", "segment", "covtype", "compared", "large", "discrete", "consistently", "degree", "highly", "parameters", "space", "given", "continuous", "experimental", "table", "described", "protein", "extensive", "possible", "sparse", "added", "linearly"], "authors": ["Ofir Pele", "Ben Taskar", "Amir Globerson", "Michael Werman"], "thumbnail_path": "thumbnails/The Pairwise PiecewiseLinear Embedding for Efficient NonLinear Classification.jpg"}, {"title": "Spectral Learning of Hidden Markov Models from Dynamic and Static Data", "topics": [0.018698219934194488, 0.01869837273714664, 0.90650832046059548, 0.01869850800248013, 0.018698252098643328, 0.018698326766939815], "pdf_url": "http://jmlr.org/proceedings/papers/v28/huang13.pdf", "most_common": ["data", "dynamic", "learning", "static", "matrix", "spectral", "proposed", "time", "estimator", "observation", "hidden", "points", "estimation", "singular", "observations", "markov", "models", "method", "set", "stationary", "distribution", "prediction", "algorithms", "kernel", "sequence", "following", "probability", "estimates", "use", "term", "testing", "column", "song", "section", "values", "also", "left", "using", "denote", "hmms", "figure", "regularization", "experiments", "space", "squared", "denotes", "estimate", "one", "based", "observable", "obtain", "methods", "algorithm", "discrete", "vectors", "propose", "series", "min", "parameters", "solve", "convex", "form", "similar", "proceedings", "vector", "international", "feature", "machine", "may", "representation", "number", "continuous", "objective", "siddiqi", "state", "let", "conference", "hmm", "optimization", "error", "activities", "matrices", "solution", "takes", "imu", "rank", "median", "predictive", "arg", "hilbert", "consists", "vec", "terms", "better", "diag", "shown", "transition", "top", "performance", "fact"], "authors": ["Tzu-Kuo Huang", "Jeff Schneider"], "thumbnail_path": "thumbnails/Spectral Learning of Hidden Markov Models from Dynamic and Static Data.jpg"}, {"title": "Learning Linear Bayesian Networks with Latent Variables", "topics": [0.017330361028722912, 0.017330480629942753, 0.91333010890095112, 0.017335280015298112, 0.01733064555260606, 0.017343123872479133], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/anandkumar13.pdf", "most_common": ["hidden", "matrix", "variables", "observed", "model", "latent", "nodes", "dag", "learning", "models", "one", "linear", "dags", "graph", "condition", "second", "let", "set", "property", "expansion", "depth", "structure", "order", "anandkumar", "moment", "bayesian", "rank", "also", "networks", "algorithm", "topic", "columns", "using", "consider", "denote", "independent", "noise", "parameter", "diagonal", "see", "result", "conditions", "theorem", "learn", "among", "described", "distribution", "results", "section", "new", "third", "levels", "probability", "number", "part", "graphical", "problem", "vectors", "edges", "directed", "variable", "relationships", "method", "full", "use", "following", "recovery", "spielman", "tree", "class", "graphs", "random", "joint", "estimation", "topics", "methods", "maximum", "via", "causal", "work", "algorithms", "paper", "induced", "dictionary", "assumption", "jmlr", "terms", "convex", "without", "moments", "core", "hsu", "column", "dependence", "rows", "genericity", "node", "correlated", "eca", "component"], "authors": ["Animashree Anandkumar", "Daniel Hsu", ""], "thumbnail_path": "thumbnails/Learning Linear Bayesian Networks with Latent Variables.jpg"}, {"title": "Spectral Experts for Estimating Mixtures of Linear Regressions", "topics": [0.020543311405014864, 0.020543778312640818, 0.89728279141785539, 0.020543353139684053, 0.020543037032997445, 0.020543728691807601], "pdf_url": "http://jmlr.org/proceedings/papers/v28/tejasvichaganty13.pdf", "most_common": ["spectral", "parameters", "experts", "tensor", "regression", "algorithm", "linear", "mixture", "let", "parameter", "moments", "data", "error", "noise", "using", "learning", "model", "norm", "estimates", "compound", "regressions", "models", "denote", "hsu", "recover", "anandkumar", "matrix", "estimate", "random", "local", "cvec", "power", "bound", "operator", "section", "method", "discriminative", "work", "information", "recovery", "number", "set", "lemma", "neural", "consistent", "balle", "use", "two", "three", "def", "factorization", "symmetric", "tensors", "systems", "kakade", "processing", "nips", "advances", "results", "tomioka", "figure", "regularization", "singular", "cambridge", "order", "shows", "given", "mit", "observation", "latent", "estimation", "conference", "robust", "components", "theorem", "convex", "computational", "log", "function", "true", "consider", "zero", "initialized", "estimated", "component", "proof", "known", "machine", "max", "restricted", "least", "strengths", "average", "tong", "viele", "optimization", "perform", "follows", "performing", "actual"], "authors": ["Arun Tejasvi Chaganty", "Percy Liang"], "thumbnail_path": "thumbnails/Spectral Experts for Estimating Mixtures of Linear Regressions.jpg"}, {"title": "On learning parametricoutput HMMs", "topics": [0.018014322458146905, 0.018014347290308937, 0.90992773226813617, 0.01801441157026764, 0.018014235606648901, 0.018014950806491441], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kontorovich13.pdf", "most_common": ["output", "learning", "hidden", "matrix", "parameters", "given", "markov", "hmm", "distribution", "stationary", "discrete", "hmms", "case", "exact", "known", "mixture", "aij", "estimating", "transition", "estimate", "number", "estimated", "following", "approach", "problem", "sequence", "state", "continuous", "error", "convex", "algorithm", "assume", "probabilities", "states", "analysis", "parametric", "quadratic", "consider", "assumption", "probability", "entries", "solution", "let", "via", "two", "assumptions", "since", "shows", "size", "note", "observed", "general", "thus", "theorem", "whose", "section", "standard", "see", "computationally", "iterations", "model", "initial", "chain", "results", "program", "likelihood", "rank", "one", "construct", "also", "estimator", "estimators", "time", "large", "vector", "small", "full", "kontorovich", "next", "sample", "science", "instead", "may", "complexity", "algorithms", "constraints", "observations", "random", "computer", "asymptotically", "empirical", "samples", "log", "approximate", "cij", "distributions", "models", "norm", "estimates", "method"], "authors": ["Aryeh Kontorovich", ""], "thumbnail_path": "thumbnails/On learning parametricoutput HMMs.jpg"}, {"title": "Tensor Analyzers", "topics": [0.018051290196912685, 0.018051300100097516, 0.90974383583390039, 0.018051152826655207, 0.018051124716582195, 0.018051296325851972], "pdf_url": "http://jmlr.org/proceedings/papers/v28/tang13.pdf", "most_common": ["factor", "tensor", "model", "training", "images", "test", "data", "using", "factors", "learning", "used", "analyzers", "tas", "face", "image", "lighting", "group", "latent", "posterior", "inference", "log", "recognition", "one", "also", "samples", "mta", "equality", "subjects", "mixture", "sampling", "mfa", "per", "groups", "number", "constraints", "bilinear", "matrix", "interactions", "new", "distribution", "models", "algorithm", "parameters", "use", "values", "tucker", "mtas", "decomposition", "fas", "natural", "linear", "gibbs", "analysis", "nats", "subject", "modeling", "identity", "loading", "patches", "multilinear", "vector", "allows", "hinton", "learn", "example", "figure", "better", "loadings", "set", "conditioned", "compared", "components", "density", "methods", "single", "code", "computation", "row", "alternating", "order", "gaussian", "given", "experiments", "human", "multiplicative", "panel", "statistics", "function", "prior", "contains", "two", "wang", "machine", "shows", "likelihood", "generative", "probabilistic", "average", "see", "simple"], "authors": ["Yichuan Tang", "Ruslan Salakhutdinov", ""], "thumbnail_path": "thumbnails/Tensor Analyzers.jpg"}, {"title": "Unfolding Latent Tree Structures using th Order Tensors", "topics": [0.017583064166473976, 0.017583646030587145, 0.91208032515087745, 0.017584735520840299, 0.017584788055667284, 0.017583441075553891], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ishteva13.pdf", "most_common": ["latent", "quartet", "tree", "variables", "algorithm", "number", "hidden", "rank", "using", "states", "size", "sample", "recovery", "spectral", "order", "correct", "probability", "phg", "test", "based", "nuclear", "structures", "tensor", "structure", "norm", "relations", "observed", "learning", "dependence", "condition", "see", "tensors", "conditions", "variable", "two", "matrix", "case", "singular", "trees", "approach", "consistent", "method", "since", "perturbation", "given", "methods", "models", "pearl", "anandkumar", "joint", "best", "unfolding", "diag", "note", "table", "properties", "assume", "large", "machine", "stock", "however", "metric", "proposed", "theorem", "log", "design", "use", "values", "guarantee", "independence", "one", "percentage", "also", "relation", "samples", "value", "grouping", "journal", "compared", "matrices", "discover", "marginal", "appendix", "algorithms", "used", "distance", "lemma", "factorization", "corresponding", "cross", "model", "tarsi", "groupings", "resolving", "focus", "research", "discovering", "small", "even", "international"], "authors": ["Mariya Ishteva", "Haesun Park", "Le Song"], "thumbnail_path": "thumbnails/Unfolding Latent Tree Structures using th Order Tensors.jpg"}, {"title": "Hierarchical Tensor Decomposition of Latent Tree Graphical Models", "topics": [0.02259975660870599, 0.022600038278725986, 0.88699904759844828, 0.022599941768951429, 0.022599866332294813, 0.02260134941287352], "pdf_url": "http://jmlr.org/proceedings/papers/v28/song13.pdf", "most_common": ["tree", "rank", "latent", "decomposition", "tensor", "hierarchical", "spectral", "models", "graphical", "new", "algorithms", "variables", "low", "algorithm", "sample", "matrix", "error", "model", "observed", "training", "size", "according", "approximation", "probability", "problem", "number", "previous", "theorem", "matricizations", "hidden", "optimization", "edge", "using", "matrices", "let", "joint", "reshape", "set", "obtain", "factors", "global", "singular", "order", "show", "based", "marginal", "equation", "states", "recursively", "parameters", "tensors", "corresponding", "modes", "special", "random", "best", "case", "edges", "form", "parikh", "variable", "structure", "original", "song", "markov", "use", "two", "recursive", "estimating", "furthermore", "decompose", "linker", "points", "view", "learning", "general", "analysis", "also", "hsu", "computational", "foster", "second", "collection", "data", "complexity", "primary", "framework", "one", "given", "instance", "objective", "result", "approach", "terms", "however", "value", "longer", "exponential", "cases", "proof"], "authors": ["Le Song", ""], "thumbnail_path": "thumbnails/Hierarchical Tensor Decomposition of Latent Tree Graphical Models.jpg"}, {"title": "Infinite Positive Semidefinite Tensor Factorization with Application to Music Signal Analysis", "topics": [0.017581476683173773, 0.017583939216582922, 0.91208758083620156, 0.017579953125476014, 0.017583726051115755, 0.017583324087450253], "pdf_url": "http://jmlr.org/proceedings/papers/v28/yoshii13.pdf", "most_common": ["matrix", "factorization", "hkn", "log", "psd", "tensor", "model", "given", "bayesian", "positive", "divergence", "matrices", "music", "nonnegative", "psdtf", "number", "using", "data", "follows", "bases", "gaussian", "observed", "basis", "used", "figure", "bregman", "prior", "probabilistic", "distribution", "signal", "gamma", "problem", "wishart", "audio", "signals", "extension", "xnk", "called", "process", "frequency", "likelihood", "variational", "set", "results", "nmf", "constraint", "models", "natural", "nonparametric", "since", "one", "viewed", "note", "case", "covariance", "lower", "eeg", "convex", "decomposition", "posterior", "update", "algorithm", "calculate", "zero", "reconstruction", "latent", "fourier", "use", "goal", "derive", "domain", "based", "identity", "analysis", "proposed", "source", "multiplicative", "often", "bound", "gig", "function", "priors", "special", "assume", "vector", "variables", "cost", "diag", "section", "method", "component", "vectors", "following", "paper", "propose", "term", "related", "place", "nonnegativity", "sounds"], "authors": ["Kazuyoshi Yoshii", "Ryota Tomioka", "Daichi Mochihashi", "Masataka Goto"], "thumbnail_path": "thumbnails/Infinite Positive Semidefinite Tensor Factorization with Application to Music Signal Analysis.jpg"}, {"title": "Optimal Regret Bounds for Selecting the State Representation in Reinforcement Learning", "topics": [0.017845634440022237, 0.017845684853593762, 0.91077072113944235, 0.017846107883914629, 0.017846176644557277, 0.017845675038469764], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/maillard13.pdf", "most_common": ["model", "models", "time", "algorithm", "optimal", "number", "state", "markov", "log", "regret", "mdp", "probability", "oms", "learning", "set", "reward", "bound", "one", "rewards", "let", "optimistic", "jaksch", "policy", "average", "rtk", "reinforcement", "episode", "term", "since", "transition", "run", "test", "total", "process", "may", "episodes", "higher", "markovian", "given", "atk", "admissible", "runs", "line", "problem", "current", "states", "get", "note", "terms", "thus", "using", "steps", "environment", "discrete", "mdps", "section", "diameter", "high", "representation", "blb", "first", "observations", "step", "research", "tewari", "action", "following", "control", "machine", "parameter", "space", "maillard", "several", "least", "performance", "considered", "ryabko", "however", "bartlett", "setting", "theorem", "deduce", "pen", "dependence", "general", "hutter", "visits", "assume", "new", "use", "next", "agent", "end", "order", "chosen", "inequality", "false", "also", "pair", "observation"], "authors": ["Odalric-Ambrym Maillard", "Phuong Nguyen", "Ronald Ortner", "Daniil Ryabko"], "thumbnail_path": "thumbnails/Optimal Regret Bounds for Selecting the State Representation in Reinforcement Learning.jpg"}, {"title": "Combinatorial MultiArmed Bandit General Framework Results and Applications", "topics": [0.02179324966537172, 0.021795345627694297, 0.89098402331349436, 0.021822233310078498, 0.021811921373048982, 0.021793226710312072], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/chen13a.pdf", "most_common": ["arm", "arms", "super", "reward", "regret", "bandit", "algorithm", "combinatorial", "problem", "framework", "cmab", "round", "outcomes", "oracle", "set", "played", "one", "bound", "linear", "general", "number", "function", "applications", "mab", "expected", "online", "random", "min", "bounded", "let", "analysis", "rounds", "approximation", "expectation", "learning", "problems", "optimal", "cucb", "variable", "vector", "social", "may", "probability", "unknown", "playing", "bad", "classical", "class", "results", "bandits", "maximization", "nonlinear", "gai", "theorem", "two", "pmc", "provide", "smoothness", "underlying", "nodes", "large", "work", "play", "edge", "variables", "rewards", "instance", "simple", "due", "value", "advertisement", "distributions", "consider", "activated", "auer", "section", "studied", "total", "takes", "information", "max", "submodular", "since", "notice", "outcome", "thus", "web", "also", "adversarial", "much", "fraction", "maximum", "tight", "setting", "stochastic", "case", "probabilities", "following", "end", "computation"], "authors": ["Wei Chen", "Yajun Wang", "Yang Yuan"], "thumbnail_path": "thumbnails/Combinatorial MultiArmed Bandit General Framework Results and Applications.jpg"}, {"title": "Dynamical Models and tracking regret in online convex programming", "topics": [0.021383786156631106, 0.021381753923509082, 0.89307627980971716, 0.021392106581428795, 0.021383773031049109, 0.021382300497664656], "pdf_url": "http://jmlr.org/proceedings/papers/v28/hall13.pdf", "most_common": ["regret", "dynamical", "tracking", "dynamic", "model", "comparator", "loss", "sequence", "models", "time", "online", "bounds", "static", "mirror", "descent", "best", "using", "algorithm", "let", "dfs", "methods", "dmd", "prediction", "convex", "learning", "bound", "data", "however", "complexity", "set", "min", "performance", "relative", "shifting", "denote", "dynamics", "term", "observations", "optimization", "lugosi", "low", "method", "social", "dmax", "figure", "share", "algorithms", "paper", "series", "corresponds", "uses", "comid", "follows", "predictions", "known", "regularization", "network", "fixed", "approach", "respect", "well", "proposed", "theorem", "function", "deviation", "consider", "small", "family", "particular", "following", "ieee", "used", "adaptive", "individual", "class", "regularized", "new", "forecaster", "underlying", "also", "scale", "log", "switches", "stochastic", "novel", "strong", "use", "instead", "max", "number", "divergence", "motion", "warmuth", "see", "bregman", "typically", "knowledge", "lemma", "terms", "much"], "authors": ["Eric Hall", "Rebecca Willett"], "thumbnail_path": "thumbnails/Dynamical Models and tracking regret in online convex programming.jpg"}, {"title": "Better Rates for Any Adversarial Deterministic MDPs", "topics": [0.016670641235442825, 0.01667087720360692, 0.91664538320357525, 0.016670953600224692, 0.016671413073897922, 0.016670731683252595], "pdf_url": "http://jmlr.org/proceedings/papers/v28/dekel13.pdf", "most_common": ["loss", "state", "graph", "player", "algorithm", "connected", "strongly", "regret", "path", "deterministic", "assumption", "bsp", "admdp", "decision", "edge", "cycle", "length", "one", "adversarial", "vertices", "problem", "steps", "game", "two", "epoch", "mdp", "edges", "adversary", "vertex", "let", "policy", "bandit", "assume", "transition", "sequence", "markov", "component", "better", "previous", "theorem", "stochastic", "states", "transitions", "research", "note", "set", "best", "period", "without", "functions", "losses", "contains", "rates", "graphs", "learning", "since", "therefore", "feedback", "cyclic", "online", "aperiodic", "reduction", "bound", "environment", "new", "outgoing", "must", "recall", "information", "add", "rbsp", "every", "prove", "radmdp", "work", "example", "assumptions", "rather", "chosen", "words", "exists", "denote", "see", "actions", "step", "called", "implies", "time", "section", "sequential", "next", "cycles", "making", "starts", "rewards", "exactly", "generality", "also", "random", "common"], "authors": ["Ofer Dekel", "Elad Hazan"], "thumbnail_path": "thumbnails/Better Rates for Any Adversarial Deterministic MDPs.jpg"}, {"title": "Multiple Identifications in MultiArmed Bandits", "topics": [0.028104053912781403, 0.028105383914704629, 0.85947513477345727, 0.028104120132812663, 0.028106900144231822, 0.0281044071220121], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/bubeck13.pdf", "most_common": ["arm", "arms", "problem", "best", "sar", "algorithm", "empirical", "one", "experiment", "let", "evaluations", "complexity", "active", "error", "rejects", "phase", "accepts", "agent", "multiple", "audibert", "mean", "probability", "successive", "bandits", "event", "top", "means", "strategy", "gabillon", "single", "type", "figure", "set", "setting", "bubeck", "accepted", "log", "denote", "section", "following", "end", "order", "budget", "distributions", "assume", "max", "gaps", "number", "see", "note", "also", "experiments", "last", "bandit", "uni", "learning", "analysis", "theorem", "using", "introduced", "bound", "highest", "consider", "new", "proof", "stage", "parameter", "paper", "proceedings", "notation", "bad", "among", "conference", "proposed", "identify", "slightly", "exploration", "requires", "focus", "induction", "uniform", "groups", "logarithmic", "makes", "prove", "particular", "idea", "since", "denoted", "latter", "measures", "exp", "show", "factor", "distribution", "faces", "sampling", "corresponding", "pac", "introduce"], "authors": ["Sebastian Bubeck", "Tengyao Wang", "Nitin Viswanathan"], "thumbnail_path": "thumbnails/Multiple Identifications in MultiArmed Bandits.jpg"}, {"title": "Gossipbased distributed stochastic bandit algorithms", "topics": [0.019380962031431002, 0.019381118648517853, 0.90309369033432862, 0.019381544006530593, 0.019381193680676027, 0.019381491298515737], "pdf_url": "http://jmlr.org/proceedings/papers/v28/szorenyi13.pdf", "most_common": ["arm", "peer", "round", "algorithm", "regret", "bandit", "number", "log", "let", "algorithms", "peers", "reward", "rewards", "arms", "two", "lemma", "model", "stochastic", "auer", "merge", "network", "section", "distributed", "protocol", "bound", "plays", "iteration", "expected", "using", "communication", "term", "random", "information", "main", "probability", "based", "problem", "neighbors", "second", "setup", "proof", "experiments", "jelasity", "perfectoverlay", "rounds", "terms", "learning", "newscast", "used", "analysis", "step", "node", "results", "large", "sum", "theoretical", "messages", "goal", "one", "show", "version", "best", "variance", "also", "models", "assume", "time", "upper", "estimates", "example", "use", "slim", "fully", "linear", "rate", "networks", "set", "computer", "see", "sends", "would", "consider", "bandits", "every", "vector", "decentralized", "work", "following", "delay", "suboptimal", "langford", "performance", "accuracy", "paper", "result", "received", "last", "receives", "error", "european"], "authors": ["Balazs Szorenyi", "Robert Busa-Fekete", "Istvan Hegedus", "Robert Ormandi", "Mark Jelasity", "Balazs Kegl"], "thumbnail_path": "thumbnails/Gossipbased distributed stochastic bandit algorithms.jpg"}, {"title": "Dual Averaging and Proximal Gradient Descent for Online Alternating Direction Multiplier Method", "topics": [0.082896909730066998, 0.018734987772434885, 0.84213782291402794, 0.018760239323481115, 0.018735085503369872, 0.01873495475661912], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/suzuki13.pdf", "most_common": ["admm", "convergence", "online", "proximal", "method", "learning", "optimization", "dual", "function", "update", "also", "loss", "rda", "regularization", "operation", "gradient", "averaging", "risk", "group", "rate", "descent", "convex", "methods", "algorithm", "stochastic", "machine", "linear", "set", "expected", "opg", "show", "lasso", "alternating", "structured", "direction", "step", "argmin", "vector", "data", "moreover", "corresponding", "proposed", "overlapped", "regularized", "rule", "algorithms", "weight", "one", "pair", "however", "regularizations", "section", "let", "following", "term", "new", "see", "analysis", "two", "constant", "time", "graph", "averaged", "type", "applications", "experiments", "batch", "matrix", "log", "features", "size", "achieves", "exists", "multiplier", "problem", "much", "samples", "observe", "error", "follows", "sparsity", "processing", "constraint", "strongly", "original", "large", "standard", "optimal", "used", "iteration", "approach", "yuan", "theorem", "sparse", "supplementary", "journal", "compute", "general", "generated", "assume"], "authors": ["Taiji Suzuki"], "thumbnail_path": "thumbnails/Dual Averaging and Proximal Gradient Descent for Online Alternating Direction Multiplier Method.jpg"}, {"title": "Learning from HumanGenerated Lists", "topics": [0.017160111188976385, 0.017160617936047, 0.91419287154307494, 0.017160759543099039, 0.017161369739694163, 0.017164270049108456], "pdf_url": "http://jmlr.org/proceedings/papers/v28/jun13.pdf", "most_common": ["feature", "learning", "swirl", "list", "lists", "patients", "item", "human", "features", "sampling", "order", "items", "task", "volunteering", "machine", "class", "one", "corpus", "color", "volunteered", "model", "using", "log", "labels", "category", "text", "verbal", "distribution", "distributions", "two", "training", "sports", "webkb", "healthy", "data", "label", "parameters", "prior", "cognitive", "example", "likelihood", "size", "show", "set", "let", "replacement", "participants", "section", "figure", "university", "estimate", "probability", "reference", "table", "settles", "unlabeled", "without", "idp", "models", "vehicles", "animals", "multinomial", "balls", "work", "movies", "labeled", "may", "semantic", "generate", "length", "given", "dogs", "exp", "controls", "words", "conference", "druck", "methods", "even", "use", "word", "applications", "experiments", "domain", "hypergeometric", "bayes", "documents", "proceedings", "expectation", "mle", "baseline", "patient", "ball", "instance", "follows", "form", "maximum", "ordered", "priors", "application"], "authors": ["Kwang-Sung Jun", "Jerry Zhu", "Burr Settles", "Timothy Rogers"], "thumbnail_path": "thumbnails/Learning from HumanGenerated Lists.jpg"}, {"title": "A Structural SVM Based Approach for Optimizing Partial AUC", "topics": [0.020813703180690313, 0.020813643373363645, 0.89593179004953849, 0.020813790318321319, 0.020813536211899977, 0.020813536866186165], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/narasimhan13.pdf", "most_common": ["auc", "partial", "positive", "optimizing", "negative", "false", "optimization", "joachims", "range", "svm", "instances", "structural", "problem", "algorithm", "curve", "fpr", "data", "method", "approach", "roc", "based", "case", "ranking", "used", "using", "learning", "area", "one", "performance", "machine", "number", "vector", "scoring", "svmpauc", "given", "ordering", "set", "table", "time", "results", "matrix", "training", "proceedings", "violated", "constraint", "international", "values", "complexity", "instance", "terms", "conference", "two", "form", "rate", "full", "plane", "algorithms", "cutting", "top", "empirical", "maximizing", "computational", "svmauc", "following", "figure", "information", "applications", "shown", "random", "argmax", "agarwal", "support", "function", "research", "solution", "sum", "orderings", "combinatorial", "linear", "note", "section", "see", "corresponding", "several", "documents", "pauc", "loss", "general", "journal", "represented", "search", "particular", "sample", "feature", "evaluation", "rank", "mining", "accuracy", "usual", "however"], "authors": ["Harikrishna Narasimhan", "Shivani Agarwal"], "thumbnail_path": "thumbnails/A Structural SVM Based Approach for Optimizing Partial AUC.jpg"}, {"title": "A Machine Learning Framework for Programming by Example", "topics": [0.017893828647220038, 0.017893731215034538, 0.91052842662135181, 0.017894063063965609, 0.01789388974173781, 0.017896060710690258], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/menon13.pdf", "most_common": ["learning", "example", "program", "rules", "input", "system", "functions", "may", "programs", "list", "search", "clues", "one", "examples", "programming", "inference", "training", "set", "function", "features", "rule", "pbe", "timeout", "would", "clue", "framework", "grammar", "using", "gulwani", "probability", "machine", "based", "also", "output", "processing", "string", "given", "baseline", "user", "figure", "text", "ranking", "like", "time", "consistent", "data", "number", "pair", "problem", "general", "strings", "every", "parameters", "systems", "model", "constant", "learned", "two", "textual", "transformation", "line", "whether", "describe", "weights", "tasks", "probabilities", "work", "learn", "used", "suggesting", "base", "compositions", "another", "likely", "error", "approach", "previous", "prototype", "certain", "force", "even", "section", "dedup", "suggests", "use", "feature", "explains", "earlier", "interesting", "operation", "could", "common", "suggested", "many", "table", "corresponding", "task", "speed", "brute", "count"], "authors": ["Aditya Menon", "Omer Tamuz", "Sumit Gulwani", "Butler Lampson", "Adam Kalai"], "thumbnail_path": "thumbnails/A Machine Learning Framework for Programming by Example.jpg"}, {"title": "Convex Adversarial Collective Classification", "topics": [0.018021531105509643, 0.018021555079535151, 0.90989192838657951, 0.018021599177119017, 0.018021429624367896, 0.018021956626888793], "pdf_url": "http://jmlr.org/proceedings/papers/v28/torkamani13.pdf", "most_common": ["adversarial", "adversary", "xij", "collective", "learning", "amn", "cacc", "data", "program", "markov", "machine", "convex", "taskar", "yij", "model", "variables", "error", "nodes", "strength", "number", "one", "set", "also", "label", "methods", "blogs", "since", "linear", "proceedings", "problem", "used", "adversaries", "integral", "similar", "weights", "dataset", "labels", "words", "conference", "web", "test", "feature", "zij", "features", "networks", "attributes", "political", "robust", "quadratic", "lowd", "svm", "time", "synthetic", "classification", "example", "links", "order", "associative", "svminv", "amns", "using", "acm", "constraints", "spam", "models", "likely", "section", "relational", "objects", "use", "positive", "work", "information", "may", "labeling", "network", "based", "margin", "two", "class", "distribution", "international", "solution", "teo", "reuters", "inference", "experiments", "tuned", "training", "given", "knowledge", "discovery", "many", "present", "roweis", "obtain", "globerson", "performance", "replace", "equivalent"], "authors": ["Mohamad Ali Torkamani", "Daniel Lowd"], "thumbnail_path": "thumbnails/Convex Adversarial Collective Classification.jpg"}, {"title": "Learning Convex QP Relaxations for Structured Prediction", "topics": [0.013397462969075517, 0.013397596258098788, 0.93301084112515209, 0.013397585502895153, 0.013397637933915182, 0.013398876210863331], "pdf_url": "http://jmlr.org/proceedings/papers/v28/jancsary13.pdf", "most_common": ["learning", "model", "convex", "training", "lrf", "inference", "loss", "relaxation", "random", "energy", "relaxations", "parameters", "quadratic", "test", "results", "prediction", "one", "structured", "approach", "using", "use", "problem", "variables", "programming", "large", "table", "exact", "pairwise", "graphical", "models", "discriminative", "matrices", "even", "obtained", "since", "tree", "margin", "input", "predictions", "dual", "used", "computational", "figure", "order", "logistic", "methods", "ensure", "formulation", "via", "trained", "map", "directly", "matting", "task", "joachims", "labels", "nowozin", "baseline", "window", "experiment", "predictive", "ravikumar", "jmlr", "joint", "dtf", "estimation", "moreover", "binary", "uses", "unary", "form", "icml", "finley", "time", "small", "cost", "train", "regularization", "forest", "parameter", "chunking", "data", "still", "fij", "labeling", "gradient", "wainwright", "interaction", "objective", "hamming", "see", "label", "terms", "weak", "tappen", "two", "minimize", "lead", "approximate", "consider"], "authors": ["Jeremy Jancsary", "Sebastian Nowozin", "Carsten Rother"], "thumbnail_path": "thumbnails/Learning Convex QP Relaxations for Structured Prediction.jpg"}, {"title": "FixedPoint Model For Structured Labeling", "topics": [0.019303384872071491, 0.019306996379118178, 0.90347727199090067, 0.019304653776097139, 0.019303744807524378, 0.019303948174288117], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/li13b.pdf", "most_common": ["model", "structured", "labeling", "training", "function", "contraction", "qni", "models", "prediction", "used", "crf", "contextual", "train", "input", "use", "testing", "condition", "regression", "learning", "process", "feature", "number", "average", "layered", "proposed", "output", "nodes", "vector", "error", "node", "table", "mapping", "data", "also", "ocr", "logistic", "using", "range", "problem", "replica", "algorithm", "random", "errors", "features", "guo", "small", "method", "nguyen", "dataset", "performance", "markov", "outputs", "may", "paper", "svmstruct", "linear", "one", "bai", "label", "modeling", "character", "much", "value", "thus", "long", "functions", "svm", "graph", "stable", "norm", "taskar", "neighborhood", "trained", "perceptron", "takes", "compare", "machine", "since", "given", "labels", "kernel", "contexts", "status", "pos", "methods", "sequence", "conditional", "denote", "assume", "keerthi", "learned", "sle", "equation", "algorithms", "hypertext", "research", "heitz", "exp", "jfi", "simple"], "authors": ["Quannan Li", "Jingdong Wang", "David Wipf", "Zhuowen Tu"], "thumbnail_path": "thumbnails/FixedPoint Model For Structured Labeling.jpg"}, {"title": "A Generalized Kernel Approach to Structured Output Learning", "topics": [0.018011535480556933, 0.018011535859219309, 0.90994219259424824, 0.018011674329795203, 0.018011501094713101, 0.01801156064146734], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kadri13.pdf", "most_common": ["kernel", "kde", "output", "kernels", "space", "learning", "feature", "structured", "problem", "covariance", "cortes", "input", "approach", "using", "regression", "formulation", "mapping", "conditional", "weston", "joint", "outputs", "data", "operator", "use", "account", "training", "method", "used", "methods", "prediction", "machine", "associated", "kadri", "allows", "table", "jkm", "generalized", "functional", "algorithm", "vector", "rkhs", "take", "proposed", "research", "functions", "problems", "information", "algorithms", "number", "show", "results", "image", "cholesky", "compare", "provide", "spaces", "arg", "min", "general", "consider", "two", "operators", "following", "map", "order", "paper", "since", "also", "performance", "based", "evaluate", "operatorvalued", "dependency", "mean", "structure", "computation", "taskar", "variant", "caponnetto", "complex", "matrix", "dependencies", "character", "see", "note", "incomplete", "pontil", "taking", "faces", "case", "trick", "rbf", "identity", "loss", "images", "recognition", "decomposition", "ridge", "way", "function"], "authors": ["Hachem Kadri", "Mohammad Ghavamzadeh", "Philippe Preux"], "thumbnail_path": "thumbnails/A Generalized Kernel Approach to Structured Output Learning.jpg"}, {"title": "Optimizing the Fmeasure in Multilabel Classification Plugin Rule Approach versus Structured Loss Minimization", "topics": [0.015925510745251906, 0.015925510455586527, 0.92037259874381505, 0.015925532173613727, 0.015925374628823697, 0.015925473252909106], "pdf_url": "http://jmlr.org/proceedings/papers/v28/dembczynski13.pdf", "most_common": ["loss", "rule", "labels", "results", "max", "rml", "training", "approach", "number", "arg", "caetano", "bayes", "label", "petterson", "algorithm", "given", "structured", "set", "minimization", "methods", "problem", "multinomial", "optimizing", "sml", "however", "learning", "inference", "prediction", "method", "let", "one", "parameters", "logistic", "function", "estimates", "approaches", "maximization", "efp", "distribution", "regression", "vector", "may", "lfp", "use", "two", "since", "log", "binary", "surrogate", "using", "solution", "consistent", "obtained", "times", "probability", "best", "terms", "reduction", "model", "also", "general", "consider", "therefore", "following", "table", "machine", "optimal", "parameter", "algorithms", "instance", "show", "introduced", "expected", "task", "theorem", "probabilities", "quadratic", "inner", "datasets", "functions", "whereas", "risk", "large", "respect", "usually", "via", "complexity", "statistical", "linear", "directly", "min", "consistency", "experimental", "moreover", "conditional", "additional", "probabilistic", "test", "marginal", "theoretical"], "authors": ["Krzysztof Dembczynski", "Wojciech Kotlowski", "Arkadiusz Jachnik", "Willem Waegeman", "Eyke Huellermeier"], "thumbnail_path": "thumbnails/Optimizing the Fmeasure in Multilabel Classification Plugin Rule Approach versus Structured Loss Minimization.jpg"}, {"title": "Principal Component Analysis on nonGaussian Dependent Data", "topics": [0.017697929711611861, 0.01769802125257006, 0.91150751050315082, 0.017698530933792849, 0.017698321696898594, 0.017699685901975858], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/han13.pdf", "most_common": ["data", "pca", "let", "dependent", "dependence", "liu", "rate", "component", "principal", "analysis", "han", "kendall", "sparse", "fpr", "gaussian", "matrix", "theorem", "nonparanormal", "two", "scheme", "pearson", "random", "coca", "high", "provide", "using", "log", "probability", "vector", "section", "tau", "sample", "correlation", "leading", "false", "method", "equation", "performance", "fnr", "dimensional", "journal", "proposed", "supp", "analyzing", "positive", "theoretical", "following", "proof", "parameter", "sequence", "particular", "sin", "rates", "observations", "points", "show", "result", "distribution", "semiparametric", "eigenvectors", "power", "estimator", "estimators", "methods", "convergence", "multivariate", "vectors", "paper", "statistical", "monotone", "number", "tpr", "notations", "estimation", "covariance", "case", "several", "independent", "stationary", "negative", "support", "measure", "corresponding", "global", "truncated", "mixing", "sign", "sup", "degree", "recovery", "coming", "card", "least", "knowledge", "tuning", "weak", "denote", "copula", "follows", "statistic"], "authors": ["Fang Han", "Han Liu"], "thumbnail_path": "thumbnails/Principal Component Analysis on nonGaussian Dependent Data.jpg"}, {"title": "Deep Canonical Correlation Analysis", "topics": [0.020100021011081427, 0.020095891761891718, 0.82833415640178587, 0.091266737432225173, 0.020095948251750064, 0.020107245141265832], "pdf_url": "http://jmlr.org/proceedings/papers/v28/andrew13.pdf", "most_common": ["correlation", "deep", "cca", "data", "kcca", "canonical", "kernel", "two", "analysis", "dcca", "representations", "learning", "using", "nonlinear", "matrix", "function", "views", "parameters", "use", "set", "output", "correlated", "layers", "regularization", "number", "optimization", "training", "features", "total", "experiments", "also", "objective", "view", "used", "test", "learned", "layer", "model", "compute", "models", "matrices", "vectors", "may", "representation", "linear", "arora", "top", "networks", "projections", "articulatory", "salakhutdinov", "speech", "livescu", "method", "hinton", "one", "argmax", "tanh", "units", "corr", "values", "learn", "gradient", "given", "value", "dimensionality", "acoustic", "fold", "let", "singular", "sigmoid", "hidden", "size", "hardoon", "performance", "rbf", "another", "development", "table", "dimensions", "vector", "section", "prediction", "new", "obtained", "hbj", "via", "positive", "figure", "nips", "network", "since", "similarly", "tuned", "computed", "kernels", "three", "maximally", "neural", "components"], "authors": ["Galen Andrew", "Jeff Bilmes", "Raman Arora", "Karen Livescu"], "thumbnail_path": "thumbnails/Deep Canonical Correlation Analysis.jpg"}, {"title": "Canonical Correlation Analysis based on HilbertSchmidt Independence Criterion and Centered Kernel Target Alignment", "topics": [0.023378142053343442, 0.023375613807442037, 0.7731814230718641, 0.13330286307675013, 0.023376279383669464, 0.023385678606930728], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/chang13.pdf", "most_common": ["qqq", "qqqq", "projected", "qqqqq", "cca", "canonical", "qqqqqq", "hsiccca", "ktacca", "data", "correlation", "kcca", "hsic", "qqqqqqq", "kernel", "kta", "two", "dcca", "vectors", "linear", "analysis", "qqqqqqqq", "nonlinear", "figure", "kij", "functions", "spearman", "algorithms", "proposed", "variables", "using", "algorithm", "results", "based", "signal", "umt", "gretton", "criterion", "set", "however", "extensions", "three", "may", "vmt", "measures", "irrelevant", "signals", "qqqqqqqqq", "obtained", "orthogonal", "applications", "weight", "one", "projections", "cos", "used", "variates", "methods", "respectively", "projection", "absolute", "measure", "pairs", "objective", "multiple", "sets", "samples", "associations", "sparse", "simulation", "pair", "form", "four", "discovered", "provide", "generalized", "article", "learning", "neural", "transformed", "performance", "variants", "cosine", "application", "relationships", "discover", "section", "sample", "parameter", "features", "extract", "hence", "centered", "jmlr", "jordan", "extracting", "selection", "correlations", "qqqqqqqqqqq", "model"], "authors": ["Billy Chang", "Uwe Kruger", "Rafal Kustra", "Junping Zhang"], "thumbnail_path": "thumbnails/Canonical Correlation Analysis based on HilbertSchmidt Independence Criterion and Centered Kernel Target Alignment.jpg"}, {"title": "Vanishing Component Analysis", "topics": [0.018860600068478617, 0.018861710814196669, 0.90569533778184752, 0.018860797165073811, 0.018860440478884407, 0.018861113691519275], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/livni13.pdf", "most_common": ["set", "polynomials", "polynomial", "vanishing", "vca", "degree", "linear", "generators", "ideal", "let", "kernel", "use", "algebraic", "span", "since", "using", "procedure", "thus", "component", "avi", "analysis", "vector", "space", "null", "used", "follows", "algorithm", "also", "function", "method", "therefore", "data", "features", "class", "theorem", "vectors", "example", "feature", "monomials", "number", "points", "approach", "monomial", "consider", "hence", "approximately", "section", "show", "learning", "next", "sample", "goal", "one", "construct", "written", "however", "components", "sets", "construction", "denote", "vanishes", "compact", "zero", "two", "combination", "orthonormal", "matrix", "given", "base", "training", "variables", "ksvm", "corresponding", "trick", "vanish", "problem", "results", "findrangenull", "known", "work", "following", "description", "pca", "furthermore", "size", "geometry", "candidate", "described", "basis", "case", "generator", "test", "form", "functions", "assume", "time", "whose", "value", "obtained", "linearly"], "authors": ["Roi Livni", "David Lehavi", "Sagi Schein", "Hila Nachliely", "Shai Shalev-Shwartz", "Amir Globerson"], "thumbnail_path": "thumbnails/Vanishing Component Analysis.jpg"}, {"title": "Fast algorithms for sparse principal component analysis based on Rayleigh quotient iteration", "topics": [0.018433452848045612, 0.018433204636152639, 0.9078317592415267, 0.01843388868527614, 0.018433279979412746, 0.018434414609586301], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kuleshov13.pdf", "most_common": ["iteration", "algorithm", "quotient", "rayleigh", "sparse", "algorithms", "principal", "method", "component", "grqi", "power", "matrix", "components", "sparsity", "analysis", "number", "variance", "data", "figure", "convergence", "technique", "gpm", "generalized", "problem", "eigenvalue", "one", "set", "methods", "step", "based", "new", "iterations", "optimization", "fast", "every", "parameter", "two", "pca", "fact", "setting", "found", "converges", "also", "expression", "simple", "compute", "update", "projected", "fewer", "rate", "gene", "use", "complexity", "magnitude", "used", "spca", "random", "case", "thus", "largest", "newton", "using", "computing", "solution", "small", "projection", "working", "machine", "order", "experiments", "good", "practice", "shown", "could", "objective", "performance", "ones", "however", "point", "several", "cubic", "learning", "speed", "although", "time", "unew", "large", "current", "lee", "desired", "xnew", "explained", "positive", "cardinality", "may", "max", "bioinformatics", "return", "gradient", "standard"], "authors": ["Volodymyr Kuleshov"], "thumbnail_path": "thumbnails/Fast algorithms for sparse principal component analysis based on Rayleigh quotient iteration.jpg"}, {"title": "Efficient Dimensionality Reduction for Canonical Correlation Analysis", "topics": [0.021594555818906819, 0.021592123710778687, 0.83372638040164004, 0.079892551423434668, 0.021594905591967733, 0.021599483053272129], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/avron13.pdf", "most_common": ["canonical", "matrix", "algorithm", "correlations", "cca", "matrices", "correlation", "dimensionality", "let", "lemma", "reduction", "pair", "error", "awi", "sampling", "rows", "two", "set", "coherence", "analysis", "log", "use", "probability", "approximate", "rank", "using", "weights", "random", "transform", "least", "bpi", "vectors", "columns", "golub", "time", "every", "uniform", "one", "value", "theorem", "fast", "compute", "randomized", "experiment", "size", "however", "large", "sample", "algorithms", "tropp", "orthonormal", "rht", "bounds", "problem", "approximation", "synthetic", "figure", "used", "avron", "given", "much", "learning", "running", "drineas", "proposed", "step", "form", "denote", "section", "boutsidis", "high", "following", "inequality", "shows", "linear", "smaller", "also", "show", "independent", "three", "column", "entries", "sun", "actual", "singular", "data", "space", "awj", "new", "experiments", "sec", "distribution", "many", "hold", "ordinal", "bound", "dataset", "requires", "technique", "subsampled"], "authors": ["Haim Avron", "Christos Boutsidis", "Sivan Toledo", "Anastasios Zouzias"], "thumbnail_path": "thumbnails/Efficient Dimensionality Reduction for Canonical Correlation Analysis.jpg"}, {"title": "Adaptive Sparsity in Gaussian Graphical Models ", "topics": [0.021894213105092566, 0.021889923306301615, 0.89054552199064296, 0.021890066240629003, 0.021889655828306983, 0.021890619529027013], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wong13.pdf", "most_common": ["glasso", "matrix", "gaussian", "entries", "sparsity", "precision", "zero", "model", "proposed", "method", "prior", "data", "nonzero", "parameter", "ols", "estimate", "likelihood", "graphical", "sparse", "models", "estimation", "hierarchical", "prediction", "adaptive", "error", "algorithm", "sample", "using", "results", "solution", "map", "laplace", "estimates", "given", "also", "accuracy", "penalty", "terms", "size", "selection", "problem", "covariance", "matrices", "large", "values", "friedman", "bayesian", "regression", "equivalent", "function", "maximization", "performance", "true", "set", "approach", "learning", "entry", "maximum", "test", "cell", "multivariate", "use", "two", "table", "optimal", "diagonal", "signaling", "random", "respect", "bias", "lower", "simulated", "epsilon", "posterior", "graph", "norm", "experiment", "positive", "figure", "experiments", "dataset", "first", "gives", "show", "figueiredo", "cholesky", "glassopath", "much", "value", "journal", "comparison", "range", "distribution", "variable", "structure", "frobenius", "solutions", "estimated", "even", "rate"], "authors": ["Eleanor Wong", "Suyash Awate", "P. Thomas Fletcher"], "thumbnail_path": "thumbnails/Adaptive Sparsity in Gaussian Graphical Models .jpg"}, {"title": "The Most Generative Maximum Margin Bayesian Networks", "topics": [0.01826436946987357, 0.018264470813855644, 0.90867448124329175, 0.01826517368482268, 0.018265573356023305, 0.018265931432132843], "pdf_url": "http://jmlr.org/proceedings/papers/v28/peharz13.pdf", "most_common": ["generative", "missing", "nln", "discriminative", "features", "margin", "parameters", "learning", "vector", "bayesian", "maximum", "solution", "likelihood", "set", "normalized", "algorithm", "log", "val", "since", "results", "parameter", "pai", "conditional", "models", "training", "networks", "problem", "distribution", "data", "strictly", "class", "test", "pernkopf", "mcl", "represent", "use", "therefore", "machine", "also", "exp", "however", "model", "using", "convex", "section", "network", "structures", "show", "experiments", "bns", "furthermore", "large", "figure", "optimal", "percentage", "character", "step", "negative", "datasets", "formulation", "distributions", "svms", "assume", "let", "interpretation", "used", "linear", "lemma", "see", "theorem", "wettig", "guo", "trained", "sample", "following", "end", "feature", "paper", "better", "constraints", "weighted", "shown", "gradient", "objective", "friedman", "covering", "parent", "uci", "optimization", "although", "function", "node", "svm", "averaged", "consistent", "method", "term", "always", "likelihoods", "projected"], "authors": ["Robert Peharz", "Sebastian Tschiatschek", "Franz Pernkopf"], "thumbnail_path": "thumbnails/The Most Generative Maximum Margin Bayesian Networks.jpg"}, {"title": "ComputationRisk Tradeoffs for CovarianceThresholded Regression", "topics": [0.020312304346840972, 0.020312883694759854, 0.89843535717506429, 0.020314497691318038, 0.02031240342388161, 0.020312553668135249], "pdf_url": "http://jmlr.org/proceedings/papers/v28/shender13.pdf", "most_common": ["risk", "log", "excess", "computation", "covariance", "regression", "sparse", "bound", "sample", "theorem", "sparsity", "linear", "lemma", "analysis", "matrix", "computational", "term", "probability", "threshold", "error", "time", "entries", "section", "assumptions", "algorithms", "statistical", "diagonally", "assumption", "population", "setting", "results", "sdd", "stochastic", "design", "technical", "regularization", "number", "hsu", "estimator", "ridge", "level", "following", "work", "system", "dominant", "second", "make", "increases", "bounded", "algorithm", "together", "solution", "large", "family", "data", "order", "since", "shows", "given", "also", "accuracy", "report", "value", "model", "learning", "nonzero", "simulations", "approximation", "version", "positive", "thresholding", "may", "main", "university", "show", "random", "many", "case", "dimension", "using", "estimators", "bounds", "consider", "bounding", "matrices", "small", "zero", "cost", "method", "obtained", "plotted", "use", "particular", "high", "parameter", "clarkson", "complexity", "decreases", "systems", "hard"], "authors": ["Dinah Shender", "John Lafferty"], "thumbnail_path": "thumbnails/ComputationRisk Tradeoffs for CovarianceThresholded Regression.jpg"}, {"title": "Scalable Simple Random Sampling and Stratified Sampling", "topics": [0.019580344195961323, 0.019597308883013417, 0.90207722563728743, 0.019581693385519783, 0.019582485321871873, 0.019580942576346169], "pdf_url": "http://jmlr.org/proceedings/papers/v28/meng13a.pdf", "most_common": ["algorithm", "sampling", "items", "random", "log", "probability", "scasrs", "data", "size", "item", "let", "high", "sample", "given", "sort", "number", "scalable", "simple", "srs", "algorithms", "theorem", "needs", "use", "set", "waiting", "time", "storage", "section", "order", "running", "reject", "thresholds", "list", "using", "failure", "select", "work", "end", "hence", "smallest", "key", "mapreduce", "sequential", "reduce", "succeeds", "rate", "need", "mappers", "stratum", "sets", "accepted", "bound", "global", "large", "following", "instead", "parallel", "generate", "least", "probabilistic", "based", "lemma", "compute", "however", "analysis", "know", "sorting", "output", "count", "applying", "implemented", "therefore", "proof", "accept", "strata", "one", "phase", "result", "many", "input", "case", "easy", "reducer", "streaming", "acm", "similar", "consider", "applied", "even", "apply", "process", "associated", "theoretical", "may", "still", "framework", "associate", "variables", "also", "selection"], "authors": ["Xiangrui Meng"], "thumbnail_path": "thumbnails/Scalable Simple Random Sampling and Stratified Sampling.jpg"}, {"title": "The lasso persistence and crossvalidation", "topics": [0.021242006793244027, 0.021242651175048217, 0.89378802328722984, 0.021243097915640743, 0.021242072213946073, 0.021242148614891251], "pdf_url": "http://jmlr.org/proceedings/papers/v28/homrighausen13.pdf", "most_common": ["lasso", "log", "risk", "parameter", "tmax", "results", "tuning", "lvn", "lemma", "estimator", "equation", "sup", "tibshirani", "set", "model", "condition", "statistical", "statistics", "section", "proof", "journal", "solution", "data", "linear", "least", "persistence", "therefore", "theoretical", "chosen", "matrix", "note", "random", "follows", "design", "following", "use", "inequality", "selection", "show", "independent", "theory", "via", "choose", "main", "bound", "squares", "given", "hence", "annals", "notation", "however", "distribution", "choosing", "function", "oracle", "particular", "max", "paper", "ritov", "efn", "suppose", "regression", "using", "predictor", "quadratic", "greenshtein", "upper", "let", "criterion", "may", "response", "excess", "variables", "zou", "geer", "exists", "case", "consistency", "theorem", "sparsity", "van", "hastie", "consider", "vector", "prediction", "information", "regularization", "choice", "recovery", "lemmas", "used", "efron", "american", "probability", "necessarily", "rewrite", "meinshausen", "constant", "expectation", "see"], "authors": ["Darren Homrighausen", "Daniel McDonald"], "thumbnail_path": "thumbnails/The lasso persistence and crossvalidation.jpg"}, {"title": "Consistency versus Realizable HConsistency for Multiclass Classification", "topics": [0.023716100986112345, 0.023778045741789395, 0.88135575356306672, 0.023716586447216262, 0.023715857493647068, 0.023717655768168339], "pdf_url": "http://jmlr.org/proceedings/papers/v28/long13.pdf", "most_common": ["loss", "function", "functions", "realizable", "lcs", "scoring", "consistency", "source", "llogit", "consistent", "class", "learning", "theorem", "let", "since", "minimizing", "algorithm", "max", "one", "notion", "respect", "proof", "accuracy", "multiclass", "matrix", "linear", "set", "see", "implies", "error", "optimal", "classes", "show", "zhang", "following", "may", "weight", "also", "used", "convex", "generated", "results", "stochastic", "large", "tewari", "prove", "note", "bartlett", "strictly", "test", "scores", "claim", "experiments", "scaling", "domain", "gradient", "probability", "property", "using", "examples", "whose", "vector", "section", "bayes", "positive", "must", "machine", "algorithms", "choose", "restricted", "get", "standard", "training", "given", "closed", "value", "minimize", "image", "rows", "support", "constant", "inf", "consider", "theory", "use", "work", "example", "minimized", "data", "increasing", "easily", "number", "similarly", "least", "lin", "average", "proceedings", "random", "lemma", "logitboost"], "authors": ["Phil Long", "Rocco Servedio"], "thumbnail_path": "thumbnails/Consistency versus Realizable HConsistency for Multiclass Classification.jpg"}, {"title": "TwoSided Exponential Concentration Bounds for Bayes Error Rate and Shannon Entropy", "topics": [0.02083300069234597, 0.02083347657993135, 0.89583240419123966, 0.020835245594532256, 0.020833024840732427, 0.020832848101218212], "pdf_url": "http://jmlr.org/proceedings/papers/v28/honorio13.pdf", "most_common": ["log", "entropy", "bound", "let", "bayes", "rate", "bounds", "lipschitz", "probability", "min", "error", "shannon", "given", "continuous", "concentration", "exponential", "domain", "bounded", "theorem", "distributions", "information", "note", "density", "inequality", "class", "empirical", "function", "results", "liu", "variables", "assume", "therefore", "samples", "unbounded", "variable", "compact", "approximation", "provide", "present", "true", "next", "random", "learning", "follows", "proposition", "finally", "change", "probabilities", "ieee", "theory", "size", "transactions", "bayesian", "lower", "distribution", "upper", "prove", "number", "least", "generalization", "show", "conditions", "estimation", "respect", "constant", "general", "every", "nonparametric", "subset", "since", "assumption", "maximum", "expected", "several", "well", "obtain", "mutual", "method", "table", "provable", "apply", "order", "second", "need", "continuity", "kernel", "set", "extend", "bin", "provides", "two", "approximate", "risk", "consistent", "section", "paper", "networks", "based", "knowledge", "best"], "authors": ["Jean Honorio", "Jaakkola Tommi"], "thumbnail_path": "thumbnails/TwoSided Exponential Concentration Bounds for Bayes Error Rate and Shannon Entropy.jpg"}, {"title": "Scale Invariant Conditional Dependence Measures", "topics": [0.022289587791918055, 0.022288548998269059, 0.88855555962260035, 0.02228901487812468, 0.022288556606161764, 0.022288732102926048], "pdf_url": "http://jmlr.org/proceedings/papers/v28/jreddi13.pdf", "most_common": ["dependence", "measures", "random", "dhs", "conditional", "estimators", "variables", "copula", "measure", "theorem", "invariant", "let", "kernel", "convergence", "operator", "use", "using", "empirical", "upper", "norm", "nhs", "kernels", "transformation", "bound", "following", "also", "fukumizu", "property", "invariance", "supplementary", "denote", "assume", "operators", "conditions", "information", "since", "generalized", "set", "result", "transformations", "suppose", "independent", "transformed", "scale", "variable", "gretton", "note", "show", "consistency", "learning", "distributions", "rate", "invertible", "increasing", "proof", "sample", "provide", "feature", "paper", "samples", "covariance", "chs", "estimator", "called", "functions", "assumptions", "used", "features", "rates", "measured", "distribution", "important", "pxy", "marginal", "prove", "normalized", "figure", "machine", "monotone", "probability", "continuous", "case", "mutual", "statistics", "similar", "certain", "bounded", "consider", "even", "section", "correlation", "dataset", "space", "shows", "similarly", "hilbertschmidt", "notation", "joint", "though", "many"], "authors": ["Sashank J Reddi", "Barnabas Poczos"], "thumbnail_path": "thumbnails/Scale Invariant Conditional Dependence Measures.jpg"}, {"title": "Infinite MarkovSwitching Maximum Entropy Discrimination Machines", "topics": [0.014520952038565935, 0.014521124923408199, 0.92739129888851013, 0.014521022765809535, 0.014521149937168559, 0.014524451446537733], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chatzis13.pdf", "most_common": ["model", "data", "markov", "method", "training", "bayesian", "latent", "entropy", "video", "approach", "maximum", "med", "obtained", "prior", "observations", "discrimination", "distribution", "edm", "prediction", "inference", "posteriors", "one", "problem", "sequential", "temporal", "machines", "nonparametric", "using", "appropriate", "models", "use", "play", "state", "modeled", "proposed", "posterior", "similar", "priors", "algorithm", "vector", "section", "following", "performance", "set", "learning", "optimization", "underlying", "function", "component", "process", "hidden", "dirichlet", "variables", "number", "sequence", "considered", "random", "parameters", "zhu", "depth", "chain", "isvm", "let", "states", "complex", "beta", "mixture", "equal", "capture", "experiments", "discriminant", "consider", "usually", "parameter", "allow", "ieee", "machine", "framework", "motion", "given", "also", "comprising", "context", "sequences", "evaluate", "test", "imposed", "yields", "recognition", "statistics", "construction", "existing", "fan", "vij", "two", "sports", "camera", "information", "max", "feature"], "authors": ["Sotirios Chatzis"], "thumbnail_path": "thumbnails/Infinite MarkovSwitching Maximum Entropy Discrimination Machines.jpg"}, {"title": "Distribution to Distribution Regression", "topics": [0.01766250272879628, 0.017662457096679129, 0.91168738401253069, 0.017662788626874471, 0.017662446366802781, 0.01766242116831673], "pdf_url": "http://jmlr.org/proceedings/papers/v28/oliva13.pdf", "most_common": ["distribution", "output", "distributions", "input", "regression", "using", "one", "estimate", "estimator", "let", "density", "estimated", "lemma", "risk", "bound", "kernel", "case", "projection", "sample", "may", "furthermore", "see", "note", "densities", "analysis", "estimators", "measure", "figure", "nonparametric", "given", "also", "rate", "doubling", "mapping", "since", "cde", "estimation", "dimension", "samples", "dde", "functional", "true", "consider", "query", "use", "instead", "hence", "clearly", "thus", "learning", "dataset", "poczos", "cell", "iid", "assumptions", "feature", "order", "series", "shown", "pairs", "probability", "frame", "drawn", "look", "model", "assume", "upper", "pdfs", "domain", "space", "length", "features", "size", "shall", "class", "optimally", "set", "used", "unseen", "real", "choosing", "methods", "convergence", "bounds", "new", "synthetic", "springer", "following", "example", "control", "machine", "response", "derive", "yij", "assumption", "upperbound", "distance", "analyze", "made", "arxiv"], "authors": ["Junier Oliva", "Barnabas Poczos", "Jeff Schneider"], "thumbnail_path": "thumbnails/Distribution to Distribution Regression.jpg"}, {"title": "Entropic Affinities Properties and Efficient Numerical Computation", "topics": [0.014586442349571955, 0.014583242173795044, 0.92708072124303276, 0.014583461936893418, 0.014583110123317906, 0.01458302217338886], "pdf_url": "http://jmlr.org/proceedings/papers/v28/vladymyrov13.pdf", "most_common": ["points", "methods", "method", "function", "order", "point", "iterations", "algorithm", "log", "entropic", "bounds", "one", "root", "dataset", "computation", "perplexity", "using", "image", "values", "bisection", "used", "convergence", "algorithms", "number", "given", "compute", "use", "fast", "set", "learning", "properties", "machine", "iteration", "mst", "many", "value", "entropy", "two", "data", "numerical", "distances", "distance", "lena", "derivatives", "runtime", "based", "local", "region", "initialization", "distribution", "good", "matrix", "however", "embedding", "thus", "roweis", "bandwidth", "steps", "global", "cost", "changes", "takes", "nearest", "shows", "also", "show", "kernel", "almost", "user", "mnist", "density", "per", "neighbor", "clustering", "single", "dimensionality", "solution", "spectral", "hinton", "give", "parameter", "close", "need", "mit", "slow", "best", "orders", "press", "datasets", "similar", "results", "case", "every", "small", "second", "nonlinear", "resulting", "example", "figure", "cambridge"], "authors": ["Max Vladymyrov", "Miguel Carreira-Perpinan"], "thumbnail_path": "thumbnails/Entropic Affinities Properties and Efficient Numerical Computation.jpg"}, {"title": "Learning Hash Functions Using Column Generation", "topics": [0.022559806253482563, 0.022547665638810759, 0.88720760622196737, 0.022547815971564786, 0.022590103801572978, 0.022547002112601487], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/li13a.pdf", "most_common": ["hashing", "hash", "using", "functions", "learning", "cghash", "ssc", "column", "set", "methods", "lsh", "binary", "problem", "retrieval", "proposed", "sph", "generation", "bits", "sth", "number", "samples", "neighbors", "splh", "lsi", "itq", "lch", "agh", "bres", "nearest", "performances", "function", "data", "method", "training", "regularization", "optimization", "loss", "true", "information", "proportion", "dual", "average", "codes", "min", "distance", "convex", "code", "plot", "used", "primal", "use", "learn", "norm", "machine", "constraints", "space", "boosting", "precision", "error", "comparison", "algorithm", "similarity", "case", "zhang", "recall", "wang", "following", "figure", "may", "shows", "linear", "proximity", "image", "original", "spectral", "andoni", "classification", "types", "large", "generate", "also", "objective", "performance", "hamming", "based", "computer", "best", "indyk", "well", "solve", "obtain", "weiss", "supervised", "triplets", "results", "graph", "solution", "compact", "work", "order"], "authors": ["Xi Li", "Guosheng Lin", "Chunhua Shen", "Anton van den Hengel", "Anthony Dick"], "thumbnail_path": "thumbnails/Learning Hash Functions Using Column Generation.jpg"}, {"title": "Robust Structural Metric Learning", "topics": [0.040141089150087718, 0.017069810281140563, 0.89144006110549467, 0.017070727235602969, 0.017067463780321965, 0.017210848447352212], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/lim13.pdf", "most_common": ["learning", "metric", "algorithm", "mlr", "features", "set", "robust", "performance", "sparsity", "number", "itml", "lmnn", "structural", "dimensionality", "training", "input", "method", "data", "dimensions", "noise", "admm", "algorithms", "audio", "similarity", "output", "methods", "results", "experiment", "figure", "dataset", "across", "noisy", "mcfee", "song", "feature", "experiments", "rank", "task", "using", "music", "datasets", "large", "via", "may", "distance", "accuracy", "lanckriet", "however", "proposed", "transformation", "uci", "image", "problem", "auc", "small", "optimization", "sparse", "time", "songs", "values", "varied", "constraints", "projected", "linear", "metrics", "lyrics", "solutions", "error", "huang", "corresponding", "dual", "used", "joachims", "convex", "informative", "constraint", "mean", "rows", "formulation", "update", "original", "test", "resulting", "projection", "thresholding", "information", "max", "representations", "ionosphere", "outperforms", "also", "ranking", "balance", "well", "obtain", "relevant", "step", "promote", "similar", "existing"], "authors": ["Daryl Lim", "Gert Lanckriet", "Brian McFee"], "thumbnail_path": "thumbnails/Robust Structural Metric Learning.jpg"}, {"title": "Revisiting the Nystrom method for improved largescale machine learning", "topics": [0.021458946843003215, 0.021458886707849196, 0.89267235686351443, 0.021491701138598576, 0.021459022979478486, 0.021459085467556135], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gittens13.pdf", "most_common": ["matrix", "leverage", "sampling", "gaussian", "srft", "spsd", "approximation", "power", "mahoney", "lev", "unif", "levscore", "error", "frob", "bounds", "scores", "results", "data", "norm", "sketching", "kernels", "matrices", "method", "frobenius", "machine", "random", "relative", "trace", "drineas", "learning", "methods", "uniform", "projection", "time", "sketches", "gittens", "rbf", "using", "sparse", "much", "dense", "empirical", "spectral", "work", "algorithms", "probability", "columns", "revisiting", "column", "bound", "let", "kumar", "proceedings", "kernel", "analysis", "section", "hold", "given", "based", "score", "improved", "linear", "reconstruction", "full", "equation", "abaloned", "exact", "denotes", "lemma", "conference", "laplacian", "mixtures", "several", "running", "second", "theoretical", "abalones", "provide", "statistical", "main", "since", "diagonal", "halko", "least", "accuracy", "corresponding", "coherence", "well", "sets", "properties", "also", "consider", "existing", "graph", "zhang", "prior", "usa", "two", "applications", "randomized"], "authors": ["Alex Gittens", "Michael Mahoney"], "thumbnail_path": "thumbnails/Revisiting the Nystrom method for improved largescale machine learning.jpg"}, {"title": "That was fast Speeding up NN search of high dimensional distributions", "topics": [0.017907305345086447, 0.017896821351452728, 0.9105018868484096, 0.017898918077819674, 0.017897856018488766, 0.017897212358742604], "pdf_url": "http://jmlr.org/proceedings/papers/v28/coviello13.pdf", "most_common": ["bregman", "algorithm", "search", "bound", "variational", "divergence", "cayton", "log", "node", "query", "data", "lower", "bisection", "branch", "section", "high", "ball", "coviello", "using", "approximation", "since", "trees", "based", "tree", "brute", "speedup", "ieee", "two", "bounds", "results", "video", "centroid", "given", "backtracking", "exponential", "divergences", "distributions", "upper", "family", "nearest", "figure", "number", "set", "database", "chan", "models", "nodes", "force", "zero", "respectively", "use", "particular", "return", "one", "exp", "mixture", "dimensional", "else", "convex", "function", "time", "method", "latent", "instead", "approximated", "space", "may", "iteration", "regular", "computed", "terms", "budget", "components", "histogram", "variable", "requires", "consider", "dynamic", "large", "experiments", "monotonic", "div", "dts", "hershey", "min", "points", "lanckriet", "parameters", "music", "close", "table", "procedure", "dual", "nielsen", "step", "olsen", "consequently", "fast", "average", "computing"], "authors": ["Emanuele Coviello", "Adeel Mumtaz", "Antoni Chan", "Gert Lanckriet"], "thumbnail_path": "thumbnails/That was fast Speeding up NN search of high dimensional distributions.jpg"}, {"title": "Stochastic kNeighborhood Selection for Supervised and Unsupervised Learning", "topics": [0.016206683705399051, 0.016195567137569682, 0.91900357907353414, 0.016204920408899003, 0.016194516994952536, 0.01619473267964552], "pdf_url": "http://jmlr.org/proceedings/papers/v28/tarlow13.pdf", "most_common": ["objective", "neighbors", "knn", "learning", "accuracy", "knca", "nca", "neighbor", "stochastic", "class", "points", "data", "metric", "function", "distance", "set", "point", "expected", "used", "majority", "embedding", "methods", "models", "performance", "exp", "number", "selection", "sum", "two", "sne", "chosen", "probability", "variables", "also", "partition", "using", "distribution", "dij", "method", "work", "space", "test", "better", "given", "embeddings", "larger", "similar", "hinton", "measure", "target", "note", "unsupervised", "factor", "roweis", "algorithm", "use", "local", "noise", "functions", "level", "neighborhood", "learned", "experiments", "training", "one", "results", "classes", "show", "several", "model", "distances", "either", "van", "log", "compute", "setting", "dimensionality", "graph", "choice", "small", "usps", "international", "objectives", "figure", "information", "end", "maj", "since", "goldberger", "proceedings", "ways", "label", "problem", "conference", "second", "margin", "components", "possible", "supervised", "true"], "authors": ["Daniel Tarlow", "Kevin Swersky", "Ilya Sutskever", "Laurent Charlin", "Rich Zemel"], "thumbnail_path": "thumbnails/Stochastic kNeighborhood Selection for Supervised and Unsupervised Learning.jpg"}, {"title": "Predictable DualView Hashing", "topics": [0.017538256999633319, 0.017505890754478757, 0.89684789333911497, 0.0330732393029275, 0.017516148001433036, 0.017518571602412464], "pdf_url": "http://jmlr.org/proceedings/papers/v28/rastegari13.pdf", "most_common": ["binary", "mean", "images", "pdh", "image", "hashing", "precision", "category", "lsh", "space", "itq", "codes", "recall", "method", "data", "retrieval", "query", "predictable", "visual", "code", "use", "two", "samples", "sgn", "cca", "bit", "number", "textual", "learning", "using", "berg", "dataset", "objective", "figure", "features", "hyperplanes", "set", "analysis", "function", "similar", "ith", "similarity", "search", "feature", "training", "hamming", "text", "proposed", "also", "methods", "algorithm", "semantic", "large", "obtained", "predictability", "high", "iterative", "report", "problem", "optimization", "sentence", "per", "svms", "values", "hash", "via", "attribute", "torralba", "linear", "one", "bits", "labels", "approach", "sensitive", "cvpr", "examples", "farhadi", "original", "results", "sun", "rastegari", "information", "map", "gionis", "since", "annotated", "hays", "multiple", "based", "compute", "scene", "experiments", "quantization", "embedding", "grauman", "coordinate", "weiss", "qualitative", "supervised", "kulis"], "authors": ["Mohammad Rastegari", "Jonghyun Choi", "Shobeir Fakhraei", "Daume Hal", "Larry Davis"], "thumbnail_path": "thumbnails/Predictable DualView Hashing.jpg"}, {"title": "A unifying framework for vectorvalued manifold regularization and multiview learning", "topics": [0.018336473286312285, 0.018336433359460707, 0.90831773957227913, 0.018336588521836356, 0.01833632811120612, 0.018336437148905468], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/haquang13.pdf", "most_common": ["learning", "let", "regularization", "matrix", "kernel", "manifold", "operator", "space", "diagonal", "sindhwani", "rosenberg", "framework", "one", "output", "data", "views", "general", "functions", "case", "vector", "rkhs", "given", "set", "block", "function", "problem", "section", "phow", "features", "least", "size", "view", "input", "proposition", "positive", "machine", "unlabeled", "hilbert", "formulation", "labeled", "special", "unifying", "training", "minh", "kxi", "table", "using", "results", "linear", "proceedings", "conference", "loss", "graph", "international", "following", "feature", "term", "number", "gray", "images", "solution", "experiments", "reproducing", "square", "accuracy", "method", "categorization", "see", "proposed", "minimization", "form", "denote", "consider", "scalar", "ssim", "two", "particular", "weight", "bird", "gives", "performance", "spaces", "implementation", "testing", "last", "point", "color", "object", "column", "wah", "bounded", "svm", "multiview", "cloud", "work", "give", "vedaldi", "ieee", "combination", "mij"], "authors": ["Minh Ha Quang", "Loris Bazzani", "Vittorio Murino"], "thumbnail_path": "thumbnails/A unifying framework for vectorvalued manifold regularization and multiview learning.jpg"}, {"title": "Domain Adaptation for Sequence Labeling Tasks with a Probabilistic Language Adaptation Model", "topics": [0.021198094050695497, 0.021197913159382818, 0.89396958245691038, 0.021197694687582772, 0.02119797517354903, 0.021238740471879611], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/xiao13.pdf", "most_common": ["domain", "adaptation", "target", "lbla", "sentences", "language", "word", "data", "model", "features", "learning", "training", "source", "distributed", "method", "representation", "labeled", "syntactic", "feature", "used", "proposed", "named", "pos", "chunking", "entity", "methods", "results", "tagging", "test", "iii", "two", "systems", "neural", "domains", "representations", "sequence", "probabilistic", "based", "words", "lbl", "blitzer", "context", "recognition", "processing", "wsj", "vector", "models", "labeling", "cross", "supervised", "scl", "table", "term", "natural", "machine", "kpn", "nlp", "conference", "log", "distribution", "augmenting", "learned", "latent", "statistical", "sentence", "using", "information", "number", "error", "unlabeled", "tasks", "distributions", "semantic", "brown", "medline", "international", "mnih", "outperforms", "performance", "common", "bengio", "comparison", "use", "learn", "represents", "given", "accuracy", "generalizable", "set", "observed", "across", "huang", "yates", "previous", "demonstrated", "computational", "figure", "contains", "association", "propose"], "authors": ["Min Xiao", "Yuhong Guo"], "thumbnail_path": "thumbnails/Domain Adaptation for Sequence Labeling Tasks with a Probabilistic Language Adaptation Model.jpg"}, {"title": "Maximum Variance Correction with Application to A Search", "topics": [0.015244749495523341, 0.015244860485652264, 0.92377612631854666, 0.015244893715845684, 0.015244616861819051, 0.015244753122613034], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/chen13c.pdf", "most_common": ["mvu", "mvc", "embedding", "variance", "graph", "heuristic", "constraints", "solution", "search", "isomap", "algorithm", "data", "nodes", "learning", "maximum", "problem", "points", "optimization", "set", "euclidean", "weinberger", "distance", "state", "embeddings", "manifold", "path", "eij", "patch", "saul", "anchor", "edges", "constraint", "two", "states", "shortest", "correction", "heuristics", "local", "several", "problems", "space", "feasible", "iterations", "laplacian", "admissibility", "dimensionality", "eigenmap", "tenenbaum", "also", "objective", "obtain", "shows", "show", "gap", "inner", "scale", "time", "dij", "ieee", "systems", "new", "international", "table", "figure", "use", "one", "sets", "proceedings", "intelligence", "conference", "game", "distances", "guarantees", "convex", "similar", "formulation", "rayner", "exact", "silva", "following", "goal", "initializations", "hii", "better", "speedup", "solutions", "scalability", "point", "consistency", "increases", "inequality", "processing", "three", "application", "patches", "zhang", "large", "even", "nonlinear", "let"], "authors": ["Wenlin Chen", "Kilian Weinberger", "Yixin Chen"], "thumbnail_path": "thumbnails/Maximum Variance Correction with Application to A Search.jpg"}, {"title": "Learning with Marginalized Corrupted Features", "topics": [0.021922431797910272, 0.021917761735702215, 0.89040745141758981, 0.021917697958984218, 0.021917458486103606, 0.021917198603709786], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/vandermaaten13.pdf", "most_common": ["mcf", "loss", "data", "corruption", "training", "blankout", "set", "learning", "test", "corrupted", "features", "poisson", "corrupting", "predictors", "distribution", "exponential", "quadratic", "noise", "logistic", "performance", "using", "xnd", "marginalized", "feature", "function", "machine", "standard", "expected", "scenario", "level", "sets", "experiments", "distributions", "results", "use", "figure", "neural", "amazon", "also", "examples", "dmoz", "reuters", "error", "model", "additional", "proceedings", "conference", "case", "functions", "international", "regularization", "may", "value", "images", "image", "exp", "show", "networks", "used", "robust", "roweis", "globerson", "table", "processing", "time", "errors", "trained", "work", "hinge", "information", "gaussian", "linear", "approaches", "size", "fdrop", "best", "minimize", "large", "represented", "contains", "particular", "three", "systems", "shows", "without", "advances", "computed", "approach", "convex", "leads", "upper", "train", "parameter", "derive", "optimal", "university", "mean", "weight", "percentage", "viewed"], "authors": ["Laurens van der Maaten", "Minmin Chen", "Stephen Tyree", "Kilian Weinberger"], "thumbnail_path": "thumbnails/Learning with Marginalized Corrupted Features.jpg"}, {"title": "Scaling Multidimensional Gaussian Processes using Projected Additive Approximations", "topics": [0.017200165289433897, 0.017200929662490757, 0.91399442424304844, 0.01720037992568817, 0.017203927318365723, 0.017200173560973062], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/gilboa13.pdf", "most_common": ["additive", "regression", "using", "algorithms", "gaussian", "runtime", "data", "model", "algorithm", "processes", "full", "multidimensional", "used", "given", "log", "datasets", "use", "section", "learning", "projected", "spgp", "input", "scaling", "number", "process", "approximations", "results", "linear", "accuracy", "approximation", "inference", "inputs", "error", "posterior", "projection", "two", "machine", "mcmc", "since", "rasmussen", "thus", "sparse", "method", "mean", "space", "standard", "one", "assumption", "also", "speedup", "across", "respect", "ppgpr", "scalar", "exact", "pursuit", "naive", "complexity", "dataset", "synthetic", "see", "expected", "bayesian", "case", "real", "methods", "dimensions", "step", "comparison", "approximate", "function", "covariance", "important", "prior", "marginal", "following", "figure", "nmse", "parallel", "hyperparameters", "greedy", "likelihood", "training", "hyperparameter", "implementation", "means", "sampling", "performance", "test", "multicore", "every", "markov", "latent", "optimize", "making", "university", "pareto", "variables", "achieves", "runtimes"], "authors": ["Elad Gilboa", "Yunus Saatci", "John Cunningham"], "thumbnail_path": "thumbnails/Scaling Multidimensional Gaussian Processes using Projected Additive Approximations.jpg"}, {"title": "Nonparametric Mixture of Gaussian Processes with Constraints", "topics": [0.016630048950805255, 0.016629049237267247, 0.91685389620661772, 0.016629122573138755, 0.016629510206241569, 0.016628372825929268], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ross13a.pdf", "most_common": ["constraints", "gaussian", "data", "mixture", "given", "nonparametric", "process", "disease", "variational", "processes", "model", "function", "algorithm", "inference", "distribution", "set", "lung", "used", "number", "figure", "dirichlet", "variables", "one", "individuals", "clustering", "section", "regression", "using", "clinical", "learning", "identify", "health", "experiments", "problem", "results", "aging", "association", "also", "performance", "genetic", "bayesian", "trajectories", "values", "synthetic", "markov", "equation", "smoke", "use", "machine", "represents", "matrix", "target", "mrf", "meaningful", "analysis", "input", "functions", "represent", "provide", "two", "known", "work", "information", "standard", "jordan", "randomly", "nmi", "approach", "according", "study", "curves", "case", "unconstrained", "journal", "formulation", "international", "learned", "latent", "training", "learn", "example", "parameter", "shown", "pairs", "instances", "rasmussen", "gps", "copd", "constrained", "random", "solutions", "new", "mrfs", "points", "mean", "corresponding", "without", "taken", "test", "regressors"], "authors": ["James Ross", "Jennifer Dy"], "thumbnail_path": "thumbnails/Nonparametric Mixture of Gaussian Processes with Constraints.jpg"}, {"title": "Fast Dual Variational Inference for NonConjugate Latent Gaussian Models", "topics": [0.018407886458759862, 0.018408064833402626, 0.90796386405721818, 0.018406482430503985, 0.018406775495061929, 0.01840692672505341], "pdf_url": "http://jmlr.org/proceedings/papers/v28/emtiyazkhan13.pdf", "most_common": ["gaussian", "variational", "dual", "log", "inference", "latent", "khan", "problem", "likelihood", "using", "bayesian", "optimization", "function", "models", "parameters", "number", "learning", "algorithm", "machine", "see", "lgms", "process", "approximations", "fast", "vector", "section", "method", "also", "approach", "model", "data", "seeger", "convex", "details", "respect", "given", "show", "set", "marginal", "use", "constraints", "shown", "since", "conjugate", "exp", "available", "covariance", "fenchel", "bound", "form", "train", "diag", "two", "archambeau", "example", "figure", "likelihoods", "used", "shows", "barber", "opper", "table", "conference", "nickisch", "test", "decomposition", "rue", "objective", "challis", "journal", "setting", "new", "prior", "poisson", "get", "max", "primal", "term", "research", "linear", "rasmussen", "min", "hyperparameter", "random", "international", "terms", "much", "gmrf", "lower", "examples", "statistics", "approximate", "similar", "assume", "time", "results", "large", "markov", "prediction", "approximation"], "authors": ["Mohammad Emtiyaz Khan", "Aleksandr Aravkin", "Michael Friedlander", "Matthias Seeger"], "thumbnail_path": "thumbnails/Fast Dual Variational Inference for NonConjugate Latent Gaussian Models.jpg"}, {"title": "Gaussian Process Vine Copulas for Multivariate Dependence", "topics": [0.024318673628261976, 0.024318884927909672, 0.87840449335896587, 0.024318769083965078, 0.024319219788094069, 0.024319959212803284], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/lopez-paz13.pdf", "most_common": ["copula", "copulas", "conditional", "vine", "gaussian", "bivariate", "dependence", "given", "set", "multivariate", "tree", "using", "trees", "parametric", "method", "conditioning", "variables", "data", "gpvine", "density", "learning", "vines", "marginal", "dependencies", "function", "models", "figure", "edge", "process", "distributions", "standard", "joe", "mllvine", "conditioned", "model", "datasets", "number", "random", "edges", "sets", "acar", "two", "since", "show", "however", "distribution", "node", "use", "spanning", "correlation", "hierarchy", "experiments", "better", "one", "factorization", "table", "test", "cooke", "approximation", "particular", "sample", "svine", "dataset", "regular", "families", "cloud", "corresponding", "graph", "vector", "obtained", "training", "information", "parameter", "systems", "shown", "estimate", "construct", "assumption", "performance", "cdf", "based", "processes", "densities", "approach", "available", "described", "jura", "higher", "independent", "used", "journal", "weather", "methods", "brechmann", "form", "ghahramani", "results", "synthetic", "nodes", "value"], "authors": ["David Lopez-Paz", "Jose Miguel Hernandez-Lobato", "Ghahramani Zoubin"], "thumbnail_path": "thumbnails/Gaussian Process Vine Copulas for Multivariate Dependence.jpg"}, {"title": "Structure Discovery in Nonparametric Regression through Compositional Kernel Search", "topics": [0.018057523168498093, 0.018057842093143182, 0.90971006847341107, 0.018058060813942903, 0.018058691314176173, 0.018057814136828401], "pdf_url": "http://jmlr.org/proceedings/papers/v28/duvenaud13.pdf", "most_common": ["kernel", "structure", "kernels", "search", "regression", "per", "lin", "base", "data", "learning", "method", "functions", "model", "space", "discovery", "using", "models", "periodic", "structures", "nonparametric", "gaussian", "linear", "additive", "figure", "one", "methods", "compositional", "extrapolation", "used", "dimensions", "function", "posterior", "composite", "rasmussen", "components", "learned", "dataset", "applying", "residuals", "sums", "time", "trend", "work", "process", "number", "sum", "parameters", "bayesian", "procedure", "capture", "dimension", "often", "variety", "interpretable", "depth", "international", "family", "marginal", "use", "learn", "machine", "snr", "since", "predictive", "generalized", "multiplying", "terms", "many", "families", "covariance", "neural", "parametric", "decomposition", "form", "similar", "included", "synthetic", "vector", "section", "products", "two", "example", "information", "chosen", "series", "shows", "set", "williams", "able", "points", "mse", "local", "approach", "likelihood", "corresponds", "table", "conference", "well", "input", "bach"], "authors": ["David Duvenaud", "James Lloyd", "Roger Grosse", "Joshua Tenenbaum", "Ghahramani Zoubin"], "thumbnail_path": "thumbnails/Structure Discovery in Nonparametric Regression through Compositional Kernel Search.jpg"}, {"title": "Sequential Bayesian Search", "topics": [0.020845587642569927, 0.02081319396030621, 0.89588437340964244, 0.020812544614500172, 0.020832004303196778, 0.020812296069784391], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wen13.pdf", "most_common": ["user", "questions", "algorithm", "number", "episode", "bayesian", "sbs", "policy", "items", "item", "search", "regret", "target", "problem", "learning", "belief", "preferences", "optimal", "asked", "cumulative", "section", "sequential", "prior", "movies", "preference", "bound", "movie", "content", "average", "tree", "min", "time", "solution", "show", "expected", "question", "note", "based", "discovery", "distribution", "second", "learn", "ttg", "lemma", "dir", "two", "probability", "gbs", "genres", "theorem", "let", "particular", "ask", "system", "mint", "performance", "choice", "study", "would", "work", "episodes", "since", "reg", "interactions", "set", "respect", "policies", "analysis", "assume", "categories", "figure", "minimum", "algorithms", "solving", "systems", "propose", "arg", "best", "approach", "refer", "sublinear", "answers", "golovin", "options", "therefore", "guestrin", "three", "better", "adaptive", "greedy", "yue", "first", "one", "lower", "interactive", "viewed", "relatively", "posterior", "frequentist", "movielens"], "authors": ["Zheng Wen", "Branislav Kveton", "Brian Eriksson", "Sandilya Bhamidipati"], "thumbnail_path": "thumbnails/Sequential Bayesian Search.jpg"}, {"title": "Kernelized Bayesian Matrix Factorization", "topics": [0.015693904982524123, 0.015694007086804618, 0.92153041494210164, 0.015693881393661589, 0.015693862441586708, 0.01569392915332133], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gonen13a.pdf", "most_common": ["matrix", "kernel", "factorization", "data", "learning", "bayesian", "method", "multiple", "components", "using", "set", "two", "outputs", "kbmf", "probabilistic", "kernelized", "drugs", "model", "information", "side", "proceedings", "multilabel", "weights", "interaction", "latent", "distribution", "results", "inference", "domain", "target", "similarity", "prediction", "objects", "figure", "proteins", "binary", "fully", "variational", "also", "predicted", "posterior", "use", "baseline", "better", "kpmf", "standard", "part", "labels", "kernels", "used", "one", "normal", "sets", "approximate", "single", "distributions", "priors", "dimensionality", "matrices", "approximation", "projection", "composite", "yamanishi", "parameter", "volsurf", "algorithms", "amanda", "covariance", "computational", "whereas", "network", "domains", "training", "earlier", "chemical", "interactions", "features", "function", "modeling", "perform", "recommender", "sources", "samples", "methods", "zhou", "updates", "feature", "representations", "systems", "toy", "variables", "bioinformatics", "number", "integrate", "label", "corresponds", "corresponding", "obtain", "early", "test"], "authors": ["Mehmet Gnen", "Suleiman Khan", "Samuel Kaski"], "thumbnail_path": "thumbnails/Kernelized Bayesian Matrix Factorization.jpg"}, {"title": "SADA A General Framework to Support Robust Causation Discovery", "topics": [0.023561833817358303, 0.023563796273947026, 0.8821554974178375, 0.023591121238420561, 0.023564863714539933, 0.02356288753789661], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/cai13.pdf", "most_common": ["causal", "sada", "variables", "variable", "cut", "causation", "algorithm", "number", "conditional", "two", "model", "linear", "sample", "independence", "noise", "framework", "set", "discovery", "bayesian", "problem", "samples", "results", "discrete", "causality", "edge", "inference", "additive", "figure", "general", "small", "data", "based", "robust", "subproblem", "condition", "must", "following", "experiments", "since", "result", "approach", "directed", "assume", "lingam", "large", "method", "algorithms", "assumption", "networks", "ica", "support", "peters", "cbn", "structure", "existing", "graph", "pearl", "example", "network", "one", "size", "precision", "baseline", "test", "recall", "pigs", "probability", "dataset", "domain", "pairs", "error", "learning", "return", "used", "janzing", "also", "shimizu", "zhang", "markov", "smaller", "cuts", "generation", "given", "dominik", "running", "edges", "table", "scale", "complete", "link", "partitioning", "partial", "division", "subproblems", "gene", "score", "cai", "correctness", "order", "least"], "authors": ["Ruichu Cai", "Zhenjie Zhang", "Zhifeng Hao"], "thumbnail_path": "thumbnails/SADA A General Framework to Support Robust Causation Discovery.jpg"}, {"title": "Domain Generalization via Invariant Feature Representation", "topics": [0.015610017568812433, 0.015609344898569444, 0.92195162324075741, 0.015609392186968111, 0.015609471441024174, 0.015610150663868533], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/muandet13.pdf", "most_common": ["dica", "domain", "data", "kernel", "distributional", "domains", "generalization", "learning", "udica", "training", "svm", "kpca", "variance", "pooling", "coir", "invariant", "subspace", "distribution", "test", "samples", "feature", "regression", "analysis", "via", "output", "functional", "distributions", "relationship", "see", "problem", "component", "marginal", "let", "input", "unseen", "motor", "total", "information", "machine", "patients", "using", "dataset", "pages", "cell", "new", "work", "sample", "representation", "across", "theorem", "previously", "variation", "inverse", "stable", "error", "two", "systems", "space", "updrs", "target", "neural", "performance", "covariance", "empirical", "central", "transfer", "cells", "denote", "blanchard", "apply", "bound", "eigenvalue", "related", "gating", "probability", "outperforms", "mit", "pan", "transformation", "press", "methods", "function", "algorithm", "table", "obtained", "may", "kqk", "matrix", "since", "shows", "onto", "kqkb", "also", "advances", "telemonitoring", "unsupervised", "set", "adaptation", "kernels", "basis"], "authors": ["Krikamol Muandet", "David Balduzzi,", "Bernhard Schoelkopf"], "thumbnail_path": "thumbnails/Domain Generalization via Invariant Feature Representation.jpg"}, {"title": "A PACBayesian Approach for Domain Adaptation with Specialization to Linear Classifiers", "topics": [0.019083245083046825, 0.01908371968839663, 0.90458322870864283, 0.019083297398815778, 0.019083168587075101, 0.019083340534022868], "pdf_url": "http://jmlr.org/proceedings/papers/v28/germain13.pdf", "most_common": ["domain", "target", "source", "bound", "adaptation", "def", "hypothesis", "disagreement", "two", "rps", "rpt", "theorem", "distribution", "one", "learning", "empirical", "rds", "linear", "divergence", "approach", "rdt", "pbda", "measure", "error", "risk", "section", "algorithm", "domains", "theory", "given", "generalization", "best", "prior", "equation", "terms", "gibbs", "let", "use", "following", "sample", "problem", "expected", "loss", "mansour", "least", "function", "note", "majority", "based", "marginals", "binary", "bounds", "data", "probability", "set", "posterior", "pseudometric", "consider", "coda", "germain", "optimal", "nips", "complexity", "derive", "propose", "labeling", "since", "average", "labels", "according", "moreover", "unlabeled", "analysis", "also", "design", "even", "suitable", "marginal", "related", "shows", "could", "laviolette", "vote", "see", "indeed", "quantities", "task", "similar", "distributions", "test", "results", "zhang", "every", "dasvm", "choice", "algorithms", "framework", "features", "another", "ability"], "authors": ["Pascal Germain", "Amaury Habrard", "Franois Laviolette", "Emilie Morvant"], "thumbnail_path": "thumbnails/A PACBayesian Approach for Domain Adaptation with Specialization to Linear Classifiers.jpg"}, {"title": "Sparse coding for multitask and transfer learning", "topics": [0.018576860799412908, 0.01857688106348588, 0.90710739160642606, 0.018576912891228228, 0.018585331846107465, 0.018576621793339545], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/maurer13.pdf", "most_common": ["learning", "tasks", "sparse", "method", "multitask", "set", "coding", "task", "transfer", "dictionary", "section", "data", "number", "performance", "error", "learn", "pontil", "bound", "algorithm", "figure", "also", "mtfl", "risk", "atoms", "sample", "machine", "maurer", "theorem", "case", "linear", "training", "one", "bounds", "environment", "probability", "corresponding", "use", "experiments", "given", "pixels", "model", "methods", "new", "mse", "xti", "term", "space", "target", "experiment", "proposed", "sparsity", "problem", "generated", "norm", "advantage", "vector", "used", "measure", "min", "yti", "dimensional", "vectors", "independent", "well", "analysis", "input", "predictor", "results", "large", "evgeniou", "obtained", "study", "following", "another", "size", "argyriou", "average", "quantity", "paper", "see", "result", "approach", "distribution", "using", "loss", "images", "hilbert", "setting", "code", "consider", "research", "second", "values", "regularization", "order", "chosen", "choose", "shown", "top", "assumption"], "authors": ["Andreas Maurer", "Massi Pontil", "Bernardino Romera-Paredes"], "thumbnail_path": "thumbnails/Sparse coding for multitask and transfer learning.jpg"}, {"title": "Bayesian Games for Adversarial Regression Problems", "topics": [0.021764730558748065, 0.021764786049450001, 0.89117543402037802, 0.021765149460405624, 0.021765001768772631, 0.021764898142245664], "pdf_url": "http://jmlr.org/proceedings/papers/v28/grosshans13.pdf", "most_common": ["bayesian", "equilibrium", "data", "costs", "regression", "games", "point", "game", "nash", "cost", "optimal", "training", "information", "model", "adversary", "learner", "time", "diag", "generator", "strategy", "minimax", "problems", "matrix", "unique", "one", "parameters", "expected", "action", "adversarial", "bayes", "players", "functions", "values", "study", "function", "application", "let", "may", "exists", "theorem", "rmse", "equation", "response", "ridge", "assumption", "lemma", "distribution", "value", "test", "instances", "robust", "given", "online", "points", "incomplete", "drawn", "according", "learning", "spam", "complete", "uniqueness", "spaces", "section", "figure", "parameter", "space", "vector", "evaluation", "target", "future", "show", "case", "taylor", "prior", "use", "actual", "existence", "least", "emails", "execution", "transformation", "convex", "shows", "therefore", "following", "standard", "instance", "set", "however", "uncertainty", "empirical", "optimization", "input", "loss", "models", "algorithm", "approximation", "iid", "harsanyi", "science"], "authors": ["Michael Grohans", "Christoph Sawade", "Michael Brckner", "Tobias Scheffer"], "thumbnail_path": "thumbnails/Bayesian Games for Adversarial Regression Problems.jpg"}, {"title": "Joint Transfer and Batchmode Active Learning", "topics": [0.021873206809981165, 0.021873229862794046, 0.8906337441021176, 0.02187349690059838, 0.021873107101245671, 0.021873215223263107], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chattopadhyay13.pdf", "most_common": ["data", "domain", "target", "learning", "active", "source", "transfer", "set", "labeled", "selected", "instances", "proposed", "figure", "method", "samples", "mmd", "performance", "unlabeled", "two", "sets", "based", "performed", "adaptation", "problem", "query", "joint", "distribution", "marginal", "term", "using", "vector", "probability", "also", "accuracy", "comparative", "bdgp", "formulation", "test", "shown", "image", "weights", "optimization", "synthetic", "categories", "sentiment", "shows", "randomly", "batch", "analysis", "performing", "stage", "methods", "similar", "value", "learned", "newsgroups", "work", "nips", "used", "size", "number", "iteration", "later", "selection", "borgwardt", "kernel", "improved", "iterations", "better", "observe", "machine", "similarity", "existing", "second", "gretton", "represented", "domains", "via", "information", "every", "framework", "related", "electronics", "approach", "consisting", "however", "kitchen", "corresponding", "perform", "quadratic", "stages", "results", "guo", "section", "simultaneously", "select", "would", "selects", "following", "university"], "authors": ["Rita Chattopadhyay", "Wei Fan", "Ian Davidson", "Sethuraman Panchanathan", "Jieping Ye"], "thumbnail_path": "thumbnails/Joint Transfer and Batchmode Active Learning.jpg"}, {"title": "Multilinear Multitask Learning", "topics": [0.018520190890953182, 0.018519869556992644, 0.90738884458837232, 0.018520329156317825, 0.018530372954000573, 0.018520392853363279], "pdf_url": "http://jmlr.org/proceedings/papers/v28/romera-paredes13.pdf", "most_common": ["learning", "multilinear", "tensor", "multitask", "tasks", "set", "convex", "problem", "approaches", "approach", "data", "one", "matrix", "training", "mtl", "methods", "dataset", "tensors", "restaurant", "regression", "section", "two", "values", "see", "use", "models", "norm", "figure", "instances", "ranks", "example", "machine", "based", "facial", "weight", "algorithm", "synthetic", "order", "factors", "argyriou", "trace", "matricization", "described", "task", "mlmtl", "real", "decomposition", "also", "results", "second", "mse", "regularization", "product", "tucker", "error", "proposed", "minimization", "consider", "alternating", "international", "method", "relaxation", "would", "feature", "experiments", "related", "used", "shown", "maurer", "rank", "min", "pontil", "conference", "model", "transfer", "datasets", "vectors", "information", "natural", "mode", "number", "size", "given", "factorization", "common", "however", "among", "case", "solve", "improvement", "input", "pages", "grouped", "ridge", "generated", "signoretto", "rankn", "original", "leads", "finally"], "authors": ["Bernardino Romera-Paredes", "Hane Aung", "Nadia Bianchi-Berthouze", "Massimiliano Pontil"], "thumbnail_path": "thumbnails/Multilinear Multitask Learning.jpg"}, {"title": "Stability and Hypothesis Transfer Learning", "topics": [0.020477233877167381, 0.020478056642866286, 0.89760760655137517, 0.02047748419925095, 0.020478181033789736, 0.020481437695550553], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kuzborskij13.pdf", "most_common": ["algorithm", "hypothesis", "source", "learning", "htl", "stability", "bound", "transfer", "loo", "training", "target", "risk", "lemma", "also", "bounds", "bousquet", "using", "set", "theorem", "case", "upper", "generalization", "term", "domains", "algorithms", "orabona", "following", "hence", "result", "analysis", "loss", "use", "proof", "domain", "theory", "rls", "problem", "second", "theoretical", "work", "optimal", "used", "one", "parameters", "small", "section", "fact", "expected", "biased", "mansour", "related", "divergence", "note", "however", "conference", "bayesian", "regularized", "sample", "machine", "ieee", "since", "probability", "given", "least", "tommasi", "ahtl", "truncation", "respect", "unlabeled", "proposed", "samples", "form", "bounded", "particular", "hypotheses", "inequality", "squares", "see", "performance", "closed", "drawn", "according", "polynomial", "empirical", "model", "practical", "supervised", "way", "function", "results", "expressed", "access", "new", "prior", "additive", "negative", "regularization", "assumption", "multiple", "class"], "authors": ["Ilja Kuzborskij", "Francesco Orabona"], "thumbnail_path": "thumbnails/Stability and Hypothesis Transfer Learning.jpg"}, {"title": "MultiTask Learning with Gaussian Matrix Generalized Inverse Gaussian Model", "topics": [0.015622620451240531, 0.015622447324168783, 0.92188375795164179, 0.01562454830609958, 0.015624255372771567, 0.015622370594077797], "pdf_url": "http://jmlr.org/proceedings/papers/v28/yang13d.pdf", "most_common": ["matrix", "learning", "model", "distribution", "mgig", "gmgig", "tasks", "regression", "sampling", "covariance", "task", "gaussian", "structure", "etr", "inverse", "methods", "zhang", "wishart", "error", "set", "problem", "among", "approximation", "samples", "prior", "multiple", "bessel", "journal", "two", "matrices", "machine", "dataset", "research", "variate", "function", "also", "multivariate", "residual", "positive", "correlation", "nips", "mean", "generalized", "degree", "landmine", "butler", "data", "statistics", "training", "size", "relationship", "average", "estimation", "freedom", "gig", "auc", "propose", "mode", "weight", "since", "random", "mgh", "herein", "make", "obtain", "performance", "log", "sbmtl", "section", "method", "parameters", "inference", "controlling", "figure", "beyond", "toy", "surplus", "argyriou", "corresponding", "able", "using", "sparse", "ishart", "scores", "proposition", "norm", "chen", "marginal", "archambeau", "feature", "parameter", "product", "evaluations", "statistical", "framework", "hence", "detection", "class", "joint", "various"], "authors": ["Ming Yang", "Li Yingming", "Zhang Zhongfei (Mark)"], "thumbnail_path": "thumbnails/MultiTask Learning with Gaussian Matrix Generalized Inverse Gaussian Model.jpg"}, {"title": "Convex Relaxations for Learning BoundedTreewidth Decomposable Graphs", "topics": [0.017534567519225365, 0.017535216477890216, 0.91231658316818964, 0.017537823854594774, 0.017535532644877071, 0.017540276335222968], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kumar13c.pdf", "most_common": ["decomposable", "problem", "convex", "graph", "junction", "learning", "set", "cliques", "may", "number", "constraint", "tree", "graphs", "algorithm", "dual", "see", "constraints", "variables", "optimization", "section", "figure", "clique", "edges", "function", "relaxation", "graphical", "edge", "distributions", "greedy", "two", "algorithms", "hypergraph", "hyperforest", "treewidth", "maximum", "consider", "maximal", "likelihood", "one", "models", "structure", "complexity", "combinatorial", "log", "jordan", "trees", "polytope", "using", "guestrin", "forest", "given", "acyclicity", "relaxations", "selection", "primal", "acyclic", "koller", "show", "supergradient", "thus", "distribution", "srebro", "bounded", "selected", "obtained", "search", "use", "values", "following", "performance", "incidence", "covariance", "approximate", "relaxed", "entropies", "vertex", "discrete", "inference", "information", "represents", "shown", "probability", "size", "exactly", "representing", "note", "friedman", "random", "based", "approach", "chechetka", "value", "property", "equivalent", "hyperedge", "cardinality", "matroid", "compare", "table", "paper"], "authors": ["Sesh Kumar K. S.", "Francis Bach"], "thumbnail_path": "thumbnails/Convex Relaxations for Learning BoundedTreewidth Decomposable Graphs.jpg"}, {"title": " SVM for Learning with Label Proportions", "topics": [0.018714416645902912, 0.018714092231397847, 0.90642870039916335, 0.018714394385542902, 0.018714002193734536, 0.018714394144258479], "pdf_url": "http://jmlr.org/proceedings/papers/v28/yu13a.pdf", "most_common": ["learning", "label", "invcal", "meanmap", "bag", "proportions", "data", "objective", "kernel", "method", "algorithm", "convex", "labels", "section", "linear", "one", "conference", "bags", "machine", "mean", "instance", "problem", "solve", "max", "used", "proceedings", "show", "optimization", "yyt", "dataset", "training", "min", "international", "model", "also", "function", "solution", "proportion", "table", "yactive", "randomly", "two", "datasets", "takes", "solving", "term", "unknown", "quadrianto", "performance", "multiple", "proposed", "similar", "svm", "alternating", "parameters", "following", "algorithms", "framework", "shown", "log", "based", "relaxation", "solved", "use", "therefore", "example", "experiments", "size", "given", "tuned", "simple", "complexity", "using", "loss", "supervised", "clustering", "distribution", "formulation", "setting", "time", "proposition", "smaller", "positive", "figure", "assumptions", "annealing", "group", "research", "initialize", "times", "vote", "outperforms", "accuracy", "explicitly", "violated", "approach", "however", "rbf", "journal", "hand"], "authors": ["Felix Yu", "Dong Liu", "Sanjiv Kumar", "Jebara Tony", "Shih-Fu Chang"], "thumbnail_path": "thumbnails/ SVM for Learning with Label Proportions.jpg"}, {"title": "Consistency of Online Random Forests", "topics": [0.018571157672935535, 0.018574336760469309, 0.90714005230303596, 0.018571682379104473, 0.018571255974329303, 0.018571514910125191], "pdf_url": "http://jmlr.org/proceedings/papers/v28/denil13.pdf", "most_common": ["random", "online", "tree", "leaf", "forests", "split", "data", "consistency", "candidate", "algorithm", "forest", "points", "trees", "two", "class", "structure", "set", "leafs", "probability", "fringe", "used", "statistics", "use", "stream", "number", "one", "model", "estimation", "depth", "consistent", "memory", "accuracy", "show", "condition", "body", "figure", "must", "training", "partition", "point", "problem", "proposition", "order", "paper", "size", "theorem", "requires", "labels", "randomness", "growing", "information", "shows", "bayes", "also", "experiment", "result", "described", "breiman", "analysis", "domingos", "inactive", "sequence", "posterior", "time", "splitting", "children", "technique", "theoretical", "work", "minimum", "maintain", "hulten", "base", "however", "new", "error", "regression", "decision", "partitioning", "risk", "small", "section", "active", "prove", "algorithms", "pixel", "practice", "framework", "structural", "since", "created", "prediction", "part", "performance", "bifet", "distribution", "many", "streams", "value", "averaging"], "authors": ["Misha Denil", "David Matheson", "De Freitas Nando"], "thumbnail_path": "thumbnails/Consistency of Online Random Forests.jpg"}, {"title": "Inference algorithms for patternbased CRFs on sequence data", "topics": [0.021653060451103795, 0.021653208647878643, 0.89173354457697218, 0.021653409793697332, 0.021653131407124531, 0.021653645123223434], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kolmogorov13.pdf", "most_common": ["set", "patterns", "algorithm", "algorithms", "pattern", "sequence", "computing", "inference", "crfs", "messages", "given", "values", "complexity", "time", "use", "following", "max", "data", "used", "problem", "compute", "sample", "log", "step", "case", "let", "number", "random", "consider", "note", "section", "computed", "model", "example", "labeling", "length", "also", "words", "present", "semiring", "nodes", "lemma", "one", "tree", "min", "general", "angles", "position", "theorem", "conditional", "assume", "preprocessing", "map", "distribution", "sum", "respectively", "two", "holds", "order", "energy", "since", "takhanov", "crf", "labelings", "thus", "need", "costs", "previous", "input", "using", "function", "node", "partial", "graph", "prediction", "complexities", "word", "probability", "done", "size", "komodakis", "clearly", "letter", "paragios", "get", "kolmogorov", "sampling", "learning", "commutative", "hmm", "value", "protein", "subtree", "sets", "per", "assuming", "equivalent", "icml", "partition", "children"], "authors": ["Rustem Takhanov", "Vladimir Kolmogorov"], "thumbnail_path": "thumbnails/Inference algorithms for patternbased CRFs on sequence data.jpg"}, {"title": "Relaxed expectation propagation based on l", "topics": [0.017203905506721535, 0.017203845578015544, 0.91397618793217028, 0.017203854264471498, 0.017203783443823895, 0.017208423274797269], "pdf_url": "http://jmlr.org/proceedings/papers/v28/qi13.pdf", "most_common": ["rep", "message", "factor", "power", "figure", "divergence", "dep", "labeling", "passing", "exact", "penalized", "moment", "pep", "inference", "error", "matching", "minimization", "approximation", "training", "new", "belief", "function", "posterior", "test", "data", "set", "relaxation", "rbp", "energy", "iterations", "gaussian", "propagation", "decision", "approximate", "updates", "penalty", "bayesian", "used", "obtain", "minka", "dataset", "based", "estimation", "bij", "algorithm", "results", "damped", "mean", "accuracy", "points", "mrf", "samples", "section", "fractional", "process", "prediction", "family", "two", "following", "algorithms", "errors", "relaxed", "convergence", "discrete", "adaptive", "number", "quality", "accuracies", "mrfs", "see", "higher", "minimize", "step", "distribution", "distributions", "models", "averaged", "use", "cases", "heskes", "information", "factors", "randomly", "estimated", "show", "expectation", "boundary", "reduces", "old", "datasets", "compute", "update", "method", "experiments", "weight", "red", "interactions", "size", "given", "rates"], "authors": ["Yuan Qi", "Yandong Guo"], "thumbnail_path": "thumbnails/Relaxed expectation propagation based on l.jpg"}, {"title": "A Fast and Exact Energy Minimization Algorithm for Cycle MRFs", "topics": [0.021408667281410006, 0.021409243143585738, 0.8929350146825733, 0.021425662959354053, 0.021412221486558525, 0.021409190446518383], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wang13f.pdf", "most_common": ["cycle", "dual", "energy", "decomposition", "algorithm", "messages", "fast", "updates", "subproblems", "mrfs", "entries", "mrf", "solver", "message", "time", "min", "using", "minimization", "map", "tree", "methods", "variable", "one", "problem", "exact", "inference", "cycles", "method", "mcauley", "two", "solving", "sontag", "note", "compute", "general", "large", "potentials", "image", "clique", "need", "state", "running", "section", "active", "usually", "use", "number", "felzenszwalb", "also", "objective", "computed", "used", "sparse", "subproblem", "seconds", "computing", "structure", "synthetic", "variables", "relaxation", "given", "komodakis", "show", "conditions", "however", "case", "design", "dechter", "sun", "jaakkola", "machine", "instances", "edge", "reparametrization", "set", "passing", "protein", "edges", "well", "pose", "update", "marinescu", "consider", "would", "comparing", "optimizing", "work", "criterion", "fully", "subset", "shown", "koller", "incomplete", "david", "estimation", "table", "observe", "average", "column", "bound"], "authors": ["Huayan Wang", "Koller Daphne"], "thumbnail_path": "thumbnails/A Fast and Exact Energy Minimization Algorithm for Cycle MRFs.jpg"}, {"title": "SubproblemTree Calibration A Unified Approach to MaxProduct Message Passing", "topics": [0.019525308066847488, 0.019526260890487868, 0.90237124584894168, 0.019525575632548829, 0.019525816997699102, 0.019525792563474989], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wang13b.pdf", "most_common": ["dual", "subproblem", "tree", "subproblems", "stc", "mplp", "message", "passing", "bethe", "objective", "msd", "proposition", "mrf", "methods", "blocks", "allocation", "messages", "sontag", "cycle", "bcd", "two", "one", "edges", "trees", "potentials", "algorithm", "given", "note", "unary", "block", "weights", "seconds", "jaakkola", "cluster", "variables", "decomposition", "problem", "time", "pass", "map", "max", "weak", "primal", "calibration", "existing", "nodes", "use", "algorithms", "could", "approach", "without", "graph", "downstream", "design", "better", "optimal", "smg", "kolmogorov", "strong", "general", "used", "inference", "equivalent", "applying", "meltzer", "choice", "assignments", "choices", "scope", "choose", "enforces", "consistency", "globerson", "grid", "satisfy", "spanning", "constraints", "restricted", "show", "however", "well", "choosing", "constraint", "larger", "example", "shown", "performs", "many", "much", "case", "protein", "arbitrary", "step", "denote", "original", "applied", "relaxation", "therefore", "states", "edge"], "authors": ["Huayan Wang", "Koller Daphne"], "thumbnail_path": "thumbnails/SubproblemTree Calibration A Unified Approach to MaxProduct Message Passing.jpg"}, {"title": "Approximate Inference in Collective Graphical Models", "topics": [0.018580404129243583, 0.018580692546689866, 0.90709730211825723, 0.018580664293137726, 0.018580309517613032, 0.018580627395058596], "pdf_url": "http://jmlr.org/proceedings/papers/v28/sheldon13.pdf", "most_common": ["inference", "map", "model", "graphical", "models", "approximate", "time", "variables", "problem", "gibbs", "marginal", "cgms", "aggregate", "tables", "exact", "individual", "nij", "log", "collective", "cgm", "algorithm", "sheldon", "statistics", "number", "population", "size", "parameters", "running", "relative", "approximation", "contingency", "message", "observations", "error", "solution", "values", "figure", "markov", "passing", "data", "probability", "one", "observed", "learning", "may", "algorithms", "sampling", "distribution", "dietterich", "two", "used", "tree", "table", "noisy", "polynomial", "saem", "general", "optimization", "junction", "variable", "discrete", "vector", "section", "counts", "hidden", "lifted", "also", "show", "bird", "mcem", "reference", "seconds", "step", "true", "results", "entries", "large", "constraints", "runs", "mean", "random", "migration", "however", "case", "thus", "using", "within", "node", "following", "let", "poisson", "takes", "probabilities", "excellent", "parameter", "birds", "given", "observation", "iterations", "fractional"], "authors": ["Daniel Sheldon", "Tao Sun", "Akshat Kumar", "Tom Dietterich"], "thumbnail_path": "thumbnails/Approximate Inference in Collective Graphical Models.jpg"}, {"title": "An Adaptive Learning Rate for Stochastic Variational Inference", "topics": [0.019383398507727249, 0.019384227183882611, 0.90302652752511636, 0.019383429324047494, 0.019438917182020728, 0.019383500277205409], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/ranganath13.pdf", "most_common": ["learning", "rate", "variational", "stochastic", "inference", "adaptive", "data", "best", "parameters", "global", "local", "update", "algorithm", "log", "gradient", "large", "natural", "set", "distribution", "constant", "family", "optimal", "parameter", "variables", "blei", "noisy", "current", "topic", "iteration", "figure", "bayesian", "coordinate", "batch", "method", "estimate", "dirichlet", "given", "elbo", "objective", "three", "model", "better", "size", "new", "predictive", "hidden", "used", "moving", "step", "compute", "setting", "models", "time", "appear", "likelihood", "documents", "however", "expected", "optimization", "sampled", "using", "posterior", "convergence", "use", "averages", "wang", "times", "machine", "decreasing", "york", "optimum", "topics", "latent", "approach", "ascent", "approximate", "analyze", "compared", "estimates", "section", "found", "monro", "intermediate", "corpus", "note", "also", "probabilistic", "problem", "point", "error", "neural", "subsampled", "processing", "within", "vocabulary", "requires", "prior", "contains", "two", "robbins"], "authors": ["Rajesh Ranganath", "Chong Wang", "Blei David", "Eric Xing"], "thumbnail_path": "thumbnails/An Adaptive Learning Rate for Stochastic Variational Inference.jpg"}, {"title": "The Bigraphical Lasso", "topics": [0.015738326552788905, 0.015737629195902818, 0.92130960263791817, 0.015737875649020995, 0.015737718094839721, 0.015738847869529317], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kalaitzis13.pdf", "most_common": ["matrix", "precision", "data", "biglasso", "structure", "lasso", "model", "gaussian", "smgm", "covariance", "graph", "matrices", "figure", "sample", "sparse", "bigraphical", "normal", "graphical", "also", "algorithm", "glasso", "features", "note", "trp", "two", "one", "columns", "approach", "university", "likelihood", "size", "pixels", "learning", "samples", "frames", "rows", "simulations", "journal", "models", "markov", "video", "dependencies", "number", "graphs", "frame", "modeling", "kronecker", "density", "sparsity", "conditional", "block", "form", "box", "example", "product", "statistical", "estimating", "research", "induced", "independence", "shows", "lawrence", "cartesian", "structures", "design", "random", "parameters", "across", "estimation", "tang", "reduced", "coil", "distribution", "leng", "generated", "results", "case", "estimates", "additive", "outputs", "problem", "process", "machine", "blocks", "complexity", "american", "since", "theory", "similarly", "assumption", "penalty", "see", "many", "maximum", "network", "inverse", "vector", "spectral", "penalized", "usa"], "authors": ["Alfredo Kalaitzis", "John Lafferty", "Neil Lawrence"], "thumbnail_path": "thumbnails/The Bigraphical Lasso.jpg"}, {"title": "Anytime Representation Learning", "topics": [0.014587221355241495, 0.014587231597945883, 0.92706373821296972, 0.014587421254259698, 0.014587090296233823, 0.014587297283349437], "pdf_url": "http://jmlr.org/proceedings/papers/v28/xu13b.pdf", "most_common": ["cost", "feature", "learning", "anytime", "representation", "set", "features", "data", "svm", "use", "loss", "afr", "gradient", "learned", "greedy", "tree", "function", "training", "budget", "algorithm", "miser", "accuracy", "also", "evaluation", "trees", "test", "time", "validation", "two", "gbrt", "learn", "chapelle", "using", "setting", "chen", "inputs", "scene", "squared", "extraction", "boosted", "parameters", "applications", "representations", "new", "results", "vector", "train", "machine", "matrix", "boosting", "number", "one", "friedman", "class", "optimization", "dimension", "weinberger", "prediction", "current", "nips", "linear", "weak", "regression", "decision", "image", "problem", "yahoo", "budgets", "cascade", "algorithms", "weight", "min", "based", "approach", "let", "hinge", "evaluate", "support", "grubb", "total", "figure", "derivative", "within", "bagnell", "costs", "performance", "object", "ranking", "however", "gao", "value", "obtain", "input", "icml", "compute", "denote", "curve", "cpu", "original", "limited"], "authors": ["Zhixiang Xu", "Matt Kusner", "Gao Huang", "Kilian Weinberger"], "thumbnail_path": "thumbnails/Anytime Representation Learning.jpg"}, {"title": "LargeScale Bandit Problems and KWIK Learning", "topics": [0.01792182131053215, 0.017921274656888253, 0.91038798136634558, 0.017921659306779129, 0.017925686638494275, 0.017921576720960838], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/abernethy13.pdf", "most_common": ["kwik", "algorithm", "learning", "action", "mab", "actions", "learner", "new", "model", "problems", "let", "theorem", "class", "state", "problem", "large", "bandit", "sequence", "arriving", "show", "set", "optimization", "supervised", "assumptions", "models", "round", "end", "reduction", "space", "kwikf", "regret", "given", "returns", "proceedings", "conference", "case", "function", "also", "time", "littman", "results", "prediction", "since", "learnability", "thus", "bound", "trials", "every", "langford", "algorithms", "standard", "one", "exists", "shall", "possible", "functions", "consider", "presented", "value", "knows", "example", "weaker", "walsh", "assumption", "subroutine", "online", "performance", "make", "search", "showing", "arbitrary", "pool", "assume", "must", "sublinear", "give", "states", "optimal", "linear", "number", "pairwise", "added", "available", "however", "obtain", "immediately", "either", "noisy", "beygelzimer", "bounded", "bandits", "query", "corollary", "maxat", "rate", "selected", "use", "therefore", "information", "parameter"], "authors": ["Jacob Abernethy", "Kareem Amin", "Michael Kearns", "Moez Draief"], "thumbnail_path": "thumbnails/LargeScale Bandit Problems and KWIK Learning.jpg"}, {"title": "Stochastic Gradient Descent for Nonsmooth Optimization Convergence Results and Optimal Averaging Schemes", "topics": [0.022916546875614379, 0.022918064715706333, 0.88541201047772389, 0.022916102505063596, 0.022921871909615706, 0.022915403516276026], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/shamir13.pdf", "most_common": ["log", "averaging", "convex", "sgd", "bound", "optimal", "iterates", "results", "iterate", "stochastic", "convergence", "bounds", "last", "schemes", "rakhlin", "simple", "also", "case", "get", "individual", "general", "upper", "gradient", "scheme", "average", "optimization", "using", "analysis", "error", "proof", "function", "let", "expected", "descent", "one", "theorem", "consider", "following", "holds", "since", "obtain", "learning", "use", "assumptions", "instead", "rates", "implies", "existing", "convexity", "rate", "new", "subgradient", "example", "machine", "algorithms", "paper", "smoothness", "easily", "inequality", "standard", "hazan", "note", "performance", "computed", "used", "see", "without", "shamir", "strongly", "constant", "technique", "obtained", "still", "suboptimal", "plugging", "result", "best", "terms", "suppose", "running", "follows", "often", "algorithm", "denote", "problems", "assume", "required", "time", "finally", "zhang", "vector", "prove", "constants", "imply", "return", "practice", "shown", "training", "open", "given"], "authors": ["Ohad Shamir", "Tong Zhang"], "thumbnail_path": "thumbnails/Stochastic Gradient Descent for Nonsmooth Optimization Convergence Results and Optimal Averaging Schemes.jpg"}, {"title": "Optimal rates for stochastic convex optimization under Tsybakov noise condition", "topics": [0.017014866629560293, 0.017015960307503609, 0.91492080124094921, 0.017014997948644438, 0.017018340908854974, 0.017015032964487524], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/ramdas13.pdf", "most_common": ["convex", "function", "rates", "optimization", "bounds", "functions", "lower", "learning", "active", "log", "stochastic", "set", "bound", "condition", "let", "convexity", "gradient", "noise", "strongly", "optimal", "using", "algorithm", "oracle", "proof", "probability", "get", "tnc", "also", "tsybakov", "sup", "lemma", "point", "around", "rate", "nowak", "inf", "hence", "hazan", "show", "kale", "use", "theorem", "decision", "two", "max", "minimizer", "complexity", "least", "castro", "error", "true", "upper", "prove", "known", "order", "inequality", "boundary", "queries", "minimax", "tight", "bounded", "since", "one", "given", "returns", "see", "optimum", "choose", "problem", "setting", "everywhere", "subgradient", "values", "minimum", "information", "classes", "note", "iouditski", "result", "label", "follows", "nesterov", "appendix", "results", "sign", "uniform", "strong", "derive", "theory", "oracles", "gives", "strength", "shall", "nemirovski", "connection", "well", "like", "yudin", "noisy", "similar"], "authors": ["Aaditya Ramdas", "Aarti Singh"], "thumbnail_path": "thumbnails/Optimal rates for stochastic convex optimization under Tsybakov noise condition.jpg"}, {"title": "Fast Semidifferentialbased Submodular Function Optimization", "topics": [0.023012655261130784, 0.023062347743861757, 0.88487711933760715, 0.023019459979384177, 0.023015634926974005, 0.023012782751042252], "pdf_url": "http://jmlr.org/proceedings/papers/v28/iyer13.pdf", "most_common": ["submodular", "function", "bilmes", "minimization", "algorithms", "algorithm", "approximation", "set", "functions", "maximization", "problems", "jegelka", "optimization", "factor", "unconstrained", "iyer", "subgradient", "problem", "constrained", "theorem", "mmax", "bound", "local", "time", "results", "instances", "mmin", "many", "lattice", "theoretical", "permutation", "minimum", "fast", "lin", "random", "bounds", "using", "case", "modular", "use", "cases", "machine", "framework", "greedy", "discrete", "even", "search", "optimal", "solution", "lemma", "iteration", "speech", "new", "learning", "used", "fujishige", "cost", "figure", "nips", "yields", "assume", "let", "example", "therefore", "combinatorial", "subgradients", "achieves", "best", "point", "polynomial", "krause", "shows", "dls", "empirical", "known", "holds", "may", "worst", "concave", "subset", "rls", "iterations", "show", "minimizing", "however", "running", "also", "moreover", "step", "constraints", "often", "tight", "whose", "goel", "narasimhan", "path", "via", "inference", "two", "cardinality"], "authors": ["Rishabh Iyer", "Stefanie Jegelka", "Jeff Bilmes"], "thumbnail_path": "thumbnails/Fast Semidifferentialbased Submodular Function Optimization.jpg"}, {"title": "A proximal Newton framework for composite minimization Graph learning without Cholesky decompositions and matrix inversions", "topics": [0.017502527916308103, 0.017502509101595173, 0.91248728319006467, 0.017502737502208963, 0.017502366997235497, 0.017502575292587738], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/trandinh13.pdf", "most_common": ["dpngs", "solution", "algorithm", "matrix", "newton", "proximal", "quic", "graph", "convex", "scheme", "problem", "framework", "selection", "let", "quadratic", "dual", "phase", "covariance", "theorem", "function", "convergence", "dom", "composite", "iterations", "learning", "note", "compute", "unique", "minimization", "inverse", "since", "sparse", "new", "figure", "complexity", "given", "iteration", "objective", "point", "methods", "kmax", "following", "hence", "method", "cholesky", "approach", "optimization", "numerical", "using", "subproblem", "step", "primal", "time", "code", "damped", "via", "number", "direction", "nesterov", "generated", "vec", "section", "use", "jmax", "gradient", "min", "show", "require", "sequence", "within", "maximum", "requires", "results", "inversions", "values", "lemma", "log", "iterative", "one", "size", "analysis", "hsieh", "also", "decompositions", "set", "estimation", "moreover", "instance", "cost", "next", "parallel", "nonsmooth", "solving", "inversion", "found", "operation", "shows", "need", "computation", "solutions"], "authors": ["Quoc Tran Dinh", "Anastasios Kyrillidis", "Volkan Cevher"], "thumbnail_path": "thumbnails/A proximal Newton framework for composite minimization Graph learning without Cholesky decompositions and matrix inversions.jpg"}, {"title": "MiniBatch Primal and Dual Methods for SVMs", "topics": [0.018233030678839936, 0.018233257981179835, 0.90881784331809645, 0.018243981262111922, 0.018238917416067285, 0.018232969343704622], "pdf_url": "http://jmlr.org/proceedings/papers/v28/takac13.pdf", "most_common": ["sdca", "pegasos", "dual", "methods", "primal", "analysis", "using", "stochastic", "objective", "norm", "data", "spectral", "also", "iterations", "aggressive", "descent", "coordinate", "bound", "iteration", "training", "number", "size", "speedups", "parallel", "based", "thus", "parallelization", "sgd", "use", "variant", "approach", "loss", "step", "similar", "svms", "method", "lemma", "suboptimality", "svm", "naive", "speedup", "see", "point", "safe", "guarantees", "update", "consider", "section", "might", "linear", "theorem", "problem", "single", "required", "large", "max", "rand", "terms", "however", "zhang", "vector", "instead", "term", "gradient", "even", "quantity", "distributed", "experiments", "essentially", "case", "optimization", "according", "used", "examples", "ascent", "qii", "setting", "original", "results", "batch", "example", "provide", "actually", "bradley", "given", "note", "show", "random", "corresponding", "well", "obtain", "duchi", "algorithm", "small", "two", "theoretical", "work", "figure", "coordinates", "main"], "authors": ["Martin Takac", "Avleen Bijral", "Peter Richtarik", "Nati Srebro"], "thumbnail_path": "thumbnails/MiniBatch Primal and Dual Methods for SVMs.jpg"}, {"title": "Stochastic Alternating Direction Method of Multipliers", "topics": [0.12576216647573329, 0.021629514453306201, 0.78772042548193433, 0.021629758024506826, 0.021628728390495913, 0.02162940717402357], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/ouyang13.pdf", "most_common": ["stochastic", "admm", "convergence", "algorithm", "method", "convex", "one", "min", "online", "lasso", "methods", "alternating", "learning", "objective", "functions", "also", "direction", "optimization", "proximal", "setting", "problems", "deterministic", "linear", "problem", "function", "following", "arg", "augmented", "lagrangian", "simple", "machine", "approximation", "solution", "used", "assumption", "gradient", "linearized", "rates", "terms", "proposed", "banerjee", "risk", "rate", "use", "two", "siam", "strongly", "section", "wang", "paper", "optimal", "training", "given", "tibshirani", "set", "denote", "yuan", "constraint", "svm", "inverse", "updates", "feasibility", "penalty", "assumptions", "dataset", "structural", "boyd", "class", "value", "http", "minimize", "obtain", "multipliers", "samples", "theorem", "sparse", "splitting", "general", "results", "zhang", "vector", "composite", "work", "example", "algorithms", "lan", "related", "shown", "matrix", "log", "combettes", "able", "bregman", "minimizing", "based", "literature", "fobos", "loss", "regularized", "form"], "authors": ["Hua Ouyang", "Niao He", "Long Tran", "Alexander Gray"], "thumbnail_path": "thumbnails/Stochastic Alternating Direction Method of Multipliers.jpg"}, {"title": "Optimization with FirstOrder Surrogate Functions", "topics": [0.016709352567890495, 0.016709546313865946, 0.91645233093482725, 0.016711182437231648, 0.016708762208152976, 0.016708825538031751], "pdf_url": "http://jmlr.org/proceedings/papers/v28/mairal13.pdf", "most_common": ["convex", "surrogate", "algorithm", "optimization", "convergence", "surrogates", "proposition", "gradient", "scheme", "function", "dataset", "functions", "assume", "distance", "optimum", "majorant", "method", "nesterov", "following", "liblinear", "descent", "coordinate", "miso", "sag", "analysis", "bottou", "section", "data", "training", "rates", "also", "objective", "see", "using", "block", "incremental", "point", "update", "zhang", "next", "machine", "linear", "passes", "minimizing", "learning", "problems", "stochastic", "let", "study", "note", "arg", "present", "sgd", "methods", "teboulle", "beck", "regularization", "effective", "algorithms", "paper", "estimate", "number", "one", "iteration", "roux", "sec", "proximal", "asgd", "sparse", "classical", "time", "results", "fista", "condition", "solution", "obtained", "lipschitz", "shown", "min", "ocr", "choose", "strongly", "large", "asymptotic", "two", "assumptions", "instead", "accelerated", "used", "rate", "new", "logistic", "covtype", "near", "regression", "shotgun", "provided", "alpha", "log", "smooth"], "authors": ["Julien Mairal"], "thumbnail_path": "thumbnails/Optimization with FirstOrder Surrogate Functions.jpg"}, {"title": "Fast Probabilistic Optimization from Noisy Gradients", "topics": [0.016161373558973402, 0.016160111223407693, 0.91919680022891359, 0.016160110197062014, 0.016160067477485333, 0.016161537314157877], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/hennig13.pdf", "most_common": ["gradient", "optimization", "function", "hessian", "noise", "methods", "algorithm", "gaussian", "descent", "noisy", "cost", "mean", "learning", "linear", "method", "probabilistic", "two", "also", "kernel", "elements", "hennig", "stochastic", "algorithms", "independent", "fast", "prior", "kiefel", "thus", "using", "problem", "gradients", "nonparametric", "paper", "machine", "observations", "objective", "covariance", "posterior", "classic", "along", "inference", "use", "matrix", "observation", "numerical", "neural", "computation", "vectors", "space", "likelihood", "symmetric", "figure", "process", "nontrivial", "number", "fact", "new", "expensive", "model", "newton", "right", "would", "limit", "functions", "results", "choice", "shows", "second", "values", "information", "evaluations", "since", "training", "performance", "fletcher", "simple", "direction", "used", "well", "input", "like", "scale", "step", "form", "setting", "problems", "broyden", "exact", "vector", "even", "nonlinear", "section", "martens", "may", "estimate", "encoding", "one", "size", "belief", "networks"], "authors": ["Philipp Hennig"], "thumbnail_path": "thumbnails/Fast Probabilistic Optimization from Noisy Gradients.jpg"}, {"title": "A Local Algorithm for Finding WellConnected Clusters", "topics": [0.026515221276485968, 0.026516750357505402, 0.72372139919790834, 0.17021182335150303, 0.026518983750103642, 0.026515822066493631], "pdf_url": "http://jmlr.org/proceedings/papers/v28/allenzhu13.pdf", "most_common": ["vol", "vector", "pagerank", "algorithm", "gap", "set", "local", "random", "deg", "conductance", "vertices", "cut", "vertex", "probability", "one", "prv", "def", "walk", "theorem", "graph", "algorithms", "time", "starting", "sweep", "clustering", "let", "lemma", "andersen", "section", "study", "proof", "assumption", "two", "clusters", "cluster", "edges", "finding", "exists", "volume", "work", "better", "given", "prs", "approximate", "full", "cuts", "output", "also", "prove", "following", "inequality", "instance", "using", "properties", "log", "use", "guarantee", "teleport", "may", "connected", "running", "inside", "implies", "results", "large", "good", "see", "prl", "result", "second", "addition", "procedure", "conn", "analysis", "sets", "compute", "constant", "matrix", "consider", "small", "version", "round", "prior", "total", "theoretical", "particular", "data", "provide", "spielman", "pra", "note", "show", "teng", "case", "empirical", "well", "curve", "mixing", "upper", "approximation"], "authors": ["Silvio Lattanzi", "Vahab Mirrokni", "Zeyuan Allen Zhu"], "thumbnail_path": "thumbnails/A Local Algorithm for Finding WellConnected Clusters.jpg"}, {"title": "Monochromatic BiClustering ", "topics": [0.016283528221101077, 0.016283683015140653, 0.91857846102973195, 0.016286650583641343, 0.01628370312831735, 0.016283974022067601], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wulff13.pdf", "most_common": ["monochromatic", "cost", "matrix", "partition", "input", "data", "problem", "rows", "algorithm", "pattern", "values", "optimal", "size", "given", "approximation", "columns", "set", "sample", "column", "solution", "function", "number", "row", "entries", "groups", "clustering", "deterministic", "annealing", "domain", "solver", "task", "also", "optimization", "synthetic", "section", "majority", "one", "objective", "used", "agreement", "time", "version", "resulting", "use", "work", "tenenbaum", "expression", "ptas", "polynomial", "respect", "kemp", "noise", "biclustering", "results", "let", "proof", "blocks", "scheme", "show", "denote", "value", "assignment", "theorem", "guarantees", "computational", "level", "consider", "every", "two", "claim", "variant", "correlation", "clusters", "dataset", "homogeneous", "osherson", "length", "probability", "ideas", "relation", "based", "missing", "learning", "lower", "analysis", "existing", "matrices", "genes", "tasks", "formally", "following", "provide", "complexity", "block", "performs", "lowest", "viewed", "exp", "words", "result"], "authors": ["Sharon Wulff", "Ruth Urner", "Shai Ben-David"], "thumbnail_path": "thumbnails/Monochromatic BiClustering .jpg"}, {"title": "Constrained fractional set programs and their application in local clustering and community detection", "topics": [0.018417211133998926, 0.018419839625606373, 0.90658763183980928, 0.01972617413338397, 0.018431259659337711, 0.018417883607863658], "pdf_url": "http://jmlr.org/proceedings/papers/v28/buhler13.pdf", "most_common": ["set", "problem", "constrained", "cut", "graph", "constraints", "relaxation", "community", "fractional", "local", "problems", "tight", "functions", "normalized", "solution", "optimal", "seed", "min", "hein", "one", "clustering", "function", "method", "volg", "continuous", "detection", "mahoney", "volume", "vold", "given", "lovasz", "constraint", "spectral", "following", "cfsp", "programs", "theorem", "relaxations", "assoc", "however", "optimization", "balanced", "form", "let", "use", "guarantee", "paper", "ratio", "general", "lrw", "wij", "note", "setzer", "convex", "equivalent", "large", "via", "algorithms", "random", "moreover", "either", "extension", "ratiodca", "case", "obtained", "two", "work", "feasible", "andersen", "order", "saha", "show", "learning", "thus", "using", "minimization", "results", "program", "section", "found", "result", "also", "subject", "rangapuram", "denote", "vol", "methods", "bound", "lang", "algorithm", "upper", "thresholding", "applications", "cheeger", "cuts", "size", "unconstrained", "written", "sets", "density"], "authors": ["Thomas Bhler", "Shyam Sundar Rangapuram", "Simon Setzer", "Matthias Hein"], "thumbnail_path": "thumbnails/Constrained fractional set programs and their application in local clustering and community detection.jpg"}, {"title": "Breaking the Small Cluster Barrier of Graph Clustering", "topics": [0.019906531652704028, 0.019906706610452633, 0.90045761973028704, 0.019912934459771266, 0.019909243541910343, 0.019906964004874746], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ailon13.pdf", "most_common": ["clusters", "cluster", "clustering", "matrix", "graph", "one", "least", "log", "small", "size", "recover", "probability", "algorithm", "number", "large", "using", "solution", "theorem", "work", "partial", "observation", "planted", "set", "learning", "convex", "following", "nodes", "chen", "optimal", "sizes", "active", "barrier", "assume", "random", "smaller", "recovery", "algorithms", "experiment", "partition", "result", "case", "results", "rate", "recovered", "also", "ground", "exists", "interval", "norm", "larger", "theoretical", "values", "breaking", "previous", "big", "problem", "generated", "spectral", "known", "end", "ailon", "paper", "disjoint", "note", "based", "correctly", "jalali", "return", "model", "constant", "consider", "corollary", "induced", "correlation", "max", "constants", "analysis", "edge", "long", "method", "two", "particular", "grant", "proof", "hence", "given", "otherwise", "edges", "proposed", "guarantees", "possible", "sparse", "bound", "relaxation", "table", "obtained", "via", "apply", "recovers", "data"], "authors": ["Nir Ailon", "Yudong Chen", "Huan Xu"], "thumbnail_path": "thumbnails/Breaking the Small Cluster Barrier of Graph Clustering.jpg"}, {"title": "Strict Monotonicity of Sum of Squares Error and Normalized Cut in the Lattice of Clusterings", "topics": [0.022633649035825352, 0.02263323246753857, 0.81756420023427268, 0.091898019778800993, 0.022636351159275009, 0.02263454732428738], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/rebagliati13.pdf", "most_common": ["clustering", "sse", "let", "sum", "normalized", "strict", "cut", "clusters", "squares", "theorem", "error", "clusterings", "lemma", "ncut", "monotonicity", "xxt", "matrix", "two", "number", "eigenvalues", "points", "lattice", "dataset", "one", "strictly", "using", "since", "graph", "following", "get", "lgc", "proof", "cluster", "results", "connected", "set", "point", "value", "obtain", "input", "functional", "nagai", "interlace", "minimum", "dim", "hcj", "given", "indicator", "result", "proper", "monotone", "undirected", "values", "xcr", "data", "functionals", "vol", "weighted", "every", "prove", "used", "similarly", "jain", "observation", "relation", "acm", "bounds", "dimensional", "learning", "choosing", "meila", "chain", "section", "full", "allow", "machine", "instead", "side", "linear", "zero", "say", "min", "pair", "fact", "last", "general", "suppose", "interlacing", "proofs", "volume", "dimensionality", "matrices", "distinct", "cases", "work", "holds", "algebra", "may", "main", "greater"], "authors": ["Nicola Rebagliati"], "thumbnail_path": "thumbnails/Strict Monotonicity of Sum of Squares Error and Normalized Cut in the Lattice of Clusterings.jpg"}, {"title": "Clustering and Learning Behaviors using a Sparse Latent Space", "topics": [0.017304600281868789, 0.017304644275492807, 0.91347339343650835, 0.017306070245658764, 0.017306422320871401, 0.017304869439599833], "pdf_url": "http://jmlr.org/proceedings/papers/v28/almingol13.pdf", "most_common": ["trajectories", "behaviors", "number", "space", "learning", "dpmm", "clustering", "using", "parameters", "latent", "multiple", "matrix", "features", "controller", "prior", "algorithm", "trajectory", "behavior", "sparse", "figure", "robot", "linear", "unlabeled", "model", "results", "feature", "representation", "clusters", "bayesian", "models", "estimated", "shows", "mixture", "cluster", "one", "local", "sparsity", "due", "systems", "potential", "classes", "laplacian", "time", "reconstruction", "method", "two", "process", "correspondence", "motion", "used", "also", "possible", "distribution", "demonstrations", "objects", "information", "better", "rmse", "base", "generate", "given", "show", "data", "error", "compute", "global", "measure", "neural", "set", "processing", "function", "consider", "trc", "vector", "corr", "type", "work", "may", "gaussian", "dirichlet", "class", "based", "observed", "problem", "primitives", "proposed", "methods", "similar", "generated", "row", "large", "learn", "component", "obtained", "use", "representations", "nonparametric", "paper", "mean", "able"], "authors": ["Lui Montesano", "Manuel Lopes", "Javier Almingol"], "thumbnail_path": "thumbnails/Clustering and Learning Behaviors using a Sparse Latent Space.jpg"}, {"title": "Precisionrecall space to correct external indices for biclustering", "topics": [0.022658533220805105, 0.022659223133062945, 0.8866953103690709, 0.022659168291572048, 0.022665306493699293, 0.022662458491789626], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/hanczar13.pdf", "most_common": ["bicluster", "measure", "biclustering", "corrected", "measures", "precision", "size", "jaccard", "estimated", "space", "recall", "biclusters", "goodness", "indices", "true", "dice", "rec", "data", "external", "performance", "uncorrected", "isometrics", "point", "random", "two", "pre", "correct", "points", "show", "bias", "used", "line", "since", "algorithm", "expected", "comparison", "problem", "results", "large", "section", "give", "lines", "algorithms", "evaluation", "gray", "set", "importance", "reliable", "obtain", "represented", "following", "figure", "matrix", "correction", "nadif", "equal", "analysis", "compatible", "consider", "leads", "solution", "value", "therefore", "order", "paper", "threshold", "experiments", "see", "mjaccard", "three", "present", "property", "several", "intersection", "represent", "use", "clustering", "roc", "whose", "cheng", "compare", "machine", "optimal", "represents", "features", "mining", "depends", "note", "internal", "computed", "learning", "mdice", "examples", "range", "dotted", "generally", "important", "hanczar", "paris", "lee"], "authors": ["Blaise Hanczar", "Mohamed Nadif"], "thumbnail_path": "thumbnails/Precisionrecall space to correct external indices for biclustering.jpg"}, {"title": "Semisupervised Clustering by Input Pattern Assisted Pairwise Similarity Matrix Completion", "topics": [0.022782353932449501, 0.022770349070602207, 0.88613362786262995, 0.022774480553758348, 0.022769678277494765, 0.022769510303065312], "pdf_url": "http://jmlr.org/proceedings/papers/v28/yi13.pdf", "most_common": ["clustering", "matrix", "pairwise", "data", "constraints", "algorithm", "completion", "proposed", "number", "input", "similarity", "algorithms", "cluster", "learning", "pattern", "metric", "vectors", "assisted", "log", "distance", "points", "theorem", "problem", "large", "given", "constrained", "optimization", "following", "based", "jain", "assumption", "let", "binary", "partition", "spectral", "information", "two", "singular", "membership", "clusters", "set", "results", "entries", "small", "sample", "complexity", "framework", "basu", "top", "observed", "result", "using", "datasets", "theory", "bilenko", "work", "verify", "optimal", "max", "perfect", "size", "table", "analysis", "patterns", "icml", "theoretical", "tao", "solving", "shows", "probability", "coherence", "sampled", "liu", "semisupervised", "nips", "three", "mushrooms", "high", "evidently", "parameter", "experiments", "measure", "approximated", "since", "linear", "accurately", "randomly", "performance", "conditions", "key", "usps", "used", "eigenvectors", "well", "follows", "provided", "baseline", "true", "required", "existing"], "authors": ["Jinfeng Yi", "Rong Jin", "Qi Qian", "Anil Jain"], "thumbnail_path": "thumbnails/Semisupervised Clustering by Input Pattern Assisted Pairwise Similarity Matrix Completion.jpg"}, {"title": "Margins Shrinkage and Boosting", "topics": [0.01849564361090944, 0.018495825649423495, 0.90752320679019627, 0.018495212877938462, 0.018495243887297397, 0.018494867184234921], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/telgarsky13.pdf", "most_common": ["step", "boosting", "margins", "margin", "shrinkage", "convergence", "exp", "section", "loss", "theorem", "schapire", "size", "learning", "bound", "empirical", "lemma", "let", "work", "rates", "singer", "case", "telgarsky", "line", "instance", "logistic", "also", "methods", "consider", "risk", "may", "manuscript", "adaboost", "sizes", "general", "particular", "search", "hard", "wolfe", "analysis", "freund", "matrix", "exponential", "binary", "guarantees", "setting", "rate", "machine", "optimal", "since", "separable", "given", "bounds", "weak", "due", "robert", "algorithm", "choice", "figure", "provide", "parameter", "iterations", "achieve", "rudin", "core", "every", "method", "positive", "guarantee", "one", "scheme", "note", "algorithms", "considered", "set", "choices", "thus", "follows", "regularized", "examples", "properties", "maximum", "results", "condition", "presented", "upper", "maximization", "following", "proof", "max", "indeed", "used", "friedman", "exists", "comparison", "function", "problem", "additionally", "proposition", "consistent", "second"], "authors": ["Matus Telgarsky"], "thumbnail_path": "thumbnails/Margins Shrinkage and Boosting.jpg"}, {"title": "Sharp Generalization Error Bounds for Randomlyprojected Classifiers", "topics": [0.016422711853350591, 0.016422730937823305, 0.91788538530674035, 0.016423089466337047, 0.016423320766021796, 0.016422761669727025], "pdf_url": "http://jmlr.org/proceedings/papers/v28/durrant13.pdf", "most_common": ["data", "probability", "random", "generalization", "error", "bound", "bounds", "space", "rij", "projection", "cos", "theorem", "linear", "learning", "let", "gaussian", "projected", "margin", "therefore", "randomly", "using", "proof", "training", "angle", "distribution", "sign", "lemma", "independent", "log", "upper", "term", "since", "part", "use", "sharp", "durrant", "empirical", "obtain", "garg", "form", "entries", "matrix", "given", "estimate", "prr", "note", "label", "matrices", "also", "class", "rxi", "rxq", "results", "risk", "two", "classes", "result", "average", "exp", "set", "however", "surface", "make", "hand", "unit", "working", "high", "following", "complexity", "derive", "university", "points", "see", "conference", "sparse", "var", "function", "fact", "straightforward", "large", "small", "theory", "erm", "machine", "exact", "variables", "projections", "separable", "without", "loss", "area", "original", "dimensionality", "vector", "eigenvalues", "cap", "compressed", "vectors", "trained", "instead"], "authors": ["Robert Durrant", "Ata Kaban"], "thumbnail_path": "thumbnails/Sharp Generalization Error Bounds for Randomlyprojected Classifiers.jpg"}, {"title": "Risk Bounds and Learning Algorithms for the Regression Approach to Structured Output Prediction", "topics": [0.02083638037217244, 0.020836215927582832, 0.89581864185619919, 0.020836329923058915, 0.0208362325203434, 0.020836199400643306], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/giguere13.pdf", "most_common": ["risk", "output", "loss", "prediction", "kernel", "bound", "structured", "regression", "quadratic", "upper", "let", "def", "predictor", "learning", "bounds", "given", "case", "theorem", "predictors", "lky", "set", "approach", "use", "training", "empirical", "proposed", "problem", "also", "used", "cortes", "equation", "since", "feature", "minimizer", "lemma", "input", "solution", "provide", "whenever", "note", "task", "hierarchical", "taskar", "theory", "two", "machine", "predicted", "distribution", "using", "provides", "posterior", "results", "depend", "obtained", "sorr", "example", "instead", "matrix", "least", "exists", "however", "spaces", "consequently", "denote", "distributions", "consider", "deterministic", "stochastic", "vector", "small", "minimizes", "algorithms", "inequality", "sosc", "denotes", "hence", "probability", "hamming", "constraint", "markov", "prior", "table", "data", "one", "minimizing", "expectation", "according", "described", "frr", "see", "eigenvectors", "obtain", "arbitrary", "function", "rousu", "consists", "marchand", "zhang", "eigenvalues", "second"], "authors": ["Sbastien Gigure", "Francois Laviolette", "Mario Marchand", "Khadidja Sylla"], "thumbnail_path": "thumbnails/Risk Bounds and Learning Algorithms for the Regression Approach to Structured Output Prediction.jpg"}, {"title": "Collective Stability and Structured Prediction Generalization from One Example", "topics": [0.019678677619681468, 0.019678937156549513, 0.90159999570594318, 0.019681035445361872, 0.019679143322496356, 0.019682210749967701], "pdf_url": "http://jmlr.org/proceedings/papers/v28/london13.pdf", "most_common": ["structured", "stability", "collective", "let", "set", "bounds", "inference", "convex", "prediction", "generalization", "learning", "theorem", "function", "uniform", "variables", "single", "marginal", "lemma", "example", "number", "class", "random", "loss", "show", "conditions", "models", "complexity", "one", "size", "tsms", "given", "rademacher", "graph", "since", "using", "output", "dependence", "realizations", "strongly", "large", "section", "risk", "data", "clique", "probability", "hypothesis", "thus", "examples", "assume", "following", "map", "model", "denote", "functions", "consider", "feature", "machine", "training", "empirical", "error", "templates", "templated", "analysis", "previous", "bound", "approximate", "whose", "taskar", "every", "use", "measure", "also", "dependent", "exists", "arg", "uniformly", "maximum", "research", "norm", "markov", "interdependent", "neville", "prove", "derive", "lipschitz", "concentration", "satisfy", "state", "many", "marginals", "graphical", "independent", "via", "distribution", "constant", "journal", "bounded", "weights", "vector", "even"], "authors": ["Ben London", "Bert Huang", "Ben Taskar", "Lise Getoor"], "thumbnail_path": "thumbnails/Collective Stability and Structured Prediction Generalization from One Example.jpg"}, {"title": "Hierarchical Regularization Cascade for Joint Learning", "topics": [0.016547160495522566, 0.016543227297937956, 0.91727935021738771, 0.016543170262751088, 0.016543557259690759, 0.016543534466709996], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zweig13.pdf", "most_common": ["learning", "sharing", "algorithm", "tasks", "regularization", "hierarchical", "approach", "online", "cascade", "set", "hierarchy", "method", "task", "results", "information", "data", "feature", "levels", "parameters", "group", "single", "using", "used", "loss", "methods", "level", "large", "baseline", "performance", "dataset", "number", "scale", "batch", "datasets", "setting", "features", "classes", "joint", "learnt", "examples", "xing", "compared", "structure", "regret", "note", "also", "accuracy", "many", "optimization", "sparse", "synthetic", "known", "zhao", "kang", "denotes", "see", "thus", "function", "share", "combination", "object", "kim", "images", "quattoni", "random", "step", "tested", "work", "algorithms", "torralba", "nips", "related", "linear", "top", "new", "based", "lasso", "among", "without", "previous", "gehler", "recognition", "multiclass", "time", "similar", "advantage", "two", "visual", "nowozin", "sample", "order", "matrix", "size", "incentive", "achieve", "provided", "comparison", "argmin", "problem", "consider"], "authors": ["Alon Zweig", "Daphna Weinshall"], "thumbnail_path": "thumbnails/Hierarchical Regularization Cascade for Joint Learning.jpg"}, {"title": "Learning Fair Representations", "topics": [0.01622488633751247, 0.016226598495005729, 0.91887311195787869, 0.016224844717413978, 0.016225210194389886, 0.016225348297799157], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zemel13.pdf", "most_common": ["information", "model", "fairness", "fair", "learning", "representations", "data", "set", "protected", "representation", "individual", "mapping", "accuracy", "discrimination", "two", "new", "individuals", "input", "statistical", "intermediate", "group", "results", "based", "used", "parity", "decisions", "distance", "may", "training", "dwork", "approach", "problem", "learned", "trained", "use", "positive", "adult", "work", "dataset", "given", "also", "respect", "similar", "important", "method", "values", "learn", "example", "good", "privacy", "system", "conference", "prototype", "possible", "much", "variable", "membership", "health", "one", "aim", "test", "using", "calders", "predictor", "prototypes", "involves", "kamishima", "figure", "first", "proportion", "logistic", "however", "sensitive", "function", "datasets", "whether", "lfr", "algorithm", "labels", "prediction", "second", "groups", "criteria", "feature", "goal", "order", "term", "another", "space", "german", "random", "achieve", "kamiran", "key", "three", "optimization", "thus", "sacc", "bias", "regression"], "authors": ["Rich Zemel", "Yu Wu", "Kevin Swersky", "Toniann Pitassi", "Cynthia Dwork"], "thumbnail_path": "thumbnails/Learning Fair Representations.jpg"}, {"title": "Differentially Private Learning with Kernels", "topics": [0.017620095998431208, 0.017620182030535086, 0.9118731432642172, 0.017620657330165917, 0.017645670603619459, 0.017620250773031094], "pdf_url": "http://jmlr.org/proceedings/papers/v28/jain13.pdf", "most_common": ["private", "model", "test", "privacy", "data", "algorithm", "learner", "kernel", "error", "learning", "training", "chaudhuri", "method", "points", "set", "using", "predictions", "provide", "user", "dimensionality", "space", "problem", "dataset", "function", "small", "prediction", "section", "preserving", "linear", "also", "see", "log", "sends", "vector", "erm", "algorithms", "interactive", "however", "point", "kernels", "samples", "parameter", "accurate", "input", "methods", "bound", "feature", "generalization", "let", "might", "hence", "noise", "solution", "example", "sample", "restricted", "given", "output", "dwork", "case", "theorem", "similar", "rubinstein", "assume", "goal", "one", "note", "release", "general", "several", "guarantees", "provides", "version", "parameters", "would", "optimal", "mcsherry", "domain", "number", "accuracy", "trusted", "well", "setting", "access", "study", "learn", "figure", "end", "kerm", "size", "require", "show", "polynomial", "releasing", "loss", "practical", "models", "results", "work", "predict"], "authors": ["Prateek Jain", "Abhradeep Thakurta"], "thumbnail_path": "thumbnails/Differentially Private Learning with Kernels.jpg"}, {"title": "Rounding Methods for Discrete Linear Classification", "topics": [0.020426637562425, 0.020426519663161041, 0.89785820312075204, 0.020435095887846345, 0.02042699649324287, 0.020426547272572634], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/chevaleyre13.pdf", "most_common": ["linear", "riskm", "rounding", "set", "loss", "learning", "class", "risk", "discrete", "problem", "algorithm", "convex", "dataset", "functions", "optimization", "let", "vector", "algorithms", "solution", "value", "methods", "complexity", "rademacher", "cut", "data", "randomized", "hypothesis", "using", "examples", "hinge", "bounds", "fractional", "approximation", "two", "function", "greedy", "probability", "also", "performance", "lemma", "theorem", "time", "table", "training", "features", "number", "one", "bound", "test", "consider", "bacterial", "abundance", "values", "example", "feature", "result", "empirical", "setting", "weights", "concept", "synthetic", "following", "term", "since", "given", "part", "random", "sup", "simple", "cvx", "error", "thus", "binary", "constant", "denote", "next", "work", "species", "optimal", "inequality", "subset", "weight", "used", "denoted", "standard", "least", "rates", "measured", "get", "chevaleyre", "ones", "among", "cancer", "case", "evaluated", "taking", "integer", "rules", "follows", "datasets"], "authors": ["Yann Chevaleyre", "Frederick Koriche", "Jean-Daniel Zucker"], "thumbnail_path": "thumbnails/Rounding Methods for Discrete Linear Classification.jpg"}, {"title": "Squaredloss Mutual Information Regularization", "topics": [0.017341291966105281, 0.017344887302763651, 0.91328902889136288, 0.017342215573640764, 0.017341688536843231, 0.017340887729284389], "pdf_url": "http://jmlr.org/proceedings/papers/v28/niu13.pdf", "most_common": ["smir", "information", "regularization", "data", "error", "learning", "tasks", "mutual", "smi", "class", "usps", "table", "training", "methods", "solution", "labeled", "kernel", "best", "mnist", "entropy", "model", "kerxr", "isolet", "kerer", "optimization", "sugiyama", "optimal", "maximization", "comparable", "convex", "bounds", "probability", "probabilistic", "belkin", "based", "lgc", "empirical", "unlabeled", "simple", "experimental", "benchmarks", "method", "prior", "machine", "rademacher", "nips", "globally", "results", "jaakkola", "figure", "max", "szummer", "generalization", "laprls", "random", "expectation", "analytical", "geometric", "thus", "regression", "binary", "task", "also", "using", "journal", "two", "function", "icml", "time", "section", "let", "following", "transductive", "experiments", "gaussian", "logistic", "bengio", "classes", "joachims", "labels", "mccallum", "classification", "logarithm", "means", "may", "minimizes", "propose", "per", "measure", "matrix", "research", "standard", "number", "given", "sec", "grandvalet", "errors", "principle", "set", "due"], "authors": ["Gang Niu", "Wittawat Jitkrittum", "Bo Dai,", "Hirotaka Hachiya", "Masashi Sugiyama"], "thumbnail_path": "thumbnails/Squaredloss Mutual Information Regularization.jpg"}, {"title": "Ellipsoidal Multiple Instance Learning", "topics": [0.018730468715668126, 0.018730347323968811, 0.90634568827523887, 0.018730349350653503, 0.018731060967525064, 0.01873208536694566], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/krummenacher13.pdf", "most_common": ["bag", "positive", "instance", "emil", "instances", "problem", "multiple", "learning", "covariance", "equation", "mil", "optimization", "datasets", "section", "method", "negative", "two", "hyperplane", "one", "ellipsoid", "margin", "wheel", "ellipsoids", "use", "following", "ellipsoidal", "robust", "mean", "see", "bags", "data", "given", "accuracy", "methods", "distance", "results", "vector", "convex", "matrix", "max", "test", "function", "solving", "min", "random", "based", "kernel", "empirical", "solve", "using", "image", "algorithm", "labels", "optimal", "resulting", "table", "machine", "gaussian", "rank", "defects", "cccp", "average", "show", "set", "approach", "dimensional", "setting", "second", "andrews", "order", "derive", "since", "approaches", "probability", "label", "distribution", "constraints", "per", "support", "also", "maximum", "optimisation", "time", "solution", "compare", "get", "half", "research", "xij", "gives", "chapelle", "due", "real", "world", "examples", "lanckriet", "distributions", "functions", "would", "musk"], "authors": ["Gabriel Krummenacher", "Cheng Soon Ong", "Joachim Buhmann"], "thumbnail_path": "thumbnails/Ellipsoidal Multiple Instance Learning.jpg"}, {"title": "Infinitesimal Annealing for Training SemiSupervised Support Vector Machine", "topics": [0.022095025662098654, 0.022095033490730057, 0.88945470628315915, 0.022159420416839857, 0.022094837501353368, 0.022100976645819007], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ogawa13a.pdf", "most_common": ["optimal", "solution", "path", "local", "algorithm", "annealing", "conditionally", "computation", "polytope", "solutions", "convex", "vmpath", "pol", "number", "cccp", "unlabeled", "optimization", "function", "instances", "light", "time", "problem", "figure", "data", "training", "better", "chapelle", "theorem", "objective", "vector", "programming", "generalization", "boundary", "values", "parametric", "step", "labels", "predicted", "learning", "total", "svm", "labeled", "see", "steps", "machine", "vmlight", "set", "proposed", "performance", "joachims", "entire", "following", "support", "best", "error", "strictly", "svms", "existing", "vapnik", "section", "increasing", "algorithms", "computing", "current", "indicates", "used", "combinatorial", "procedure", "supervised", "use", "good", "reaches", "one", "given", "min", "interior", "based", "label", "conditions", "table", "optimality", "input", "loss", "strict", "blue", "new", "adjacent", "experiments", "shows", "feasible", "note", "also", "left", "lemma", "international", "however", "sindhwani", "possible", "right", "properties"], "authors": ["Kohei Ogawa", "Motoki Imamura", "Ichiro Takeuchi", "Masashi Sugiyama"], "thumbnail_path": "thumbnails/Infinitesimal Annealing for Training SemiSupervised Support Vector Machine.jpg"}, {"title": "Sparse Gaussian Conditional Random Fields Algorithms and Application to Energy Forecasting", "topics": [0.016106822063432603, 0.016107054305617874, 0.91946164972103273, 0.016110099221753271, 0.016107293667088459, 0.016107081021075012], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wytock13.pdf", "most_common": ["gaussian", "sparse", "model", "crf", "wind", "forecasting", "performance", "optimization", "newton", "method", "figure", "methods", "conditional", "mrf", "problem", "algorithm", "random", "using", "regularized", "log", "regularization", "data", "input", "parameters", "use", "features", "power", "covariance", "inverse", "since", "true", "set", "versus", "output", "sample", "graphical", "sparsity", "results", "term", "energy", "number", "size", "thus", "two", "coordinate", "sxx", "zhang", "entries", "shows", "even", "active", "approach", "mse", "algorithms", "matrix", "approaches", "variables", "given", "yuan", "also", "sgcrf", "previous", "norm", "case", "pjm", "substantial", "accuracy", "estimation", "learning", "demand", "descent", "several", "proposed", "dependence", "bounds", "time", "past", "theoretical", "high", "assumptions", "solving", "gradient", "note", "objective", "maximum", "however", "upon", "forecasts", "edges", "underlying", "shown", "faster", "graph", "linear", "degree", "total", "discriminative", "generalization", "hsieh", "compute"], "authors": ["Matt Wytock", "Zico Kolter"], "thumbnail_path": "thumbnails/Sparse Gaussian Conditional Random Fields Algorithms and Application to Energy Forecasting.jpg"}, {"title": "Adaptive Hamiltonian and Riemann Manifold Monte Carlo", "topics": [0.017561482845639298, 0.017561498302297775, 0.91219198384476541, 0.017561447400632556, 0.017561844816859955, 0.017561742789805032], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wang13e.pdf", "most_common": ["hmc", "adaptive", "set", "using", "samplers", "monte", "bayesian", "carlo", "use", "ahmc", "function", "mcmc", "sampler", "data", "hamiltonian", "samples", "algorithm", "number", "objective", "parameters", "leapfrog", "results", "nuts", "optimization", "adaptation", "markov", "gaussian", "tuning", "riemann", "rmhmc", "process", "manifold", "since", "also", "show", "steps", "parameter", "method", "measure", "roberts", "neal", "thus", "neural", "sample", "distribution", "sampling", "used", "model", "performance", "ess", "chain", "minimum", "armhmc", "predictive", "error", "median", "experiments", "approach", "obtained", "posterior", "general", "gelman", "esjd", "girolami", "machine", "better", "networks", "calderhead", "sets", "latent", "true", "maximum", "stochastic", "two", "algorithms", "paper", "good", "standard", "probability", "need", "settings", "best", "higher", "variance", "log", "models", "time", "per", "compact", "conditions", "small", "section", "allows", "known", "following", "end", "matrix", "ripley", "state", "pima"], "authors": ["Ziyu Wang", "Shakir Mohamed", "De Freitas Nando"], "thumbnail_path": "thumbnails/Adaptive Hamiltonian and Riemann Manifold Monte Carlo.jpg"}, {"title": "Stochastic Simultaneous Optimistic Optimization", "topics": [0.017858953999097017, 0.017859136092960019, 0.91070126907398263, 0.017859251618226005, 0.0178623368683671, 0.01785905234736735], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/valko13.pdf", "most_common": ["function", "hmax", "optimization", "node", "depth", "number", "stosoo", "case", "stochastic", "algorithm", "nodes", "evaluations", "let", "optimistic", "loss", "figure", "time", "global", "since", "assumption", "munos", "expanded", "order", "lemma", "one", "dimension", "upper", "regret", "lipschitz", "point", "bubeck", "log", "min", "radius", "cell", "performance", "around", "bound", "soo", "assume", "simultaneous", "smoothness", "knowledge", "set", "representative", "setting", "functions", "consider", "space", "exists", "bandit", "learning", "leaves", "analysis", "therefore", "optimal", "event", "tree", "doo", "however", "locally", "bounded", "maximum", "deterministic", "holds", "algorithms", "evaluation", "also", "according", "metric", "expansion", "section", "noised", "def", "machine", "value", "shows", "probability", "least", "kleinberg", "show", "means", "many", "search", "lower", "without", "sampled", "evaluate", "know", "smooth", "constant", "bandits", "choice", "springer", "values", "assumptions", "end", "left", "related", "estimate"], "authors": ["Michal Valko", "Alexandra Carpentier", "Remi Munos"], "thumbnail_path": "thumbnails/Stochastic Simultaneous Optimistic Optimization.jpg"}, {"title": "BlockCoordinate FrankWolfe Optimization for Structural SVMs", "topics": [0.016525038186409987, 0.01652494752559118, 0.91737585218299311, 0.01652481173929754, 0.01652474728117713, 0.016524603084531009], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/lacoste-julien13.pdf", "most_common": ["algorithm", "structural", "dual", "problem", "optimization", "convergence", "gap", "svm", "duality", "primal", "method", "svms", "subgradient", "methods", "rate", "oracle", "stochastic", "algorithms", "iteration", "maximization", "given", "objective", "convex", "appendix", "number", "batch", "error", "structured", "joachims", "zhang", "taskar", "plane", "cutting", "gradient", "results", "linear", "training", "see", "using", "equivalent", "let", "optimal", "variables", "bcfw", "descent", "coordinate", "update", "decoding", "passes", "show", "theorem", "sparse", "solution", "vector", "use", "call", "machine", "instead", "jaggi", "point", "thus", "learning", "obtain", "yields", "approximate", "quadratic", "requires", "case", "exact", "cost", "ssg", "work", "domain", "online", "iterate", "however", "suboptimality", "iterations", "used", "step", "block", "dataset", "compute", "frankwolfe", "random", "large", "even", "section", "new", "allows", "variant", "data", "experiments", "solving", "since", "standard", "gives", "jmlr", "collins", "note"], "authors": ["Simon Lacoste-Julien", "Martin Jaggi", "Mark Schmidt", "Patrick Pletscher"], "thumbnail_path": "thumbnails/BlockCoordinate FrankWolfe Optimization for Structural SVMs.jpg"}, {"title": "Taming the Curse of Dimensionality Discrete Integration by Hashing and Optimization", "topics": [0.014317538099921753, 0.014313691583508124, 0.92842228599332011, 0.014314141845648531, 0.014318434913244246, 0.014313907564357336], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/ermon13.pdf", "most_common": ["optimization", "function", "algorithm", "problem", "wish", "number", "partition", "using", "discrete", "weight", "graphical", "models", "map", "probability", "inference", "parity", "random", "computing", "figure", "constraints", "estimate", "approximate", "let", "model", "high", "belief", "instances", "factor", "set", "theorem", "hashing", "large", "variables", "compute", "propagation", "constant", "hash", "least", "integration", "methods", "consider", "results", "approximation", "values", "provide", "combinatorial", "one", "given", "solutions", "sampling", "learning", "often", "gomes", "area", "estimation", "also", "weights", "sum", "known", "counting", "jordan", "note", "queries", "bounds", "thus", "solved", "see", "field", "slices", "although", "log", "exp", "problems", "total", "complexity", "randomized", "truth", "weighted", "independent", "wainwright", "exponentially", "sat", "ground", "following", "however", "distribution", "error", "lower", "obtain", "provides", "uniformly", "bound", "functions", "oracle", "dimensionality", "small", "configurations", "jaakkola", "items", "use"], "authors": ["Stefano Ermon", "Carla Gomes", "Ashish Sabharwal", "Bart Selman"], "thumbnail_path": "thumbnails/Taming the Curse of Dimensionality Discrete Integration by Hashing and Optimization.jpg"}, {"title": "Expensive Function Optimization with Stochastic Binary Outcomes", "topics": [0.016069202771949308, 0.016070022487414338, 0.91965262441578766, 0.016069568457406674, 0.016069422782282763, 0.016069159085159174], "pdf_url": "http://jmlr.org/proceedings/papers/v28/tesch13.pdf", "most_common": ["function", "optimization", "binary", "stochastic", "test", "algorithm", "probability", "improvement", "expected", "bayesian", "parameter", "problem", "metric", "selection", "bandit", "functions", "expensive", "success", "latent", "number", "sample", "performance", "space", "model", "using", "use", "work", "point", "used", "learning", "ucbc", "gaussian", "random", "global", "results", "robot", "parameters", "given", "points", "set", "posterior", "auer", "outcomes", "high", "algorithms", "snake", "also", "class", "ybest", "underlying", "sampled", "methods", "regret", "values", "goal", "data", "experiments", "rasmussen", "continuous", "experiment", "expectation", "robust", "well", "often", "step", "would", "synthetic", "case", "machine", "max", "rather", "could", "one", "areas", "simple", "regression", "baseline", "comparison", "bounds", "bandits", "method", "compare", "choice", "response", "setting", "framework", "instead", "shown", "linear", "standard", "unknown", "williams", "objective", "eif", "processes", "paper", "due", "journal", "obtain", "choosing"], "authors": ["Matthew Tesch", "Jeff Schneider", "Howie Choset"], "thumbnail_path": "thumbnails/Expensive Function Optimization with Stochastic Binary Outcomes.jpg"}, {"title": "OlogT Projections for Stochastic Optimization of Smooth and Strongly Convex Functions", "topics": [0.018121200689013923, 0.018122206952138641, 0.90939456924598994, 0.018120219372939429, 0.018121903337496359, 0.018119900402421465], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhang13e.pdf", "most_common": ["stochastic", "algorithm", "gradient", "log", "optimization", "projections", "rate", "convex", "optimal", "number", "convergence", "smooth", "lemma", "strongly", "function", "algorithms", "probability", "oracle", "epoch", "theorem", "following", "hazan", "objective", "descent", "problem", "proposed", "kale", "solution", "high", "given", "achieve", "performing", "functions", "risk", "proof", "projection", "domain", "least", "nesterov", "bound", "calls", "norm", "excess", "lan", "achieves", "nemirovski", "learning", "results", "value", "use", "making", "online", "expectation", "using", "step", "method", "sgd", "nips", "size", "assumption", "based", "set", "point", "let", "icml", "deterministic", "shamir", "juditsky", "parameters", "composite", "work", "maintain", "paper", "versus", "inequality", "ftk", "rakhlin", "approximation", "iteration", "accelerated", "also", "average", "solutions", "methods", "conditional", "bounds", "gradients", "dekel", "bounded", "assume", "prediction", "prove", "positive", "two", "theoretical", "needs", "provide", "complexity", "order", "cotter"], "authors": ["Lijun Zhang", "Tianbao Yang", "Rong Jin", "Xiaofei He"], "thumbnail_path": "thumbnails/OlogT Projections for Stochastic Optimization of Smooth and Strongly Convex Functions.jpg"}, {"title": "Revisiting FrankWolfe ProjectionFree Sparse Convex Optimization", "topics": [0.01393602991739616, 0.013937317477388961, 0.93031999124425324, 0.013935748411377503, 0.013935447888588425, 0.013935465060995739], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/jaggi13.pdf", "most_common": ["algorithm", "convex", "optimization", "linear", "matrix", "norm", "convergence", "domain", "sparse", "function", "atomic", "duality", "also", "using", "matrices", "optimizing", "algorithms", "jaggi", "gap", "sparsity", "problem", "approximation", "iteration", "vectors", "gradient", "case", "schatten", "subproblems", "domains", "given", "norms", "general", "problems", "bounded", "known", "clarkson", "see", "methods", "min", "trace", "svd", "zhang", "unit", "current", "analysis", "simplex", "vector", "greedy", "one", "quality", "constrained", "set", "value", "hull", "bach", "step", "primal", "approximate", "form", "obtained", "variant", "submodular", "variants", "revisiting", "arbitrary", "upper", "optimal", "structured", "new", "bound", "quadratic", "iterates", "update", "method", "becomes", "curvature", "appendix", "example", "holds", "instead", "singular", "ball", "used", "since", "hazan", "point", "learning", "dual", "lower", "time", "existing", "solution", "solved", "even", "section", "atoms", "use", "therefore", "group", "applications"], "authors": ["Martin Jaggi"], "thumbnail_path": "thumbnails/Revisiting FrankWolfe ProjectionFree Sparse Convex Optimization.jpg"}, {"title": "Algorithms for Direct  Loss Optimization in Binary Classification", "topics": [0.018281189596924999, 0.018280650603971785, 0.90859682913456308, 0.01828058859799073, 0.018280345403552254, 0.018280396662996971], "pdf_url": "http://jmlr.org/proceedings/papers/v28/nguyen13a.pdf", "most_common": ["loss", "search", "algorithms", "svm", "points", "sla", "solution", "data", "optimization", "end", "function", "algorithm", "hyperplane", "vector", "bnb", "optimal", "decision", "machine", "direct", "combinatorial", "class", "binary", "convex", "table", "value", "two", "approximation", "given", "point", "regression", "bpm", "noise", "time", "linear", "figure", "pcs", "training", "logistic", "dataset", "csa", "shows", "initial", "datasets", "losses", "solutions", "best", "learning", "outliers", "robust", "lossmin", "range", "values", "one", "robustness", "approach", "margin", "running", "improvement", "bound", "smooth", "test", "following", "approximated", "local", "corresponding", "assigned", "methods", "hinge", "implied", "results", "equation", "work", "return", "since", "bayes", "descent", "assignment", "branch", "synthetic", "novel", "optimize", "compare", "minimum", "hull", "feasible", "directly", "least", "prediction", "seen", "objective", "optimized", "combinations", "set", "techniques", "uci", "thus", "input", "yields", "log", "true"], "authors": ["Tan Nguyen", "Scott Sanner"], "thumbnail_path": "thumbnails/Algorithms for Direct  Loss Optimization in Binary Classification.jpg"}, {"title": "Toward Optimal Stratification for Stratified MonteCarlo Integration", "topics": [0.017403276122472378, 0.017403345529154606, 0.91298331117697962, 0.017403446451284575, 0.017403296365341565, 0.017403324354767259], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/carpentier13.pdf", "most_common": ["samples", "partition", "algorithm", "stratum", "strata", "sampling", "function", "optimal", "number", "bound", "estimate", "according", "hierarchical", "also", "paper", "domain", "sample", "carpentier", "bss", "node", "measure", "one", "partitioning", "upper", "cmax", "children", "munos", "variations", "figure", "provide", "variance", "allocation", "consider", "points", "random", "integration", "time", "oracle", "assumption", "noise", "two", "bounded", "order", "toward", "write", "mean", "scheme", "theorem", "almost", "noisy", "since", "nte", "see", "however", "strategy", "log", "problem", "assume", "partitions", "empirical", "fmax", "term", "probability", "lower", "point", "adaptive", "large", "smaller", "strategies", "times", "precisely", "online", "phase", "set", "result", "allocates", "thus", "nodes", "particular", "negligible", "indeed", "choose", "main", "schemes", "standard", "given", "tree", "class", "min", "allocate", "proportional", "exploration", "monte", "uniform", "let", "larger", "use", "would", "assumptions", "recursive"], "authors": ["Alexandra Carpentier", "Remi Munos"], "thumbnail_path": "thumbnails/Toward Optimal Stratification for Stratified MonteCarlo Integration.jpg"}, {"title": "An Optimal Policy for Target Localization with Application to Electron Microscopy", "topics": [0.017800234139021171, 0.017800327974350494, 0.91099489382219601, 0.017800267026803374, 0.017803960369704698, 0.017800316667924289], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/sznitman13.pdf", "most_common": ["policy", "optimal", "image", "pixel", "target", "question", "images", "scans", "questions", "time", "given", "using", "function", "value", "mitochondria", "strip", "number", "locations", "electron", "sequential", "greedy", "noise", "information", "also", "used", "application", "scanning", "noisy", "problem", "cost", "active", "denoted", "localization", "jedynak", "microscopy", "sem", "computed", "interval", "answers", "probability", "one", "density", "learning", "form", "posterior", "let", "scan", "intensity", "distribution", "many", "bayesian", "location", "block", "use", "error", "type", "may", "regions", "shown", "shows", "imaging", "times", "show", "approach", "acquired", "observed", "tissue", "claimed", "frazier", "per", "true", "consider", "entropy", "sznitman", "estimated", "current", "work", "values", "process", "data", "produced", "related", "quality", "note", "objective", "average", "region", "castro", "surface", "left", "ian", "log", "compute", "dynamic", "example", "minimum", "lookahead", "university", "literature", "continuous"], "authors": ["Raphael Sznitman", "Aurelien Lucchi", "Peter Frazier", "Bruno Jedynak", "Pascal Fua"], "thumbnail_path": "thumbnails/An Optimal Policy for Target Localization with Application to Electron Microscopy.jpg"}, {"title": "Fast Image Tagging", "topics": [0.020726863125797027, 0.020726276449075584, 0.89563618093164254, 0.020726768946820143, 0.020726269979375624, 0.021457640567289018], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chen13j.pdf", "most_common": ["image", "tags", "training", "tag", "fasttag", "mapping", "images", "tagprop", "annotation", "number", "set", "ieee", "guillaumin", "feature", "loss", "tagging", "data", "model", "features", "score", "learning", "visual", "computer", "results", "relevant", "conference", "makadia", "algorithm", "time", "two", "descriptors", "recall", "fast", "international", "three", "also", "methods", "new", "method", "work", "machine", "linear", "one", "sets", "local", "corruption", "using", "existing", "large", "benchmark", "train", "leastsquares", "distance", "pattern", "terms", "figure", "byi", "annotated", "proceedings", "based", "joint", "automatic", "vision", "mins", "esp", "rare", "acm", "function", "complete", "models", "precision", "section", "via", "example", "predict", "may", "red", "manmatha", "feet", "jec", "lavrenko", "performance", "retrieval", "incomplete", "text", "testing", "available", "however", "several", "analysis", "sky", "game", "examples", "recognition", "dataset", "volume", "similar", "test", "enrichment", "partial"], "authors": ["Minmin Chen", "Alice Zheng", "Kilian Weinberger"], "thumbnail_path": "thumbnails/Fast Image Tagging.jpg"}, {"title": "An Efficient Posterior Regularized Latent Variable Model for Interactive Sound Source Separation", "topics": [0.019263897014071038, 0.01926331121004813, 0.9036376196273409, 0.019262088007771863, 0.019262410356029418, 0.019310673784738591], "pdf_url": "http://jmlr.org/proceedings/papers/v28/bryan13.pdf", "most_common": ["separation", "source", "algorithm", "method", "model", "latent", "posterior", "matrix", "proposed", "sound", "mixture", "user", "variable", "data", "constraints", "sources", "plca", "vectors", "number", "probabilistic", "smaragdis", "used", "audio", "signal", "regularization", "training", "given", "speech", "processing", "results", "sdr", "music", "interactive", "expectation", "using", "multiplicative", "regularized", "form", "values", "sounds", "parameters", "baseline", "step", "equations", "separated", "basis", "methods", "durrieu", "oracle", "penalties", "use", "two", "spectrogram", "annotations", "example", "process", "evaluation", "recording", "factorization", "result", "basic", "lvm", "distribution", "component", "end", "frequency", "standard", "probability", "raj", "allow", "stft", "perform", "analysis", "without", "grouping", "function", "cost", "section", "allows", "distinct", "normalized", "sir", "siren", "information", "multiplication", "linear", "observed", "exp", "sisec", "achieve", "international", "arg", "conference", "procedure", "sar", "lower", "solve", "output", "repeat", "bound"], "authors": ["Nicholas Bryan", "Gautham Mysore"], "thumbnail_path": "thumbnails/An Efficient Posterior Regularized Latent Variable Model for Interactive Sound Source Separation.jpg"}, {"title": "MaxMargin MultipleInstance Dictionary Learning", "topics": [0.016783245532609736, 0.016783158423142697, 0.91608358039292603, 0.016783609900268521, 0.016783177227378501, 0.016783228523674584], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wang13d.pdf", "most_common": ["learning", "image", "positive", "dictionary", "instances", "mmdl", "xij", "negative", "instance", "scene", "images", "cluster", "multiple", "set", "codebook", "method", "feature", "using", "learned", "zij", "representation", "linear", "object", "bags", "patches", "dataset", "class", "bag", "lazebnik", "svm", "training", "number", "accuracy", "cvpr", "used", "discriminative", "learn", "clusters", "methods", "machine", "features", "given", "yang", "based", "zhang", "sift", "use", "paper", "one", "patch", "mil", "proposed", "also", "supervised", "clustering", "way", "formulation", "spatial", "category", "codewords", "visual", "following", "ieee", "codebooks", "problem", "input", "two", "pij", "algorithm", "iccv", "vector", "naive", "wang", "response", "bank", "average", "moosmann", "computer", "label", "however", "take", "performance", "recognition", "indoor", "encoded", "zhu", "solution", "latent", "uiuc", "figure", "max", "research", "lbp", "labels", "experiments", "optimization", "margin", "pyramid", "obtain", "rehg"], "authors": ["Xinggang Wang", "Zhuowen Tu"], "thumbnail_path": "thumbnails/MaxMargin MultipleInstance Dictionary Learning.jpg"}, {"title": "Parameter Learning and Convergent Inference for Dense Random Fields", "topics": [0.016565129125989054, 0.016565186029119119, 0.91717396825099973, 0.016565218921029683, 0.016565093401807399, 0.01656540427105499], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kraehenbuehl13.pdf", "most_common": ["algorithm", "inference", "gradient", "random", "parameters", "learning", "loss", "mean", "dense", "model", "kernel", "label", "parameter", "message", "compatibility", "pairwise", "koltun", "marginals", "approximate", "section", "use", "passing", "convergent", "unary", "potentials", "function", "models", "log", "matrix", "gaussian", "performance", "fields", "image", "marginal", "negative", "objective", "approach", "using", "positive", "number", "kernels", "variable", "entropy", "training", "term", "accuracy", "guaranteed", "functions", "search", "performed", "algorithms", "used", "shown", "robust", "potts", "terms", "grid", "conditions", "learned", "jointly", "vineet", "kkt", "wainwright", "diagonal", "standard", "also", "respect", "present", "minimize", "hamming", "given", "product", "parallel", "tappen", "concave", "labeling", "evaluation", "linear", "divergence", "directly", "generative", "cccp", "logistic", "vision", "estimation", "wti", "evaluate", "block", "convergence", "compute", "single", "vector", "approximation", "equation", "learn", "example", "table", "feature", "minimizes", "experiment"], "authors": ["Philipp Kraehenbuehl", "Vladlen Koltun"], "thumbnail_path": "thumbnails/Parameter Learning and Convergent Inference for Dense Random Fields.jpg"}, {"title": "Can We Recognize Tiger by Bus Images  Robust and Discriminative SelfTaught Image Categorization", "topics": [0.017598719713547203, 0.017598694500408393, 0.91200615208401381, 0.017598958687267751, 0.017598658784386163, 0.017598816230376808], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wang13g.pdf", "most_common": ["learning", "data", "dictionary", "methods", "unlabeled", "method", "robust", "images", "target", "labeled", "discriminative", "raina", "learned", "following", "transfer", "wang", "approach", "proposed", "using", "sparse", "size", "new", "lee", "information", "domain", "basis", "image", "auxiliary", "use", "learn", "ding", "vectors", "feature", "objective", "huang", "function", "existing", "mairal", "knowledge", "algorithm", "two", "number", "heng", "used", "nie", "compared", "results", "section", "training", "stl", "also", "class", "compute", "optimal", "due", "sets", "distribution", "jrd", "svm", "regularization", "supervision", "representation", "machine", "much", "patterns", "via", "samples", "automatically", "robustness", "figure", "parameter", "classify", "outlier", "dai", "hua", "macro", "performance", "preliminary", "traditional", "joint", "however", "solve", "loss", "dictionaries", "respect", "three", "important", "vector", "diagonal", "including", "labeling", "related", "shown", "matrix", "feiping", "structured", "min", "selection", "minimizing", "reconstruction"], "authors": ["Hua Wang", "Feiping Nie", "Heng Huang"], "thumbnail_path": "thumbnails/Can We Recognize Tiger by Bus Images  Robust and Discriminative SelfTaught Image Categorization.jpg"}, {"title": "Learning SpatioTemporal Structure from RGBD Videos for Human Activity Detection and Forecasting", "topics": [0.017552699268032448, 0.017552748403080042, 0.91223458105459809, 0.017553517496551076, 0.01755295966204751, 0.017553494115690845], "pdf_url": "http://jmlr.org/proceedings/papers/v28/koppula13.pdf", "most_common": ["graph", "temporal", "human", "object", "activity", "structure", "features", "future", "segmentation", "using", "activities", "model", "learning", "frames", "labeling", "segment", "nodes", "objects", "detection", "anticipation", "saxena", "method", "additive", "possible", "koppula", "time", "row", "feature", "videos", "two", "kgs", "figure", "energy", "structures", "frame", "sampling", "anticipating", "function", "past", "macro", "however", "sample", "segmentations", "work", "shows", "set", "modeling", "recall", "obtain", "labels", "level", "distance", "crf", "approach", "methods", "node", "use", "given", "performance", "based", "computed", "precision", "previous", "also", "anticipated", "interactions", "micro", "observed", "proposed", "potential", "poses", "consider", "results", "segments", "respectively", "example", "jiang", "video", "random", "well", "cvpr", "sampled", "works", "iccv", "total", "therefore", "torre", "maps", "food", "relations", "multiple", "show", "joint", "taking", "described", "edge", "performing", "conditional", "recognition", "denote"], "authors": ["Hema Koppula", "Ashutosh Saxena"], "thumbnail_path": "thumbnails/Learning SpatioTemporal Structure from RGBD Videos for Human Activity Detection and Forecasting.jpg"}, {"title": "A Spectral Learning Approach to RangeOnly SLAM", "topics": [0.018565590912188869, 0.01856592885520833, 0.90716864609220771, 0.018568031338991535, 0.018565977310812425, 0.018565825490591131], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/boots13.pdf", "most_common": ["slam", "spectral", "robot", "batch", "algorithm", "range", "path", "learning", "optimization", "data", "landmark", "approach", "matrix", "state", "model", "measurement", "positions", "djugash", "localization", "motion", "nonlinear", "methods", "true", "time", "recover", "error", "system", "best", "algorithms", "linear", "see", "boots", "approaches", "factorization", "missing", "results", "section", "estimate", "number", "singh", "problem", "conference", "landmarks", "proceedings", "svd", "international", "method", "singular", "observations", "online", "odometry", "using", "full", "ekf", "via", "figure", "used", "gordon", "last", "much", "readings", "popular", "plaza", "solution", "learned", "two", "appendix", "learn", "information", "systems", "space", "since", "kanade", "observation", "show", "local", "byron", "robotics", "models", "structure", "finally", "thrun", "contains", "sin", "mapping", "statistical", "found", "squared", "features", "also", "lawn", "upgrade", "new", "metric", "several", "position", "poses", "dead", "steps", "computational"], "authors": ["Byron Boots", ""], "thumbnail_path": "thumbnails/A Spectral Learning Approach to RangeOnly SLAM.jpg"}, {"title": "NonLinear Stationary Subspace Analysis with Application to Video Classification", "topics": [0.019016168644341417, 0.019016099961311039, 0.90491958390289839, 0.019016350520645466, 0.019015838341102497, 0.019015958629700964], "pdf_url": "http://jmlr.org/proceedings/papers/v28/baktashmotlagh13.pdf", "most_common": ["stationary", "video", "kernel", "subspace", "nlssa", "pca", "recognition", "approach", "action", "analysis", "signal", "data", "features", "class", "ssa", "videos", "problem", "linear", "kssa", "dynamic", "used", "use", "accuracy", "model", "stationarity", "sources", "matrix", "training", "cvpr", "representation", "methods", "obtained", "part", "note", "texture", "human", "image", "solution", "table", "therefore", "rbf", "using", "hara", "hog", "introduce", "number", "mean", "since", "average", "accuracies", "baselines", "yields", "dataset", "section", "method", "eigenvalue", "analytic", "however", "sequences", "covariance", "also", "chan", "shown", "algorithm", "following", "wang", "information", "shows", "scene", "one", "min", "compute", "experiments", "epochs", "across", "modeling", "generalized", "shared", "similar", "results", "expressed", "ahuja", "projection", "contains", "vasconcelos", "compare", "mapping", "projected", "ghanem", "performance", "based", "sankaranarayanan", "learning", "perform", "epoch", "components", "computational", "dimensionality", "component", "two"], "authors": ["Mahsa Baktashmotlagh", "Mehrtash Harandi", "Abbas Bigdeli", "Brian Lovell", "Mathieu Salzmann"], "thumbnail_path": "thumbnails/NonLinear Stationary Subspace Analysis with Application to Video Classification.jpg"}, {"title": "On Compact Codes for Spatially Pooled Features", "topics": [0.01913998749860717, 0.019139568129100237, 0.90430119667026843, 0.019139966809067165, 0.019139426691571541, 0.019139854201385382], "pdf_url": "http://jmlr.org/proceedings/papers/v28/jia13.pdf", "most_common": ["dictionary", "pooling", "learning", "accuracy", "feature", "codes", "size", "matrix", "pooled", "sampling", "encoding", "features", "coding", "figure", "coates", "image", "padl", "performance", "local", "kernel", "methods", "using", "sparse", "random", "large", "approximation", "two", "may", "one", "compact", "would", "also", "algorithm", "max", "bound", "training", "responses", "sizes", "bounds", "spatial", "computation", "patches", "selected", "method", "spatially", "data", "algorithms", "number", "note", "set", "pipeline", "code", "linear", "learn", "codebook", "testing", "clustering", "starting", "obtained", "use", "used", "selection", "columns", "view", "simple", "obtain", "dictionaries", "often", "function", "time", "vector", "error", "highly", "kumar", "produce", "stl", "unsupervised", "based", "many", "extraction", "output", "datasets", "svd", "original", "small", "section", "learned", "sample", "work", "column", "representation", "better", "could", "given", "especially", "show", "new", "patch", "various", "invariant"], "authors": ["Yangqing Jia", "Oriol Vinyals", "Trevor Darrell"], "thumbnail_path": "thumbnails/On Compact Codes for Spatially Pooled Features.jpg"}, {"title": "Analogypreserving Semantic Embedding for Visual Object Categorization", "topics": [0.020123050016094792, 0.020111225977721293, 0.89942723818682546, 0.020111466902510245, 0.020115374745346082, 0.020111644171502182], "pdf_url": "http://jmlr.org/proceedings/papers/v28/juhwang13.pdf", "most_common": ["analogies", "semantic", "embedding", "analogy", "categories", "visual", "class", "category", "use", "object", "space", "learning", "two", "analogical", "constraints", "pairs", "also", "data", "attribute", "attributes", "recognition", "large", "classes", "learned", "parallelogram", "lme", "leopard", "set", "thus", "categorization", "label", "margin", "form", "relationships", "example", "labels", "method", "embeddings", "using", "prior", "instances", "accuracy", "pair", "weinberger", "figure", "number", "features", "show", "knowledge", "distances", "regularizer", "methods", "discover", "discriminative", "work", "feature", "easily", "ase", "one", "chapelle", "lampert", "approach", "discovery", "lmeprior", "auxiliary", "structural", "given", "lion", "score", "preserve", "however", "according", "among", "convex", "image", "structure", "focus", "panda", "regularize", "table", "gentner", "training", "cat", "wang", "regularization", "goal", "matrix", "vector", "automatic", "hwang", "chimp", "much", "novel", "aim", "candidate", "dalmatian", "datasets", "similarity", "existing", "dimensionality"], "authors": ["Sung Ju Hwang", "Kristen Grauman", "Fei Sha"], "thumbnail_path": "thumbnails/Analogypreserving Semantic Embedding for Visual Object Categorization.jpg"}, {"title": "Exploiting Ontology Structures and Unlabeled Data for Learning", "topics": [0.020347952848926702, 0.020348040325151608, 0.89824954981699123, 0.020357835938739872, 0.020348458917611219, 0.020348162152579386], "pdf_url": "http://jmlr.org/proceedings/papers/v28/balcan13a.pdf", "most_common": ["unlabeled", "ontology", "error", "learning", "category", "probability", "edge", "errunl", "least", "data", "given", "case", "one", "rate", "err", "nand", "example", "let", "positive", "assume", "consider", "hypothesis", "labeled", "also", "theorem", "vcdim", "categories", "section", "tightness", "two", "model", "using", "algorithm", "results", "cases", "sample", "since", "show", "lemma", "examples", "would", "following", "safe", "labeling", "structures", "set", "suppose", "good", "exploiting", "bound", "implies", "true", "graph", "proof", "need", "note", "negative", "empirical", "either", "analyze", "every", "must", "three", "machine", "related", "independence", "number", "say", "labels", "conditions", "used", "learn", "multiple", "large", "science", "work", "hypotheses", "subject", "incident", "conference", "ontologies", "mitchell", "carlson", "edges", "predicts", "extension", "high", "proceedings", "relationships", "blum", "never", "tasks", "use", "type", "natural", "space", "log", "assumption", "hruschka", "class"], "authors": ["Nina Balcan", "Avrim Blum", "Yishay Mansour"], "thumbnail_path": "thumbnails/Exploiting Ontology Structures and Unlabeled Data for Learning.jpg"}, {"title": "OnePass AUC Optimization", "topics": [0.020171037919012567, 0.020171773651677414, 0.8991442471002552, 0.020171176081555799, 0.02017085895064348, 0.020170906296855591], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gao13.pdf", "most_common": ["auc", "training", "optimization", "loss", "matrices", "opauc", "online", "learning", "covariance", "algorithm", "data", "datasets", "algorithms", "batch", "rank", "square", "oamgra", "matrix", "gradient", "theorem", "approximate", "performance", "oamseq", "set", "also", "figure", "parameter", "proceedings", "approach", "two", "results", "rate", "international", "number", "conference", "opaucr", "running", "using", "average", "section", "full", "machine", "instances", "table", "numerical", "univariate", "convergence", "compared", "time", "features", "gao", "zhao", "values", "approaches", "one", "optimizes", "random", "classes", "better", "due", "proposed", "comparison", "bound", "dataset", "regularization", "whereas", "approximation", "study", "positive", "benchmark", "following", "approximated", "shows", "distribution", "develop", "used", "function", "memory", "storing", "zhou", "calculate", "kotlowski", "stochastic", "joachims", "even", "method", "respectively", "obtained", "losses", "making", "experiments", "main", "solution", "size", "store", "pairwise", "randomly", "class", "german", "requirement"], "authors": ["Wei Gao", "Rong Jin", "Shenghuo Zhu", "Zhi-Hua Zhou"], "thumbnail_path": "thumbnails/OnePass AUC Optimization.jpg"}, {"title": "NearOptimal Bounds for CrossValidation via Loss Stability", "topics": [0.025848822799742273, 0.025849881628855403, 0.87074318403827233, 0.025850386699457849, 0.025848870169258083, 0.025858854664414167], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kumar13a.pdf", "most_common": ["stability", "loss", "var", "variance", "algorithm", "training", "cov", "learning", "set", "lemma", "hypothesis", "kale", "function", "reduction", "bounds", "examples", "bound", "work", "let", "example", "algorithms", "disccv", "notion", "setting", "stable", "unbiased", "show", "distribution", "covariance", "discrepancy", "single", "via", "therefore", "theorem", "covu", "following", "varu", "one", "due", "error", "obtain", "using", "step", "denote", "random", "blum", "two", "varx", "showed", "disci", "drawn", "thus", "wagner", "kearns", "every", "main", "since", "also", "performance", "fact", "consider", "ron", "uniform", "new", "change", "obtained", "trained", "kumar", "mean", "jmlr", "factor", "enough", "many", "simple", "independent", "vassilvitskii", "algorithmic", "usa", "introduced", "test", "covx", "even", "active", "devroye", "studied", "mss", "element", "hypotheses", "bousquet", "estimate", "hence", "generalization", "note", "begin", "crossvalidation", "notation", "see", "weak", "expected", "observe"], "authors": ["Ravi Kumar", "Daniel Lokshtanov", "Sergei Vassilvitskii", "Andrea Vattani,"], "thumbnail_path": "thumbnails/NearOptimal Bounds for CrossValidation via Loss Stability.jpg"}, {"title": "Algebraic classifiers a generic approach to fast crossvalidationparallel training", "topics": [0.017902434514353683, 0.017902387945545318, 0.91048816459420767, 0.017902405579918883, 0.017902150186866202, 0.017902457179108294], "pdf_url": "http://jmlr.org/proceedings/papers/v28/izbicki13.pdf", "most_common": ["model", "data", "algebraic", "set", "monoid", "training", "structure", "online", "learning", "function", "algorithms", "base", "decision", "accuracy", "number", "models", "use", "parallel", "homstumps", "figure", "free", "bayesian", "batch", "time", "section", "stumps", "standard", "boosting", "algorithm", "method", "fast", "loop", "new", "train", "attribute", "machine", "takes", "let", "type", "group", "mboost", "operation", "split", "single", "trainer", "derive", "homtrainer", "abelian", "point", "sets", "mbayes", "points", "adaboost", "concatenation", "run", "bagging", "palit", "give", "algebra", "get", "international", "called", "second", "two", "work", "example", "information", "element", "shown", "construct", "show", "distribution", "binary", "analysis", "processing", "weighted", "way", "similar", "calculate", "technique", "finally", "every", "trained", "select", "classify", "diagram", "paper", "better", "systems", "good", "mapreduce", "generalization", "take", "crossvalidation", "left", "homomorphic", "computer", "conference", "forms", "three"], "authors": ["Michael Izbicki"], "thumbnail_path": "thumbnails/Algebraic classifiers a generic approach to fast crossvalidationparallel training.jpg"}, {"title": "Topk Selection based on Adaptive Sampling of Noisy Preferences", "topics": [0.018757524866810937, 0.01834003032853148, 0.90784736510267816, 0.018372098251367677, 0.018342883057635009, 0.018340098392976737], "pdf_url": "http://jmlr.org/proceedings/papers/v28/busa-fekete13.pdf", "most_common": ["options", "random", "ranking", "sampling", "algorithm", "racing", "pairwise", "problem", "probability", "sample", "set", "learning", "matrix", "nmax", "samples", "based", "section", "pbr", "complexity", "stochastic", "number", "selection", "tks", "strategy", "setting", "setup", "one", "proceedings", "sampled", "therefore", "general", "empirical", "procedure", "bound", "distribution", "consider", "uniform", "let", "strategies", "high", "algorithms", "shown", "since", "pairs", "variables", "see", "accuracy", "sum", "relation", "teams", "conference", "three", "expected", "intervals", "preference", "bounds", "distributions", "variable", "markov", "values", "subset", "least", "option", "bandit", "case", "thus", "comparisons", "also", "moreover", "line", "indices", "work", "machine", "instead", "used", "namely", "according", "corresponding", "introduce", "model", "theorem", "using", "follows", "interval", "original", "estimates", "international", "mnih", "two", "meyer", "figure", "information", "goal", "max", "order", "expectations", "policy", "solution", "given", "need"], "authors": ["Robert Busa-Fekete", "Weiwei Cheng", "Paul Weng", "Eyke Huellermeier", "Balazs Szorenyi"], "thumbnail_path": "thumbnails/Topk Selection based on Adaptive Sampling of Noisy Preferences.jpg"}, {"title": "Enhanced statistical rankings via targeted data collection", "topics": [0.018351780417237409, 0.018351568457339814, 0.90821074048528094, 0.018353038005385701, 0.0183812834045478, 0.018351589230208243], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/osting13.pdf", "most_common": ["data", "pairwise", "graph", "ranking", "problem", "collection", "movie", "comparison", "targeted", "dataset", "number", "given", "comparisons", "edge", "statistical", "algebraic", "informativeness", "yahoo", "optimal", "least", "rating", "edges", "user", "second", "let", "movies", "squares", "connectivity", "laplacian", "design", "via", "eigenvalue", "var", "rankings", "top", "algorithm", "additional", "information", "enhanced", "using", "weights", "small", "one", "addition", "fisher", "consider", "nodes", "figure", "reviews", "may", "see", "experimental", "used", "methods", "function", "osting", "random", "large", "degree", "increase", "min", "graphs", "set", "improve", "optimization", "problems", "matrix", "inverse", "eigenvalues", "spectral", "wij", "jiang", "university", "since", "pair", "present", "complete", "boyd", "weight", "node", "denote", "bottom", "alternatives", "haber", "item", "vector", "residual", "amount", "two", "particular", "must", "work", "referred", "weighted", "greedy", "applications", "yij", "siam", "randomly", "also"], "authors": ["Braxton Osting", "Christoph Brune", "Stanley Osher"], "thumbnail_path": "thumbnails/Enhanced statistical rankings via targeted data collection.jpg"}, {"title": "Efficient Ranking from Pairwise Comparisons", "topics": [0.016811079351548054, 0.016811510284230481, 0.91592764930298542, 0.016827337492988915, 0.016811201244909681, 0.016811222323337448], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wauthier13.pdf", "most_common": ["ranking", "comparisons", "algorithm", "algorithms", "binary", "theorem", "bound", "pairwise", "data", "learning", "bre", "objects", "probability", "scores", "ure", "measurements", "function", "bounds", "machine", "true", "rank", "show", "comparison", "permutation", "following", "sample", "number", "lower", "log", "scoring", "measured", "distributed", "theorems", "inv", "svm", "proposition", "section", "using", "active", "two", "large", "random", "score", "set", "simple", "case", "object", "paper", "top", "exp", "however", "many", "expected", "predicts", "partial", "noiseless", "tau", "complexity", "ailon", "displacement", "kendall", "given", "also", "online", "relative", "conference", "problem", "constant", "shows", "uniform", "must", "information", "systems", "research", "could", "one", "quality", "distance", "average", "lemma", "expectation", "much", "loss", "communication", "measure", "assume", "corollary", "prediction", "use", "noisy", "proof", "subset", "exactly", "mit", "advances", "proceedings", "situations", "result", "estimation", "mossel"], "authors": ["Fabian Wauthier", "Michael Jordan", "Nebojsa Jojic"], "thumbnail_path": "thumbnails/Efficient Ranking from Pairwise Comparisons.jpg"}, {"title": "Stable Coactive Learning via Perturbation", "topics": [0.020810746565400887, 0.020815591019591021, 0.89593966117335155, 0.020811675233547895, 0.020811302259510046, 0.02081102374859848], "pdf_url": "http://jmlr.org/proceedings/papers/v28/raman13.pdf", "most_common": ["learning", "feedback", "user", "algorithm", "preference", "ranking", "perturbation", "perceptron", "coactive", "noise", "perturbed", "prefp", "top", "swap", "regret", "joachims", "model", "search", "iterations", "two", "figure", "pair", "vector", "documents", "number", "performance", "average", "strategy", "clicks", "stable", "rankings", "probability", "online", "object", "document", "using", "bound", "users", "following", "algorithms", "rank", "news", "utility", "results", "presented", "section", "via", "feature", "airs", "note", "shivaswamy", "consider", "dynamic", "ndcg", "weight", "shows", "however", "expected", "also", "query", "prediction", "even", "study", "example", "optimal", "one", "without", "typically", "engine", "bounds", "problem", "paper", "systems", "since", "system", "chapelle", "experiments", "current", "let", "toy", "work", "information", "first", "iteration", "second", "data", "context", "behavior", "baseline", "used", "well", "proposed", "theorem", "conventional", "low", "eyt", "svm", "large", "upper", "preferences"], "authors": ["Karthik Raman", "Thorsten Joachims,", "Pannaga Shivaswamy", "Tobias Schnabel"], "thumbnail_path": "thumbnails/Stable Coactive Learning via Perturbation.jpg"}, {"title": "Optimistic Knowledge Gradient Policy for Optimal Budget Allocation in Crowdsourcing", "topics": [0.019277576860843814, 0.019277639724234595, 0.90355420076178672, 0.019277762736591906, 0.019332913738536635, 0.019279906178006432], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chen13f.pdf", "most_common": ["policy", "budget", "label", "instance", "optimal", "allocation", "worker", "optimistic", "accuracy", "problem", "crowdsourcing", "labeling", "knowledge", "yit", "gittins", "beta", "bayesian", "prior", "next", "mdp", "gradient", "model", "reliability", "approximate", "distribution", "random", "since", "expected", "workers", "index", "one", "reward", "instances", "learning", "uniform", "figure", "need", "labels", "state", "policies", "decision", "stage", "method", "positive", "choose", "probability", "based", "using", "many", "frazier", "true", "zij", "proposition", "max", "space", "xie", "could", "note", "also", "liu", "according", "setting", "set", "conditional", "algorithm", "assume", "consistent", "particular", "better", "att", "computationally", "see", "however", "due", "majority", "process", "dynamic", "dawid", "goes", "address", "active", "total", "information", "framework", "randomized", "formulate", "skene", "vote", "given", "acquire", "posterior", "btt", "deterministic", "general", "real", "assuming", "although", "function", "called", "problems"], "authors": ["Xi Chen", "Qihang Lin", "Dengyong Zhou"], "thumbnail_path": "thumbnails/Optimistic Knowledge Gradient Policy for Optimal Budget Allocation in Crowdsourcing.jpg"}, {"title": "Quantile Regression for Largescale Applications", "topics": [0.018444678721748375, 0.018444866747679978, 0.90777593429407377, 0.018445098803358994, 0.018444701536006233, 0.018444719897132769], "pdf_url": "http://jmlr.org/proceedings/papers/v28/yang13f.pdf", "most_common": ["algorithm", "regression", "quantile", "matrix", "sampling", "basis", "compute", "time", "solution", "size", "problem", "lemma", "log", "methods", "ispc", "data", "main", "embedding", "mahoney", "probability", "given", "fast", "row", "independent", "see", "method", "sample", "meng", "let", "koenker", "problems", "results", "vector", "use", "applications", "algorithms", "yang", "approximate", "unif", "two", "noco", "response", "linear", "value", "input", "nnz", "consider", "norm", "large", "may", "randomized", "relative", "also", "result", "empirical", "running", "portnoy", "column", "respectively", "ipm", "following", "spc", "found", "evaluation", "construct", "least", "sax", "objective", "dasgupta", "quantiles", "age", "technical", "optimal", "clarkson", "complexity", "transform", "used", "prqfn", "number", "one", "random", "annual", "subspace", "solve", "output", "cauchy", "computing", "wellconditioned", "applied", "matrices", "design", "full", "work", "figure", "provide", "rank", "performs", "need", "show", "runs"], "authors": ["Michael Mahoney", "Jiyan Yang", "Xiangrui Meng"], "thumbnail_path": "thumbnails/Quantile Regression for Largescale Applications.jpg"}, {"title": "Distributed training of Largescale Logistic models", "topics": [0.06122480378530968, 0.016969933114360861, 0.87087382506332101, 0.016991816341425148, 0.016969714848280838, 0.016969906847302322], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/gopal13.pdf", "most_common": ["parameters", "training", "rmlr", "function", "logistic", "bound", "methods", "number", "models", "optimization", "lbfgs", "problem", "admm", "exp", "objective", "distributed", "using", "solution", "one", "variational", "dataset", "log", "method", "optimal", "gradient", "large", "stationary", "convergence", "time", "memory", "parameter", "across", "iterations", "descent", "model", "train", "order", "given", "min", "however", "point", "learning", "even", "data", "multiple", "parallelizable", "also", "opt", "therefore", "work", "since", "linear", "iteration", "optimum", "classes", "note", "secondly", "yik", "would", "example", "machine", "variables", "boyd", "used", "http", "possible", "convex", "stochastic", "fat", "upper", "let", "figure", "difference", "shows", "optimized", "show", "arg", "clef", "block", "class", "datasets", "computing", "single", "problems", "algorithm", "consider", "computation", "multinomial", "takes", "taken", "high", "experiments", "still", "solving", "introduce", "could", "iterative", "lshtc", "fact", "paper"], "authors": ["Siddharth Gopal", "Yiming Yang"], "thumbnail_path": "thumbnails/Distributed training of Largescale Logistic models.jpg"}, {"title": "Label Partitioning For Sublinear Ranking", "topics": [0.021615147971950844, 0.021613427192436488, 0.8919245650783888, 0.021613446552703777, 0.02161639870975449, 0.021617014494765597], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/weston13.pdf", "most_common": ["label", "labels", "partitioner", "input", "scorer", "set", "partition", "example", "given", "examples", "assignment", "relevant", "precision", "training", "partitions", "partitioning", "large", "one", "ranking", "space", "using", "rank", "learning", "algorithm", "case", "time", "original", "ranked", "optimization", "methods", "consider", "method", "max", "image", "results", "number", "baseline", "hierarchical", "linear", "table", "problem", "annotation", "algorithms", "experiments", "also", "take", "objective", "however", "wsabie", "thus", "used", "proposed", "assigned", "recommendation", "optimize", "would", "true", "counting", "scoring", "documents", "note", "approach", "user", "task", "model", "loss", "single", "video", "section", "following", "subset", "many", "simply", "possible", "per", "acm", "computing", "weston", "typically", "items", "approaches", "two", "must", "work", "goal", "maps", "speeding", "lsh", "size", "top", "bits", "considered", "proceedings", "see", "correctly", "bengio", "several", "heuristic", "nips", "videos"], "authors": ["Jason Weston", "Ameesh Makadia", "Hector Yee"], "thumbnail_path": "thumbnails/Label Partitioning For Sublinear Ranking.jpg"}, {"title": "Human Boosting", "topics": [0.021345528861279835, 0.021345219791232752, 0.8932687032272778, 0.021345298827365008, 0.02134975426109726, 0.021345495031747336], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/pareek13.pdf", "most_common": ["human", "boosting", "learning", "humans", "learners", "training", "examples", "accuracy", "task", "algorithm", "data", "learner", "using", "use", "figure", "adaboost", "machine", "control", "decision", "distribution", "group", "test", "weights", "tasks", "experiments", "category", "given", "one", "set", "dimensions", "function", "two", "gradient", "boundary", "weak", "learn", "work", "performance", "class", "remp", "used", "boosted", "schapire", "may", "shown", "friedman", "new", "analysis", "classes", "spam", "results", "grubb", "opinion", "better", "bagnell", "features", "number", "gabor", "note", "stochastic", "stimuli", "workers", "dataset", "consider", "even", "learned", "crowdsourcing", "algorithms", "could", "ashby", "typically", "best", "maddox", "label", "key", "experimental", "iterations", "mturk", "error", "without", "real", "rules", "step", "whether", "large", "crosshair", "small", "section", "interpret", "reviews", "example", "lines", "interesting", "performs", "instance", "text", "based", "humanboost", "achieves", "however"], "authors": ["Harsh Pareek", "Pradeep Ravikumar"], "thumbnail_path": "thumbnails/Human Boosting.jpg"}, {"title": "LargeScale Learning with Less RAM via Randomization", "topics": [0.017024839803399881, 0.017024708530232718, 0.91487599540543918, 0.017024801938008833, 0.017025140810329974, 0.017024513512589299], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/golovin13.pdf", "most_common": ["learning", "randomized", "using", "rounding", "bound", "regret", "algorithm", "data", "ram", "online", "precision", "bits", "model", "use", "adaptive", "log", "via", "memory", "per", "rate", "rates", "set", "value", "let", "counting", "coordinate", "values", "encoding", "used", "less", "consider", "results", "prediction", "may", "since", "also", "proceedings", "theorem", "grid", "bounds", "cost", "machine", "number", "conference", "randomization", "loss", "mcmahan", "international", "counter", "logb", "gradient", "feasible", "probability", "error", "thus", "counts", "approximate", "large", "representation", "one", "store", "lemma", "point", "methods", "convex", "small", "ctr", "example", "proof", "variant", "algorithms", "linear", "training", "gives", "ogd", "added", "reduces", "schedule", "implies", "time", "round", "method", "feature", "given", "additional", "relative", "project", "note", "take", "larger", "scale", "acm", "range", "single", "resolution", "discrete", "even", "predictions", "following", "figure"], "authors": ["Daniel Golovin", "D. Sculley", "Brendan McMahan", "Michael Young"], "thumbnail_path": "thumbnails/LargeScale Learning with Less RAM via Randomization.jpg"}, {"title": "Robust Regression on MapReduce", "topics": [0.01708748728220463, 0.01708760697874858, 0.91456213978841716, 0.017087521656556415, 0.017087334825849763, 0.017087909468223524], "pdf_url": "http://jmlr.org/proceedings/papers/v28/meng13b.pdf", "most_common": ["algorithm", "regression", "algorithms", "mapreduce", "log", "work", "data", "clarkson", "sampling", "conditioning", "size", "problem", "ipcpm", "given", "problems", "random", "distributed", "robust", "let", "number", "convex", "solution", "solutions", "lemma", "method", "use", "matrix", "used", "also", "see", "compute", "single", "subsampled", "learning", "sample", "better", "standard", "randomized", "min", "proceedings", "mahoney", "machine", "since", "iterative", "one", "iterations", "fast", "time", "query", "parallel", "linear", "iteration", "multiple", "points", "relative", "point", "although", "computing", "describe", "pass", "solving", "framework", "construct", "note", "queries", "set", "gives", "annual", "proposed", "per", "results", "large", "vector", "ellipsoid", "following", "example", "optimal", "max", "well", "ram", "ipcpms", "approach", "many", "thus", "using", "communication", "strongly", "symposium", "extra", "particular", "subgradient", "table", "several", "transform", "meng", "cauchy", "interest", "initialization", "stored", "poly"], "authors": ["Michael Mahoney", "Xiangrui Meng"], "thumbnail_path": "thumbnails/Robust Regression on MapReduce.jpg"}, {"title": "Adaptive Task Assignment for Crowdsourced Classification", "topics": [0.022359505051175569, 0.022358538819331822, 0.88804046674268211, 0.02235885460518908, 0.022520253673519758, 0.022362381108101723], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/ho13.pdf", "most_common": ["task", "tasks", "algorithm", "workers", "worker", "optimal", "labels", "set", "assignment", "error", "values", "qmin", "probability", "label", "solution", "online", "let", "small", "estimate", "assign", "skill", "primal", "number", "problem", "using", "may", "section", "learner", "quality", "setting", "assume", "random", "standard", "gold", "levels", "model", "relaxed", "requester", "weights", "approximation", "would", "type", "assignments", "value", "access", "inference", "adaptive", "learning", "assigned", "skills", "crowdsourced", "estimates", "use", "crowdsourcing", "must", "given", "karger", "used", "true", "consider", "one", "dual", "also", "theorem", "linear", "guarantee", "algorithms", "labeling", "weighted", "since", "data", "exploration", "assigning", "complete", "formulation", "every", "work", "arrive", "produce", "types", "feasible", "majority", "close", "need", "min", "performance", "show", "lemma", "infer", "integer", "heterogeneous", "distribution", "diverse", "buchbinder", "following", "high", "provide", "including", "nips", "research"], "authors": ["Chien-Ju Ho", "Shahin Jabbari", "Jennifer Wortman Vaughan"], "thumbnail_path": "thumbnails/Adaptive Task Assignment for Crowdsourced Classification.jpg"}, {"title": "Local Deep Kernel Learning for Efficient Nonlinear SVM Prediction", "topics": [0.015327969765145904, 0.015328570621729357, 0.92335985002368026, 0.015327901965685604, 0.015327645299155965, 0.015328062324603018], "pdf_url": "http://jmlr.org/proceedings/papers/v28/jose13.pdf", "most_common": ["prediction", "kernel", "ldkl", "learning", "svm", "accuracy", "training", "time", "local", "data", "linear", "methods", "feature", "deep", "could", "multiple", "using", "learn", "given", "set", "speed", "node", "space", "features", "random", "lmkl", "decision", "primal", "support", "llsvm", "also", "function", "cpsp", "dual", "rff", "embedding", "sets", "loss", "parameters", "nips", "trees", "formulation", "large", "sign", "cost", "vectors", "fourier", "better", "covertype", "based", "learnt", "dimensional", "would", "thus", "kernels", "global", "number", "times", "jmlr", "tanh", "costs", "rahimi", "tree", "note", "accuracies", "however", "recht", "higher", "sparse", "scale", "problem", "approximation", "even", "path", "two", "optimization", "paper", "smooth", "single", "compared", "vector", "zero", "high", "speeding", "found", "furthermore", "banana", "performance", "point", "descent", "functions", "focus", "localized", "results", "figure", "gonen", "experiments", "torr", "maintaining", "since"], "authors": ["Cijo Jose", "Prasoon Goyal", "Parv Aggrwal", "Manik Varma"], "thumbnail_path": "thumbnails/Local Deep Kernel Learning for Efficient Nonlinear SVM Prediction.jpg"}, {"title": "Fastfood  Computing Hilbert Space Expansions in loglinear time", "topics": [0.017693966240932363, 0.017696171293209231, 0.91152767324677586, 0.017694433636191928, 0.017693778042486698, 0.017693977540403864], "pdf_url": "http://jmlr.org/proceedings/papers/v28/le13.pdf", "most_common": ["kernel", "random", "fastfood", "gaussian", "kitchen", "matrices", "matrix", "sinks", "rbf", "function", "expansions", "cos", "approximation", "basis", "time", "methods", "log", "functions", "rahimi", "recht", "also", "using", "fourier", "use", "space", "exact", "computation", "feature", "features", "given", "theorem", "computing", "large", "training", "smola", "hadamard", "method", "let", "hence", "independent", "scaling", "learning", "transform", "compute", "vector", "fast", "loglinear", "experiments", "terms", "hilbert", "even", "nystrom", "sii", "diagonal", "number", "note", "accuracy", "show", "distribution", "regression", "expansion", "fact", "entries", "small", "prove", "map", "data", "set", "key", "cov", "many", "kernels", "used", "dimension", "input", "matern", "dataset", "rows", "storage", "results", "prediction", "memory", "work", "nips", "spectral", "much", "case", "well", "costs", "support", "problems", "faster", "permutation", "via", "two", "iid", "proof", "machine", "instead", "since"], "authors": ["Quoc Le", "Tamas Sarlos", "Alexander Smola"], "thumbnail_path": "thumbnails/Fastfood  Computing Hilbert Space Expansions in loglinear time.jpg"}, {"title": "Smooth Operators and an RKHS Integration Approach", "topics": [0.016764002559091776, 0.01676415593381218, 0.91617939987641561, 0.016764139527535766, 0.016764196042780864, 0.016764106060363864], "pdf_url": "http://jmlr.org/proceedings/papers/v28/grunewalder13.pdf", "most_common": ["rkhs", "operator", "operators", "kernel", "estimate", "conditional", "function", "smooth", "case", "measure", "approximate", "risk", "linear", "multiplication", "rule", "gretton", "product", "expectation", "approach", "problem", "approximation", "theorem", "song", "fukumizu", "error", "bounded", "functions", "adjoint", "natural", "sup", "space", "sum", "two", "basic", "want", "measures", "operations", "constraints", "one", "learning", "reproducing", "integral", "smola", "use", "derivative", "exists", "transformations", "hilbert", "form", "assume", "upper", "change", "wij", "positive", "proof", "eqx", "pontil", "huang", "mean", "corresponding", "samples", "operation", "important", "consider", "fremlin", "example", "sample", "generic", "expectations", "estimating", "get", "probability", "rates", "see", "embeddings", "inference", "convergence", "solution", "suitable", "assumptions", "sense", "mapping", "bound", "used", "since", "theory", "eqy", "given", "assumption", "vito", "however", "regression", "complex", "via", "often", "general", "scalar", "errors", "shift", "useful"], "authors": ["Steffen Grunewalder", "Gretton Arthur", "John Shawe-Taylor"], "thumbnail_path": "thumbnails/Smooth Operators and an RKHS Integration Approach.jpg"}, {"title": "Domain Adaptation under Target and Conditional Shift", "topics": [0.018504045850467013, 0.018504298003849472, 0.9074796130136028, 0.018504021241903871, 0.018503980675206953, 0.018504041214969694], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhang13d.pdf", "most_common": ["test", "new", "data", "shift", "distribution", "training", "domain", "conditional", "tars", "kernel", "target", "set", "class", "adaptation", "learning", "change", "changes", "causal", "problem", "estimate", "ytr", "one", "approaches", "regression", "pxy", "getars", "given", "approach", "embedding", "situation", "well", "consider", "marginal", "sample", "machine", "mean", "estimated", "xnew", "use", "covariate", "cons", "problems", "atars", "reweighting", "matrix", "correction", "performance", "points", "across", "importance", "empirical", "see", "proposed", "covs", "xte", "acons", "note", "expected", "xtr", "gretton", "error", "assumptions", "knowledge", "case", "make", "two", "loss", "distributions", "assume", "weights", "four", "let", "would", "values", "making", "practice", "also", "minimizing", "parameters", "huang", "estimation", "used", "minimize", "possible", "table", "smola", "following", "cause", "generalized", "boundary", "however", "fukumizu", "denote", "domains", "sets", "model", "transformed", "practical", "support", "reg"], "authors": ["Kun Zhang", "Bernhard Schoelkopf", "Krikamol Muandet", "Zhikun Wang"], "thumbnail_path": "thumbnails/Domain Adaptation under Target and Conditional Shift.jpg"}, {"title": "Learning Optimally Sparse Support Vector Machines", "topics": [0.016998585904716465, 0.016998943463712432, 0.91500629813351508, 0.016998702061873545, 0.016998752007399927, 0.016998718428782585], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/cotter13.pdf", "most_common": ["support", "svm", "training", "sparse", "lhinge", "predictor", "problem", "set", "using", "vector", "vectors", "size", "error", "bound", "hinge", "svms", "section", "one", "kernel", "solution", "number", "learning", "margin", "also", "optimization", "loss", "algorithm", "perceptron", "lemma", "procedure", "sample", "best", "value", "function", "large", "small", "subgradient", "following", "algorithms", "least", "lslant", "solutions", "optimally", "descent", "step", "runtime", "use", "machine", "osuna", "generalization", "objective", "show", "supported", "approach", "slant", "log", "example", "data", "complexity", "based", "however", "empirical", "bias", "timit", "well", "examples", "test", "experiments", "even", "optimize", "method", "must", "instead", "cotter", "perform", "probability", "kernelized", "http", "see", "bounds", "prediction", "cost", "resulting", "nguyen", "adult", "known", "guarantee", "good", "standard", "compression", "xit", "iteration", "lin", "aggressive", "terms", "girosi", "used", "obtain", "theorem", "performance"], "authors": ["Andrew Cotter", "Shai Shalev-Shwartz", "Nati Srebro"], "thumbnail_path": "thumbnails/Learning Optimally Sparse Support Vector Machines.jpg"}, {"title": "A New Frontier of Kernel Design for Structured Data", "topics": [0.023047647344527737, 0.023047616095232298, 0.88476195867352125, 0.023047714244545759, 0.023047585944696778, 0.023047477697476157], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/shin13.pdf", "most_common": ["kernel", "kernels", "partitionable", "type", "degree", "mapping", "hidden", "two", "theorem", "family", "positive", "let", "data", "shin", "example", "new", "string", "iii", "pairs", "lemma", "design", "structured", "also", "one", "frontier", "hence", "case", "follows", "search", "kuboyama", "table", "important", "following", "good", "since", "distance", "theory", "parameters", "adjustable", "use", "holds", "formula", "number", "tree", "trees", "compute", "set", "symmetric", "literature", "fact", "optimal", "replacing", "linear", "determined", "pair", "class", "average", "show", "obtain", "grid", "integral", "associated", "computation", "recurrence", "novel", "matrices", "counts", "appendix", "machine", "answer", "parameter", "framework", "edit", "furthermore", "given", "means", "characterization", "three", "thus", "cross", "using", "convolution", "assume", "space", "validation", "results", "advantage", "method", "prove", "hold", "information", "derived", "combination", "used", "kcnt", "induction", "leukemia", "need", "formulas", "based"], "authors": ["Kilho Shin"], "thumbnail_path": "thumbnails/A New Frontier of Kernel Design for Structured Data.jpg"}, {"title": "Characterizing the Representer Theorem", "topics": [0.018796879669486392, 0.018797210476846564, 0.90601117482861138, 0.018800960106638086, 0.018796981287121713, 0.018796793631295987], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/yu13.pdf", "most_common": ["theorem", "representer", "function", "admissible", "increasing", "proof", "let", "also", "note", "matrix", "case", "condition", "hence", "admissibility", "regularizer", "one", "argyriou", "strictly", "since", "kernel", "problem", "characterization", "proposition", "norm", "vector", "section", "learning", "example", "radial", "result", "characterizing", "thus", "necessary", "complete", "consider", "prove", "figure", "see", "interpolation", "remark", "following", "holds", "product", "inner", "results", "therefore", "dinuzzo", "take", "suppose", "vectors", "loss", "hilbert", "matrices", "must", "rkhs", "machine", "singular", "wahba", "paper", "main", "reproducing", "clearly", "min", "fact", "get", "set", "conditions", "notice", "property", "lower", "methods", "equivalent", "although", "theory", "even", "work", "claim", "minimizer", "easily", "space", "gives", "new", "considered", "points", "left", "show", "spaces", "point", "due", "lim", "thanks", "previous", "follows", "convex", "regularizers", "next", "form", "true", "proved", "implies"], "authors": ["Yaoliang Yu", "Hao Cheng", "Dale Schuurmans", "Csaba Szepesvari"], "thumbnail_path": "thumbnails/Characterizing the Representer Theorem.jpg"}, {"title": "Covariate Shift in Hilber Space A Solution Via Sorrogate Kernels", "topics": [0.018837970449992501, 0.0188381000342315, 0.90580979196843991, 0.018838144247149153, 0.018837921311092919, 0.018838071989093912], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhang13b.pdf", "most_common": ["kernel", "data", "matrix", "training", "surrogate", "learning", "sample", "space", "test", "domain", "covariate", "hilbert", "matrices", "shift", "two", "transfer", "using", "wifi", "distributions", "used", "figure", "feature", "across", "table", "model", "via", "similar", "solution", "one", "performance", "new", "kernels", "time", "machine", "set", "domains", "eigenvector", "kzx", "given", "empirical", "pan", "distribution", "learned", "therefore", "information", "localization", "testing", "eigenfunctions", "collected", "signals", "signal", "methods", "transform", "devices", "results", "section", "following", "neural", "adaptation", "proposed", "samples", "provides", "conference", "svm", "international", "map", "propose", "research", "linear", "continuous", "yang", "compute", "underlying", "best", "approach", "problem", "transformed", "corresponding", "theorem", "input", "evaluate", "tasks", "kmm", "processing", "concept", "let", "use", "particular", "three", "want", "sugiyama", "mean", "estimate", "advances", "selection", "text", "labels", "kliep", "huang", "aligning"], "authors": ["Kai Zhang", "Vincent Zheng", "QIaojun Wang", "James Kwok", "Qiang Yang"], "thumbnail_path": "thumbnails/Covariate Shift in Hilber Space A Solution Via Sorrogate Kernels.jpg"}, {"title": "Fast Conical Hull Algorithms for Nearseparable Nonnegative Matrix Factorization", "topics": [0.017103974678490279, 0.017088580060972254, 0.91449353083581586, 0.01708762553013406, 0.017138835954892486, 0.017087452939694873], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kumar13b.pdf", "most_common": ["xray", "matrix", "cone", "algorithms", "algorithm", "extreme", "nmf", "columns", "current", "set", "hottopixx", "separable", "performance", "greedy", "datasets", "hull", "conical", "step", "rays", "data", "factorization", "point", "anchor", "methods", "figure", "vavasis", "selection", "also", "dist", "features", "arg", "fast", "problem", "gillis", "selected", "residual", "used", "points", "implementation", "local", "projection", "accuracy", "anchors", "sparse", "noise", "vector", "use", "exterior", "rand", "one", "ray", "proposed", "using", "column", "clustering", "solution", "obtained", "subset", "nonnegative", "hence", "number", "modeling", "topic", "parallel", "arora", "based", "new", "optimization", "convex", "problems", "generated", "search", "solving", "bittorf", "variables", "assumption", "multiple", "iterations", "lemma", "combinations", "experiments", "maximum", "detection", "scalability", "three", "reuters", "ibmt", "well", "esser", "svm", "results", "let", "table", "highly", "normalized", "may", "max", "tropp", "research", "linear"], "authors": ["Abhishek Kumar", "Vikas Sindhwani", "Prabhanjan Kambadur"], "thumbnail_path": "thumbnails/Fast Conical Hull Algorithms for Nearseparable Nonnegative Matrix Factorization.jpg"}, {"title": "General Functional Matrix Factorization Using Gradient Boosting", "topics": [0.016538242895250806, 0.016538792285087998, 0.91730588784407663, 0.01653820548226426, 0.016538416022678162, 0.016540455470642167], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/chen13e.pdf", "most_common": ["feature", "time", "function", "model", "matrix", "information", "factorization", "method", "functions", "user", "latent", "use", "functional", "gradient", "using", "general", "training", "data", "yij", "algorithm", "results", "dataset", "also", "factor", "set", "vkj", "learning", "auxiliary", "boosting", "one", "demographic", "construction", "models", "section", "complexity", "two", "collaborative", "tree", "hij", "gfmf", "interest", "split", "methods", "may", "features", "new", "conference", "second", "space", "objective", "performance", "dependent", "observed", "bias", "loss", "social", "users", "age", "international", "table", "music", "give", "order", "rmse", "number", "construct", "proceedings", "make", "preference", "acm", "statistics", "gij", "problem", "prediction", "segmentation", "hlef", "best", "koren", "hright", "step", "automatically", "dimensions", "segments", "item", "train", "equation", "work", "learn", "topic", "algorithms", "paper", "usa", "friedman", "based", "knowledge", "datasets", "bin", "thus", "used", "attributes"], "authors": ["Tianqi Chen", "Hang Li", "Qiang Yang", "Yong Yu"], "thumbnail_path": "thumbnails/General Functional Matrix Factorization Using Gradient Boosting.jpg"}, {"title": "Fast MaxMargin Matrix Factorization with Data Augmentation", "topics": [0.016624940096703497, 0.016624970464225612, 0.91687382072509938, 0.016625302860632254, 0.016624730935698967, 0.016626234917640332], "pdf_url": "http://jmlr.org/proceedings/papers/v28/xu13a.pdf", "most_common": ["gibbs", "data", "model", "matrix", "problem", "latent", "loss", "par", "nonparametric", "factorization", "sampling", "factors", "probabilistic", "augmentation", "number", "learning", "srebro", "averaged", "single", "yij", "posterior", "distribution", "models", "algorithm", "delegate", "rrm", "fast", "bayesian", "samples", "given", "pair", "new", "hinge", "methods", "function", "formulation", "two", "level", "rennie", "factor", "set", "machine", "map", "solving", "induced", "one", "directly", "error", "zhu", "tij", "users", "risk", "international", "ibp", "inference", "max", "since", "movielens", "truncation", "conference", "thus", "binary", "test", "time", "nmae", "use", "training", "ratings", "min", "note", "sets", "eachmovie", "conditional", "log", "regularizer", "distributions", "prior", "process", "term", "may", "variational", "also", "weak", "simple", "strong", "alternative", "yet", "form", "icml", "maximum", "polson", "normalized", "thresholds", "scott", "features", "actually", "introduce", "likelihood", "iteration", "dimension"], "authors": ["Minjie Xu", "Jun Zhu", "Bo Zhang"], "thumbnail_path": "thumbnails/Fast MaxMargin Matrix Factorization with Data Augmentation.jpg"}, {"title": "Local LowRank Matrix Approximation", "topics": [0.016819363110675667, 0.016819046877938323, 0.9159046150727731, 0.016819127110946838, 0.016818862755077612, 0.016818985072588357], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/lee13.pdf", "most_common": ["matrix", "llorma", "local", "svd", "approximation", "set", "rank", "kernel", "using", "observed", "number", "anchor", "points", "systems", "assume", "entries", "use", "information", "factorization", "based", "global", "recommendation", "bound", "models", "proposition", "matrices", "two", "rmse", "learning", "algorithm", "train", "machine", "dfc", "distance", "movielens", "case", "function", "lee", "assumption", "min", "conference", "used", "analysis", "norm", "large", "section", "method", "figure", "may", "size", "outperforms", "proposed", "methods", "problem", "denote", "test", "small", "known", "tao", "experiments", "estimate", "mackey", "accuracy", "completion", "see", "several", "without", "international", "results", "neighborhood", "processing", "compressed", "def", "instead", "neural", "product", "since", "standard", "indices", "continuous", "arg", "locally", "three", "salakhutdinov", "well", "lebanon", "uniformly", "analyze", "users", "collaborative", "linear", "mnih", "lines", "least", "training", "probability", "observations", "incomplete", "winner", "arxiv"], "authors": ["Joonseok Lee", "Seungyeon Kim", "Guy Lebanon", "Yoram Singer"], "thumbnail_path": "thumbnails/Local LowRank Matrix Approximation.jpg"}, {"title": "Learning the betaDivergence in Tweedie Compound Poisson Matrix Factorization Models", "topics": [0.019322156127783371, 0.019326141070990458, 0.90321734624680594, 0.01932247746331938, 0.019320411223216122, 0.019491467867884575], "pdf_url": "http://jmlr.org/proceedings/papers/v28/simsekli13.pdf", "most_common": ["poisson", "compound", "factorization", "parameter", "model", "matrix", "dispersion", "tweedie", "methods", "models", "index", "log", "data", "audio", "distribution", "divergence", "lyrics", "use", "using", "song", "symbolic", "music", "tensor", "one", "modeling", "algorithm", "positive", "note", "time", "matrices", "inference", "learning", "coupled", "icm", "figure", "features", "given", "order", "observed", "section", "study", "estimate", "also", "exp", "variance", "estimation", "present", "musical", "follows", "function", "polyphonic", "functions", "notes", "power", "therefore", "information", "factors", "parameters", "missing", "problem", "exponential", "used", "useful", "form", "excitation", "dunn", "method", "marginal", "two", "following", "applications", "gamma", "representation", "frames", "nonnegative", "approach", "results", "smyth", "similar", "cost", "particular", "mean", "since", "dictionary", "probability", "variational", "observation", "random", "experiments", "obtain", "evaluate", "songs", "case", "level", "prediction", "international", "processing", "family", "known", "natural"], "authors": ["Umut Simsekli", "Yusuf Kenan Yilmaz", "Ali Taylan Cemgil"], "thumbnail_path": "thumbnails/Learning the betaDivergence in Tweedie Compound Poisson Matrix Factorization Models.jpg"}, {"title": "ELLA An Efficient Lifelong Learning Algorithm", "topics": [0.015853598185943014, 0.015853121234647542, 0.92073318509715651, 0.015853284101116926, 0.015853723652737479, 0.015853087728398517], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/ruvolo13.pdf", "most_common": ["learning", "task", "ella", "data", "tasks", "lifelong", "accuracy", "algorithm", "training", "model", "new", "learned", "number", "omtl", "performance", "using", "set", "online", "batch", "regression", "models", "knowledge", "given", "basis", "three", "stl", "speedup", "latent", "problem", "facial", "equation", "show", "approach", "transfer", "use", "term", "expression", "function", "mtl", "time", "particular", "parameter", "instances", "mine", "value", "two", "shared", "previously", "update", "land", "results", "iii", "values", "linear", "proceedings", "components", "sets", "sparse", "conference", "compute", "vector", "cost", "agent", "machine", "complexity", "magnitude", "used", "since", "one", "min", "fact", "see", "delta", "international", "total", "next", "must", "dictionary", "coding", "relative", "converges", "instance", "optimized", "london", "arg", "across", "optimization", "combination", "also", "problems", "section", "method", "based", "kumar", "following", "proof", "algorithms", "features", "orders", "nearly"], "authors": ["Paul Ruvolo", "Eric Eaton"], "thumbnail_path": "thumbnails/ELLA An Efficient Lifelong Learning Algorithm.jpg"}, {"title": "Riemannian Similarity Learning", "topics": [0.014819878630014936, 0.014819757302224066, 0.92590107865644478, 0.01481989234433051, 0.014819704572459839, 0.014819688494525782], "pdf_url": "http://jmlr.org/proceedings/papers/v28/cheng13.pdf", "most_common": ["learning", "riemannian", "similarity", "matrix", "action", "absil", "algorithm", "metric", "manifold", "work", "training", "recognition", "methods", "space", "rsl", "vector", "tangent", "applications", "domain", "also", "performance", "kulis", "optimization", "function", "point", "used", "loss", "rank", "consider", "related", "gradw", "retraction", "object", "set", "problem", "two", "benchmark", "following", "experiments", "one", "data", "labels", "model", "images", "varying", "bilinear", "method", "domains", "gradient", "accuracy", "saenko", "euclidean", "well", "proposed", "table", "class", "synthetic", "categories", "new", "feature", "instances", "pairwise", "min", "webcam", "face", "dimension", "hog", "denote", "log", "form", "matrices", "particular", "values", "learn", "example", "hof", "dataset", "target", "generalization", "rhs", "local", "amazon", "factorization", "lee", "geometric", "connection", "adaptation", "three", "cvpr", "results", "using", "usually", "comparison", "functions", "hnf", "nocedal", "presented", "prediction", "aim", "positive"], "authors": ["Li Cheng"], "thumbnail_path": "thumbnails/Riemannian Similarity Learning.jpg"}, {"title": "MultipleSource Cross Validation", "topics": [0.019877600936449233, 0.019877484914443407, 0.9006127916541371, 0.019877280379113498, 0.019877279854686399, 0.019877562261170417], "pdf_url": "http://jmlr.org/proceedings/papers/v28/geras13.pdf", "most_common": ["data", "error", "training", "estimator", "estimators", "variance", "estimate", "learning", "bias", "procedure", "new", "test", "set", "source", "cvr", "cvs", "bengio", "section", "unbiased", "eki", "grandvalet", "figure", "standard", "sources", "setting", "domains", "machine", "ckl", "used", "yields", "decomposition", "quadratic", "prediction", "instead", "variables", "previous", "form", "let", "common", "points", "table", "equations", "work", "mean", "one", "show", "expected", "results", "large", "number", "domain", "terms", "sets", "also", "structure", "average", "consider", "random", "smaller", "blocks", "practice", "panel", "larger", "empirical", "even", "ekm", "resulting", "positive", "sample", "get", "better", "magnitude", "idea", "first", "performance", "based", "testing", "see", "blitzer", "suggested", "cov", "adaptation", "much", "covariance", "case", "analysis", "using", "within", "similar", "denote", "distributions", "algorithm", "reasoning", "every", "estimates", "second", "design", "items", "would", "naive"], "authors": ["Krzysztof Geras", "Charles Sutton"], "thumbnail_path": "thumbnails/MultipleSource Cross Validation.jpg"}, {"title": "Activized Learning with Uniform Classification Noise", "topics": [0.021238517746590451, 0.021242093793749167, 0.89378580465004542, 0.021238700820782084, 0.021238264830064382, 0.021256618158768621], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/yang13c.pdf", "most_common": ["dxy", "learning", "label", "passive", "noise", "active", "algorithm", "subroutine", "uniform", "hanneke", "sample", "exp", "labels", "let", "set", "labeled", "data", "universal", "number", "sequence", "complexity", "activized", "probability", "uniformnoise", "budget", "sets", "given", "result", "examples", "since", "also", "lemma", "case", "activizers", "constant", "one", "values", "algorithms", "nontrivial", "activizer", "request", "based", "function", "shatters", "concept", "rate", "may", "machine", "classes", "pair", "problem", "suppose", "thus", "methods", "appropriate", "distribution", "exist", "returned", "would", "work", "target", "min", "following", "many", "unlabeled", "input", "referred", "log", "called", "denote", "results", "every", "small", "even", "existence", "feed", "need", "points", "however", "simply", "value", "error", "several", "literature", "way", "certain", "distributions", "required", "original", "consider", "vapnik", "technique", "empirical", "section", "two", "therefore", "pairs", "recursive", "return", "always"], "authors": ["Liu Yang", "Steve Hanneke"], "thumbnail_path": "thumbnails/Activized Learning with Uniform Classification Noise.jpg"}, {"title": "Efficient Active Learning of Halfspaces an Aggressive Approach", "topics": [0.017258944540010701, 0.017264333683345196, 0.91369482582717276, 0.017259472990761429, 0.01726023353098487, 0.017262189427724926], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/gonen13.pdf", "most_common": ["active", "learning", "algorithm", "label", "complexity", "aluma", "greedy", "approach", "pool", "aggressive", "space", "version", "distribution", "mellow", "log", "halfspaces", "examples", "margin", "learner", "approximation", "labeling", "hypothesis", "probability", "using", "show", "example", "majority", "cal", "sample", "guarantee", "data", "theorem", "results", "number", "given", "labels", "factor", "queries", "result", "case", "unlabeled", "volume", "also", "class", "denote", "guarantees", "outputs", "query", "algorithms", "optimal", "vote", "let", "pmin", "error", "dasgupta", "opt", "bound", "alg", "uniform", "gonen", "one", "target", "realizable", "euclidean", "possible", "approximate", "setting", "random", "would", "compare", "since", "lemma", "analysis", "proposed", "passive", "consider", "qbc", "allows", "balcan", "machine", "better", "theory", "koller", "assumption", "proceedings", "exists", "tong", "thus", "convex", "general", "cases", "small", "section", "prove", "theoretical", "used", "shown", "approaches", "obtain", "improvement"], "authors": ["Alon Gonen", "Sivan Sabato", "Shai Shalev-Shwartz"], "thumbnail_path": "thumbnails/Efficient Active Learning of Halfspaces an Aggressive Approach.jpg"}, {"title": "Selective sampling algorithms for costsensitive multiclass prediction", "topics": [0.018792251180926742, 0.018792180771736243, 0.90598506444110882, 0.018792416325548622, 0.018844153509001548, 0.018793933771677866], "pdf_url": "http://jmlr.org/proceedings/papers/v28/agarwal13.pdf", "most_common": ["multiclass", "regret", "query", "active", "learning", "algorithm", "matrix", "cost", "algorithms", "model", "function", "rule", "number", "selective", "loss", "results", "also", "assumption", "label", "sampling", "case", "queries", "probability", "prediction", "setting", "complexity", "random", "data", "linear", "log", "binary", "dgs", "use", "assumptions", "noise", "condition", "order", "classes", "average", "labels", "orabona", "best", "passive", "small", "ratio", "weight", "convex", "tsybakov", "section", "criterion", "given", "online", "class", "based", "see", "problem", "describe", "structure", "large", "parameter", "gentile", "arg", "generated", "assume", "probabilities", "mismatch", "work", "example", "machine", "better", "structured", "points", "logistic", "observe", "used", "previous", "theorem", "guarantees", "using", "examples", "similar", "general", "dekel", "update", "subsampling", "theoretical", "particular", "max", "natural", "intuition", "following", "set", "according", "bbq", "present", "error", "obtain", "conditional", "form", "consider"], "authors": ["Alekh Agarwa"], "thumbnail_path": "thumbnails/Selective sampling algorithms for costsensitive multiclass prediction.jpg"}, {"title": "Generic Exploration and Karmed Voting Bandits", "topics": [0.020309275458291292, 0.020309859556172091, 0.8984524878137049, 0.020309454111486439, 0.020309631721175277, 0.020309291339169991], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/urvoy13.pdf", "most_common": ["bandits", "algorithm", "exploration", "decision", "savage", "generic", "condorcet", "problem", "matrix", "preference", "arm", "environment", "figure", "yue", "order", "set", "regret", "parameters", "algorithms", "see", "dueling", "joachims", "simulations", "voting", "winner", "best", "function", "parameter", "independence", "feasible", "also", "ucop", "bandit", "rigged", "time", "sampling", "independent", "samples", "arms", "elimination", "predicate", "uniform", "sample", "borda", "mean", "logp", "used", "pac", "setting", "problems", "bounded", "stochastic", "rate", "copeland", "beat", "policy", "number", "random", "expected", "several", "reward", "parametric", "proposed", "horizon", "utility", "linear", "explored", "one", "learning", "analysis", "bound", "pxq", "use", "existence", "propose", "wrapped", "online", "state", "sensitivity", "simple", "ucb", "cumulative", "instance", "theorem", "interleave", "auer", "design", "preferences", "section", "explore", "following", "criterion", "complexity", "feedback", "term", "probability", "accuracy", "arg", "filtering", "property"], "authors": ["Tanguy Urvoy", "Fabrice Clerot", "Raphael Feraud", "Sami Naamane"], "thumbnail_path": "thumbnails/Generic Exploration and Karmed Voting Bandits.jpg"}, {"title": "Efficient Semisupervised and Active Learning of Disjunctions", "topics": [0.016324107136449318, 0.016324226243100884, 0.91837730627271885, 0.016325415972594307, 0.01632419273928408, 0.016324751635852657], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/balcan13.pdf", "most_common": ["learning", "examples", "set", "algorithm", "labeled", "hypothesis", "example", "log", "active", "probability", "variables", "graph", "number", "sample", "indicators", "negative", "path", "positive", "unlabeled", "complexity", "compatible", "disjunctions", "vertex", "consistent", "label", "data", "indicator", "one", "connected", "variable", "error", "commonality", "target", "bound", "time", "must", "blum", "balcan", "cover", "type", "edge", "using", "algorithms", "least", "given", "bounds", "setting", "disjunction", "appears", "proceedings", "let", "conference", "appear", "machine", "hypotheses", "every", "vertices", "components", "minimal", "labels", "contains", "since", "problem", "endpoints", "search", "queries", "polynomial", "mistake", "regularity", "dasgupta", "output", "function", "updates", "allows", "outputs", "minimum", "compatibility", "furthermore", "random", "enough", "present", "used", "running", "model", "identify", "computational", "two", "removing", "distribution", "concept", "international", "component", "along", "makes", "nearest", "information", "gcom", "assumption", "generalization", "general"], "authors": ["Nina Balcan", "Christopher Berlind", "Steven Ehrlich", "Yingyu Liang"], "thumbnail_path": "thumbnails/Efficient Semisupervised and Active Learning of Disjunctions.jpg"}, {"title": "Costsensitive Multiclass Classification Risk Bounds", "topics": [0.02971617496668132, 0.029716820674557779, 0.85141669498898209, 0.029717760175866741, 0.02971608815202556, 0.02971646104188656], "pdf_url": "http://jmlr.org/proceedings/papers/v28/avilapires13.pdf", "most_common": ["inf", "calibration", "function", "loss", "lemma", "multiclass", "let", "risk", "assumption", "bounds", "proposition", "proof", "surrogate", "theorem", "convex", "result", "functions", "results", "case", "also", "holds", "since", "binary", "show", "follows", "min", "assumptions", "given", "steinwart", "section", "lee", "problem", "bartlett", "consider", "losses", "particular", "work", "one", "set", "exists", "maximum", "learning", "simplex", "prove", "coding", "clearly", "using", "implies", "measurable", "cost", "satisfy", "constants", "table", "selector", "calibrated", "label", "otherwise", "mroueh", "obtain", "examples", "proofs", "hinge", "assume", "remains", "columns", "machine", "max", "minimizer", "scoring", "hence", "need", "satisfying", "minimizing", "minimization", "span", "form", "vector", "positive", "following", "may", "note", "based", "reid", "presented", "journal", "excess", "use", "two", "therefore", "taken", "numbers", "choose", "matrix", "furthermore", "statement", "measured", "means", "argmax", "present", "empirical"], "authors": ["Bernardo Pires", "Csaba Szepesvari", "Mohammad Ghavamzadeh"], "thumbnail_path": "thumbnails/Costsensitive Multiclass Classification Risk Bounds.jpg"}, {"title": "Active Learning for MultiObjective Optimization", "topics": [0.021157389704657661, 0.021157585006103229, 0.89419030404663824, 0.02115780428670104, 0.021179441064252277, 0.021157475891647553], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/zuluaga13.pdf", "most_common": ["error", "evaluations", "percentage", "pal", "design", "optimization", "points", "set", "sampling", "algorithm", "pareto", "learning", "active", "space", "objective", "process", "noc", "gaussian", "log", "objectives", "max", "data", "designs", "one", "hypervolume", "uncertainty", "prediction", "sample", "example", "number", "parego", "point", "problem", "cost", "use", "evolutionary", "accuracy", "evaluated", "sets", "function", "bounds", "frontier", "snw", "min", "kernel", "uses", "evaluation", "iteration", "show", "srinivas", "expensive", "theorem", "used", "models", "desired", "theoretical", "information", "optimal", "since", "approach", "analysis", "functions", "results", "zuluaga", "every", "section", "values", "following", "figure", "choose", "probability", "also", "performance", "iterations", "achieve", "predict", "three", "case", "thus", "conference", "multiobjective", "consider", "consists", "cases", "parameter", "zurich", "squared", "may", "target", "many", "reduction", "exponential", "several", "obtain", "evaluate", "average", "using", "next", "convergence", "method"], "authors": ["Marcela Zuluaga", "Guillaume Sergent", "Andreas Krause", "Markus Pueschel"], "thumbnail_path": "thumbnails/Active Learning for MultiObjective Optimization.jpg"}, {"title": "Nearoptimal Batch Mode Active Learning and Adaptive Submodular Optimization", "topics": [0.018490059860657073, 0.01849780178497511, 0.90752868355084748, 0.018494072191925011, 0.018497997054494744, 0.018491385557100511], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/chen13b.pdf", "most_common": ["active", "batch", "learning", "sequential", "batchgreedy", "set", "labels", "policy", "mode", "algorithm", "greedy", "fully", "submodular", "adaptive", "optimal", "number", "examples", "nodes", "cost", "observations", "batches", "optimization", "maximization", "random", "selected", "items", "problem", "figure", "hypotheses", "well", "problems", "results", "use", "example", "data", "krause", "golovin", "social", "applications", "network", "unlabeled", "item", "select", "prove", "one", "size", "approach", "simple", "using", "practical", "svm", "consider", "natural", "selection", "case", "competitive", "general", "policies", "theorem", "setting", "next", "sample", "target", "many", "time", "even", "section", "let", "obtained", "two", "algorithms", "linear", "note", "also", "selecting", "corresponding", "sampler", "surprisingly", "several", "compared", "stochastic", "marginal", "theoretical", "known", "following", "information", "goal", "may", "labeling", "probability", "fact", "observe", "state", "dasgupta", "kempe", "passive", "samples", "decision", "submodularity", "made"], "authors": ["Yuxin Chen", "Andreas Krause"], "thumbnail_path": "thumbnails/Nearoptimal Batch Mode Active Learning and Adaptive Submodular Optimization.jpg"}]}