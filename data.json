{"topics": [["channels", "channel", "seizure", "epileptic", "ieeg", "parsing", "seizures", "switching", "bursts", "electrode", "heldout", "onset", "recordings", "independencies", "epilepsy", "litt", "esteller", "parsings", "intuitive", "patients"], ["topic", "policy", "sparse", "dropout", "kernel", "feature", "state", "recovery", "topics", "network", "kernels", "group", "matrix", "features", "variational", "process", "inference", "log", "training", "sparsity"], ["spn", "spns", "learnspn", "query", "domingos", "subsets", "cll", "pll", "davis", "winmine", "lowd", "poon", "della", "pietra", "sij", "bbc", "gogate", "kddcup", "eachmovie", "chickering"], ["mri", "motor", "demonstration", "audio", "house", "timesteps", "demonstrations", "neuroimaging", "innovation", "singer", "mci", "bursts", "electrode", "switching", "spearman", "disease", "tags", "years", "never", "heavy"], ["internal", "cursor", "mri", "plant", "trading", "reversion", "basket", "bmi", "ime", "baskets", "timestep", "portmanteau", "costs", "transaction", "predictability", "feedback", "assets", "cointegration", "tiao", "ols"], ["bekk", "songs", "bmdc", "musical", "rock", "song", "music", "jazz", "artists", "metal", "innovation", "artist", "blues", "classic", "hip", "hop", "audio", "genres", "pop", "genre"]], "papers": [{"title": "On autoencoder scoring", "topics": [0.015723348209175803, 0.92138331449189903, 0.015723342619689423, 0.015723406649709139, 0.015723266080484126, 0.01572332194904243], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kamyshanska13.pdf", "most_common": ["autoencoder", "data", "scores", "autoencoders", "energy", "learning", "training", "using", "activation", "hidden", "model", "function", "models", "class", "may", "log", "bengio", "sigmoid", "linear", "vector", "reconstruction", "factored", "assign", "one", "error", "example", "dynamical", "vincent", "conference", "memisevic", "scoring", "show", "score", "binary", "alain", "const", "activations", "international", "hinton", "train", "machine", "systems", "compute", "case", "rbm", "used", "functions", "weights", "learn", "representations", "gradient", "classes", "also", "performance", "probabilistic", "unnormalized", "units", "neural", "input", "denoising", "unit", "information", "shown", "features", "number", "based", "processing", "deep", "parameters", "trained", "viewed", "aes", "rifai", "variety", "allows", "use", "work", "criterion", "swersky", "energies", "squared", "larochelle", "exp", "typically", "section", "networks", "contractive", "like", "way", "outputs", "figure", "good", "term", "weight", "since", "shows", "normalizing", "icml", "potential", "multiple"], "authors": "Hanna Kamyshanska; Roland Memisevic", "thumbnail_path": "thumbnails/On autoencoder scoring.jpg"}, {"title": "On the difficulty of training Recurrent Neural Networks", "topics": [0.014135659712517613, 0.92930969506022354, 0.014135627351292637, 0.014135710470615579, 0.014135559070901546, 0.014147748334449267], "pdf_url": "http://jmlr.org/proceedings/papers/v28/pascanu13.pdf", "most_common": ["model", "gradients", "recurrent", "term", "one", "gradient", "state", "neural", "problem", "networks", "exploding", "wrec", "norm", "vanishing", "time", "training", "long", "error", "clipping", "use", "learning", "see", "order", "network", "bengio", "step", "input", "regularization", "length", "problems", "attractor", "unit", "would", "mikolov", "temporal", "large", "rate", "jaeger", "change", "two", "dynamical", "systems", "hidden", "sequence", "boundary", "sequences", "direction", "descent", "task", "success", "doya", "results", "win", "explode", "also", "art", "hypothesis", "basins", "used", "sutskever", "matrix", "msgd", "behaviour", "train", "attraction", "crossing", "given", "jacobian", "bifurcation", "tanh", "value", "components", "proposed", "rnn", "using", "though", "test", "pathological", "asymptotic", "therefore", "curvature", "figure", "information", "maps", "derivative", "practice", "language", "note", "deal", "schmidhuber", "single", "models", "case", "matrices", "diag", "address", "values", "learn", "means", "short"], "authors": "Razvan Pascanu; Tomas Mikolov; Yoshua Bengio", "thumbnail_path": "thumbnails/On the difficulty of training Recurrent Neural Networks.jpg"}, {"title": "Maxout Networks", "topics": [0.021969468343665831, 0.89033620067387886, 0.021923495355960554, 0.021923604302919245, 0.021923284134018901, 0.021923947189556564], "pdf_url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf", "most_common": ["maxout", "dropout", "training", "model", "set", "error", "units", "networks", "test", "averaging", "best", "mnist", "function", "pooling", "network", "learning", "validation", "deep", "gradient", "linear", "state", "models", "activation", "two", "hidden", "layer", "layers", "neural", "number", "optimization", "large", "approximation", "trained", "hinton", "may", "performance", "many", "using", "methods", "approximate", "convolutional", "rate", "continuous", "well", "use", "dataset", "weights", "applied", "unit", "train", "figure", "max", "art", "table", "conference", "bagging", "obtained", "parameters", "likelihood", "stochastic", "international", "softmax", "inputs", "given", "also", "arbitrarily", "pooled", "fergus", "sgd", "zeiler", "krizhevsky", "new", "method", "value", "bengio", "used", "obtain", "convex", "mask", "results", "small", "prediction", "connected", "positive", "times", "feature", "data", "rates", "proceedings", "geometric", "piecewise", "digits", "srivastava", "mlp", "make", "architectures", "input", "provided", "single", "consists"], "authors": "Ian Goodfellow; David Warde-Farley; Mehdi Mirza; Aaron Courville; Yoshua Bengio", "thumbnail_path": "thumbnails/Maxout Networks.jpg"}, {"title": "Collaborative hyperparameter tuning", "topics": [0.016342840164203239, 0.91828591299869933, 0.016342800463670676, 0.016342871570835787, 0.016342758370744705, 0.01634281643184619], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/bardenet13.pdf", "most_common": ["tuning", "hyperparameter", "optimization", "hyperparameters", "algorithm", "number", "collaborative", "learning", "error", "function", "problems", "section", "figure", "surrogate", "problem", "scot", "methods", "two", "model", "ranking", "log", "average", "set", "similar", "machine", "datasets", "search", "rankings", "validation", "results", "experiment", "point", "default", "space", "also", "smbo", "terms", "used", "dataset", "global", "setup", "experiments", "quality", "random", "new", "conference", "feature", "training", "rank", "given", "target", "note", "common", "method", "criterion", "gaussian", "features", "points", "adaboost", "best", "described", "strategy", "value", "using", "posterior", "separate", "applied", "choice", "sequential", "international", "algorithms", "better", "since", "one", "errors", "means", "kernel", "bayesian", "thus", "user", "grid", "step", "bergstra", "presented", "past", "prior", "descriptors", "propose", "optimal", "research", "strategies", "proceedings", "principal", "knowledge", "automatic", "see", "available", "three", "journal", "use"], "authors": "Rmi Bardenet; Mtys Brendel; Balazs Kegl; Michele Sebag", "thumbnail_path": "thumbnails/Collaborative hyperparameter tuning.jpg"}, {"title": "Learning mid-level representations of objects by harnessing the aperture problem", "topics": [0.014966154310844144, 0.92516937936040178, 0.014966118107820206, 0.014966159933609136, 0.014966066791620511, 0.014966121495704194], "pdf_url": "http://jmlr.org/proceedings/papers/v28/memisevic13.pdf", "most_common": ["features", "learning", "images", "invariant", "aperture", "training", "videos", "model", "learn", "data", "complex", "using", "transformations", "motion", "set", "memisevic", "cell", "figure", "subspace", "models", "pooling", "fourier", "components", "problem", "image", "approach", "objects", "example", "transformation", "object", "video", "work", "show", "use", "two", "one", "also", "input", "frames", "representation", "shows", "energy", "multiple", "layer", "neural", "test", "computation", "subspaces", "trained", "shown", "across", "invariance", "form", "harnessing", "feature", "natural", "rotations", "makes", "representations", "used", "related", "autoencoder", "recognition", "encode", "amounts", "matrix", "translations", "bilinear", "since", "may", "hoyer", "olshausen", "class", "random", "vincent", "vision", "frame", "see", "fleet", "code", "norb", "allows", "cadieu", "hinton", "factored", "still", "rotation", "linear", "top", "extracting", "rao", "note", "phase", "typically", "based", "responses", "noisy", "independent", "well", "possible"], "authors": "Roland Memisevic; Georgios Exarchakis", "thumbnail_path": "thumbnails/Learning mid-level representations of objects by harnessing the aperture problem.jpg"}, {"title": "Approximation properties of DBNs with binary hidden units and real-valued visible units", "topics": [0.023052437816205348, 0.8847380051825543, 0.023052438361400349, 0.023052480115382284, 0.023052294968323551, 0.023052343556134194], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/krause13.pdf", "most_common": ["pmix", "distributions", "binary", "visible", "mixture", "units", "distribution", "hidden", "approximation", "dbns", "family", "properties", "log", "variables", "qmix", "mixtures", "bound", "exp", "gaussian", "let", "mix", "arbitrarily", "thus", "model", "theorem", "rbms", "hinton", "given", "exponential", "conditional", "results", "neural", "every", "compact", "dbn", "exists", "deep", "restricted", "belief", "probability", "roux", "networks", "lemma", "rbm", "follows", "layers", "show", "equation", "one", "variance", "learning", "well", "positive", "following", "furthermore", "bengio", "constant", "computation", "case", "copenhagen", "vectors", "two", "get", "holds", "energy", "number", "parameters", "joint", "corresponding", "layer", "normalization", "components", "strictly", "dvj", "models", "upper", "subset", "approximated", "continuous", "boltzmann", "densities", "written", "however", "salakhutdinov", "independent", "used", "density", "representational", "power", "step", "universal", "second", "machines", "information", "element", "practice", "shown", "formula", "kldivergence", "proceedings"], "authors": "Oswin Krause; Asja Fischer; Tobias Glasmachers; Christian Igel", "thumbnail_path": "thumbnails/Approximation properties of DBNs with binary hidden units and real-valued visible units.jpg"}, {"title": "Better Mixing via Deep Representations", "topics": [0.013797026042799445, 0.93101501113260754, 0.013797032093590589, 0.013797080442549667, 0.013796903103671274, 0.013796947184781484], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/bengio13.pdf", "most_common": ["samples", "learning", "better", "deep", "mixing", "representations", "one", "modes", "would", "deeper", "algorithms", "levels", "input", "bengio", "distribution", "factors", "sampling", "higher", "volume", "space", "data", "representation", "layer", "interpolating", "manifold", "markov", "disentangling", "features", "classes", "also", "hypothesis", "hinton", "good", "used", "model", "mnist", "using", "manifolds", "via", "cae", "raw", "dbn", "rifai", "pages", "layers", "hidden", "mode", "another", "proceedings", "tfd", "experiments", "underlying", "examples", "associated", "chain", "likely", "example", "machine", "lecun", "quality", "top", "obtained", "points", "tend", "models", "depth", "results", "rbm", "may", "hypotheses", "mcmc", "idea", "training", "object", "various", "many", "density", "conference", "near", "report", "noise", "generated", "international", "technical", "two", "correspond", "interpolation", "could", "unlikely", "boltzmann", "vincent", "second", "lower", "mix", "image", "nearest", "whereas", "variation", "faster", "neighbors"], "authors": "Yoshua Bengio; Gregoire Mesnil; Yann Dauphin; Salah Rifai", "thumbnail_path": "thumbnails/Better Mixing via Deep Representations.jpg"}, {"title": "Fast dropout training", "topics": [0.023002583632087008, 0.88498690316905493, 0.023002652434715814, 0.02300264506037723, 0.023002623612972485, 0.023002592090792553], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wang13a.pdf", "most_common": ["dropout", "training", "fast", "neural", "gaussian", "time", "approximation", "using", "objective", "real", "log", "data", "hidden", "loss", "function", "unit", "random", "variance", "sampling", "input", "noise", "test", "table", "gradient", "features", "networks", "regression", "samples", "validation", "error", "proceedings", "used", "trained", "let", "also", "logistic", "manning", "see", "learning", "respect", "datasets", "variable", "results", "errors", "hinton", "train", "wang", "figure", "feature", "still", "shown", "network", "normal", "methods", "computed", "approach", "plain", "units", "without", "output", "approximate", "applied", "exact", "method", "instead", "directly", "inputs", "linear", "one", "performance", "show", "expectation", "distribution", "taking", "case", "mnist", "less", "dimensions", "much", "faster", "small", "maxout", "sgd", "integrating", "regularization", "may", "number", "softmax", "mean", "idea", "sentiment", "since", "performs", "times", "rate", "empirically", "set", "label", "make", "several"], "authors": "Sida Wang; Christopher Manning", "thumbnail_path": "thumbnails/Fast dropout training.jpg"}, {"title": "Feature Selection in High-Dimensional Classification", "topics": [0.015992359750977538, 0.9200382248182063, 0.015992345361257116, 0.015992385183297202, 0.015992379981565222, 0.015992304904696619], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kolar13.pdf", "most_common": ["problem", "log", "sample", "set", "theorem", "size", "sign", "selection", "road", "discriminant", "optimization", "analysis", "solution", "conditions", "sparsity", "variable", "matrix", "lemma", "linear", "distance", "hamming", "let", "min", "constant", "results", "vector", "scaled", "section", "feature", "result", "procedure", "regime", "estimator", "scaling", "recover", "denote", "given", "equal", "consistency", "version", "following", "proof", "high", "sharp", "parameter", "support", "subplot", "corresponds", "independent", "three", "fan", "sublinear", "paper", "show", "estimation", "dimensional", "characterize", "power", "fractional", "second", "theoretical", "least", "observe", "simulation", "oracle", "risk", "condition", "behavior", "two", "particular", "figure", "information", "max", "provide", "correlation", "kkt", "denotes", "probability", "class", "covariance", "used", "identity", "lower", "components", "sparse", "provides", "toeplitz", "assume", "consider", "multivariate", "next", "cai", "recovery", "recovers", "mai", "data", "characterizes", "shows", "population", "liu"], "authors": "Mladen Kolar; Han Liu", "thumbnail_path": "thumbnails/Feature Selection in High-Dimensional Classification.jpg"}, {"title": "Markov Network Estimation From Multi-attribute Data", "topics": [0.016723674484743666, 0.91638156043760866, 0.016723766591024408, 0.016723727056467914, 0.016723624066675935, 0.016723647363479425], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kolar13a.pdf", "most_common": ["graph", "matrix", "distance", "estimation", "hamming", "nodes", "procedure", "network", "covariance", "data", "precision", "partial", "canonical", "sample", "log", "chain", "markov", "blocks", "results", "nearest", "correlation", "estimate", "graphical", "neighbor", "block", "estimating", "set", "based", "method", "given", "one", "random", "model", "using", "following", "gaussian", "size", "number", "selection", "conditions", "problem", "attributes", "node", "max", "diagonal", "nodal", "networks", "however", "independent", "update", "glasso", "multivariate", "two", "attribute", "also", "optimization", "chiquet", "kolar", "sparse", "guo", "let", "obtained", "vectors", "gene", "penalized", "likelihood", "variables", "graphs", "penalty", "descent", "yuan", "structure", "assume", "inverse", "vector", "consistent", "current", "theoretical", "figure", "provide", "paper", "university", "note", "objective", "multiple", "learning", "corresponding", "proposed", "step", "methods", "single", "models", "follow", "estimates", "zero", "new", "usa", "lemma", "known", "example"], "authors": "Mladen Kolar; Han Liu; Eric Xing", "thumbnail_path": "thumbnails/Markov Network Estimation From Multi-attribute Data.jpg"}, {"title": "Exact Rule Learning via Boolean Compressed Sensing", "topics": [0.018135016380425924, 0.90932466805414103, 0.018134976246480247, 0.018135117768064094, 0.018134830837161157, 0.018135390713727481], "pdf_url": "http://jmlr.org/proceedings/papers/v28/malioutov13.pdf", "most_common": ["rule", "learning", "boolean", "set", "rules", "problem", "compressed", "data", "group", "decision", "sets", "sensing", "testing", "accuracy", "via", "approach", "exact", "using", "sparse", "matrix", "training", "features", "recovery", "one", "also", "section", "individual", "columns", "optimization", "proposed", "samples", "algorithm", "combinatorial", "solution", "covering", "results", "learned", "relaxation", "clauses", "boosting", "binary", "interpretability", "signal", "interpretable", "conjunctive", "use", "example", "better", "approaches", "number", "lists", "single", "work", "malyutov", "conditions", "error", "consider", "linear", "apply", "learn", "thresholds", "analytics", "however", "malioutov", "property", "petal", "heuristic", "possible", "nonzero", "vector", "second", "feature", "paper", "since", "programming", "probability", "clause", "cohen", "min", "objective", "continuous", "show", "based", "best", "terms", "two", "simple", "subjects", "tests", "would", "ixj", "small", "learner", "satisfy", "table", "known", "machine", "may", "recover", "note"], "authors": "Dmitry Malioutov; Kush Varshney", "thumbnail_path": "thumbnails/Exact Rule Learning via Boolean Compressed Sensing.jpg"}, {"title": "Sparse Recovery under Linear Transformation", "topics": [0.014810755026542914, 0.92594626775648414, 0.014810743694429805, 0.014810778706245408, 0.014810727884506072, 0.014810726931791814], "pdf_url": "http://jmlr.org/proceedings/papers/v28/liu13.pdf", "most_common": ["number", "condition", "log", "case", "matrix", "random", "error", "lasso", "sparse", "estimate", "one", "probability", "signal", "bounded", "recovery", "problem", "gaussian", "min", "linear", "fused", "analysis", "consider", "high", "measurement", "transformation", "two", "following", "noisy", "bound", "true", "noiseless", "let", "given", "entries", "consistent", "verify", "paper", "special", "assumption", "section", "consistency", "guaranteed", "constant", "assume", "results", "upper", "term", "statistics", "converges", "model", "theorem", "using", "sparsity", "graph", "theoretical", "cases", "since", "least", "recover", "result", "measurements", "existing", "total", "tao", "large", "relative", "set", "see", "learning", "general", "value", "property", "formulation", "zhang", "vector", "max", "ieee", "theory", "recovered", "second", "note", "edge", "annals", "numerical", "use", "journal", "norm", "solution", "zero", "larger", "work", "information", "machine", "main", "free", "standard", "tibshirani", "part", "transactions", "considered"], "authors": "Ji Liu; Lei Yuan; Jieping Ye", "thumbnail_path": "thumbnails/Sparse Recovery under Linear Transformation.jpg"}, {"title": "Noisy and Missing Data Regression: Distribution-Oblivious Support Recovery", "topics": [0.015341010664386182, 0.92329508099831548, 0.01534098268162442, 0.015341034612804165, 0.015340936907267545, 0.015340954135602224], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/chen13d.pdf", "most_common": ["support", "noise", "algorithm", "recovery", "missing", "results", "theorem", "data", "wainwright", "knowledge", "loh", "performance", "omp", "error", "bounds", "show", "regression", "covariance", "rosenbaum", "tsybakov", "noisy", "consider", "two", "work", "standard", "case", "use", "log", "provide", "independent", "model", "method", "additive", "proof", "algorithms", "selector", "covariate", "columns", "obtain", "sparse", "even", "information", "matrix", "guarantees", "matching", "setting", "parameter", "problem", "using", "methods", "ieee", "one", "require", "note", "set", "seems", "minimax", "inner", "simulations", "theory", "known", "following", "figure", "gaussian", "covariates", "estimate", "probability", "improved", "lower", "moreover", "dantzig", "zit", "estimator", "bound", "correlated", "assume", "orthogonal", "design", "particular", "product", "condition", "also", "simple", "analysis", "without", "lasso", "either", "let", "pursuit", "via", "control", "better", "good", "gradient", "projected", "shows", "greedy", "seem", "grad", "estimation"], "authors": "Yudong Chen; Constantine Caramanis", "thumbnail_path": "thumbnails/Noisy and Missing Data Regression: Distribution-Oblivious Support Recovery.jpg"}, {"title": "Learning Policies for Contextual Submodular Prediction", "topics": [0.014533004566814245, 0.92731851593463899, 0.0145329749537144, 0.014533067998546543, 0.014549388311934478, 0.014533048234351474], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ross13b.pdf", "most_common": ["list", "learning", "submodular", "online", "policies", "scp", "loss", "features", "policy", "contextual", "algorithm", "performance", "prediction", "using", "training", "item", "distribution", "optimization", "items", "approach", "use", "set", "state", "problem", "learner", "let", "weighted", "reduction", "sequence", "construct", "best", "guarantees", "dey", "data", "predict", "greedy", "conseqopt", "lists", "function", "convex", "denote", "update", "cti", "work", "example", "one", "lin", "user", "also", "setting", "regret", "streeter", "guestrin", "good", "yue", "min", "expected", "thus", "regression", "document", "reward", "examples", "functions", "consider", "golovin", "goal", "may", "value", "probability", "directly", "class", "result", "clairvoyant", "initial", "single", "test", "section", "bilmes", "agnostic", "learn", "vti", "linear", "bagnell", "length", "multiple", "rouge", "maximize", "trajectory", "case", "wti", "trajectories", "position", "via", "often", "submodularity", "problems", "joachims", "taskar", "new", "pick"], "authors": "Stephane Ross; Jiaji Zhou; Yisong Yue; Debadeepta Dey; Drew Bagnell", "thumbnail_path": "thumbnails/Learning Policies for Contextual Submodular Prediction.jpg"}, {"title": "Learning an Internal Dynamics Model from Control Demonstration", "topics": [0.023051759052413676, 0.40854769036614952, 0.023051641934264368, 0.023051850382102165, 0.49924556417466825, 0.023051494090402001], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/golub13.pdf", "most_common": ["internal", "model", "cursor", "control", "plant", "state", "dynamics", "bmi", "ime", "feedback", "subject", "timestep", "actual", "learning", "estimates", "may", "target", "position", "cost", "neural", "estimate", "current", "data", "aiming", "function", "trial", "delay", "parameters", "sensory", "latent", "motor", "estimation", "visual", "task", "demonstration", "true", "problem", "models", "section", "states", "framework", "angular", "drive", "across", "graphical", "work", "training", "given", "trajectory", "straight", "error", "goals", "likelihood", "machine", "optimal", "abbeel", "trajectories", "variables", "probabilistic", "international", "activity", "commands", "recorded", "algorithm", "inverse", "errors", "figure", "belief", "system", "note", "knowledge", "available", "due", "timesteps", "seek", "input", "predictions", "form", "line", "time", "applied", "demonstrations", "along", "use", "would", "mismatch", "known", "schwartz", "previously", "extract", "red", "toward", "access", "black", "observed", "see", "points", "movements", "signals", "using"], "authors": "Matthew Golub; Steven Chase; Byron Yu", "thumbnail_path": "thumbnails/Learning an Internal Dynamics Model from Control Demonstration.jpg"}, {"title": "Safe Policy Iteration", "topics": [0.018490868610967773, 0.90754595286533279, 0.018490812433643186, 0.018490906518041111, 0.018490699499409374, 0.018490760072605885], "pdf_url": "http://jmlr.org/proceedings/papers/v28/pirotta13.pdf", "most_common": ["policy", "state", "iteration", "improvement", "algorithms", "bound", "policies", "two", "value", "following", "one", "function", "uspi", "mspi", "safe", "cpi", "greedy", "performance", "iterations", "amspi", "kakade", "algorithm", "auspi", "states", "advantage", "number", "approximate", "corollary", "theorem", "distribution", "consider", "values", "optimal", "since", "figure", "matrix", "using", "starting", "set", "case", "step", "chain", "may", "paper", "target", "proposed", "approximation", "current", "spi", "improving", "approaches", "new", "taking", "section", "derivative", "langford", "transition", "given", "bounds", "action", "lower", "stationary", "acpi", "api", "approximated", "maximizes", "gradient", "estimate", "size", "parr", "future", "proceedings", "lemma", "factor", "approach", "expected", "larger", "guaranteed", "blackjack", "follows", "convex", "discount", "initial", "whose", "worse", "version", "use", "better", "return", "domain", "space", "card", "considered", "problem", "perform", "discounted", "model", "reward", "learning", "possible"], "authors": "Matteo Pirotta; Marcello Restelli; Alessio Pecorino; Daniele Calandriello", "thumbnail_path": "thumbnails/Safe Policy Iteration.jpg"}, {"title": "Temporal Difference Methods for the Variance of the Reward To Go", "topics": [0.014299190079142323, 0.92850413510437191, 0.014299167933688128, 0.014299216469746415, 0.014299138526622762, 0.014299151886428494], "pdf_url": "http://jmlr.org/proceedings/papers/v28/tamar13.pdf", "most_common": ["variance", "may", "state", "approximation", "equation", "policy", "let", "function", "reward", "algorithm", "bertsekas", "lstd", "denote", "proposition", "solution", "projected", "evaluation", "methods", "linear", "point", "learning", "following", "assumption", "using", "norm", "second", "matrix", "vector", "value", "algorithms", "space", "standard", "show", "based", "exists", "trajectories", "convergence", "temporal", "lemma", "reinforcement", "barto", "large", "mdp", "also", "sutton", "respect", "thus", "guarantees", "unique", "decision", "deviation", "consider", "stochastic", "section", "onto", "features", "given", "result", "approach", "estimation", "moment", "projection", "obtained", "positive", "known", "process", "assumptions", "propose", "framework", "inequality", "weighted", "estimate", "probability", "continuous", "terminal", "mannor", "theorem", "step", "approximate", "distribution", "markov", "version", "estimates", "even", "method", "equations", "domains", "next", "therefore", "criteria", "appendix", "states", "proof", "control", "figure", "machine", "tsitsiklis", "mapping", "used", "denotes"], "authors": "Aviv Tamar; Dotan Di Castro; Shie Mannor", "thumbnail_path": "thumbnails/Temporal Difference Methods for the Variance of the Reward To Go.jpg"}, {"title": "Value Iteration with incremental representation learning for continuous POMDPs", "topics": [0.014963581044196069, 0.9251820797182212, 0.014963683054237146, 0.014963623592355476, 0.014963454697865752, 0.01496357789312449], "pdf_url": "http://jmlr.org/proceedings/papers/v28/brechtel13.pdf", "most_common": ["value", "continuous", "representation", "belief", "discrete", "space", "backup", "iteration", "state", "learning", "bound", "pomdps", "beliefs", "problem", "pomdp", "function", "every", "solving", "lower", "upper", "optimal", "using", "decision", "thus", "policy", "samples", "results", "presented", "planning", "process", "solver", "implementation", "porta", "observations", "problems", "algorithm", "represent", "concept", "states", "incremental", "observation", "set", "obstacle", "case", "must", "poupart", "particles", "approaches", "also", "new", "solve", "step", "idea", "intelligence", "time", "linear", "even", "represented", "agent", "end", "corridor", "number", "tree", "used", "sparse", "operator", "bounds", "functions", "monte", "approximation", "evaluated", "carlo", "values", "machine", "robot", "research", "smc", "one", "need", "expectation", "observable", "according", "systems", "procedure", "reward", "intersection", "arbitrary", "journal", "basis", "approximate", "partially", "general", "novel", "second", "use", "next", "therefore", "known", "information", "shows"], "authors": "Sebastian Brechtel; Tobias Gindele; R diger Dillmann", "thumbnail_path": "thumbnails/Value Iteration with incremental representation learning for continuous POMDPs.jpg"}, {"title": "The Sample-Complexity of General Reinforcement Learning", "topics": [0.018505543623761781, 0.90747175956943338, 0.018505542763209676, 0.018505602842280408, 0.018505808756988783, 0.018505742444325859], "pdf_url": "http://jmlr.org/proceedings/papers/v28/lattimore13.pdf", "most_common": ["exploration", "learning", "phase", "environments", "environment", "merl", "bound", "emax", "lemma", "let", "number", "bounds", "reinforcement", "general", "since", "policy", "phases", "set", "gmax", "algorithm", "class", "case", "probability", "hutter", "optimal", "log", "true", "history", "model", "failure", "lower", "theorem", "classes", "proper", "follows", "start", "therefore", "high", "show", "mdps", "proof", "given", "also", "exists", "lattimore", "union", "upper", "work", "proceedings", "conference", "value", "used", "exploiting", "statistics", "results", "international", "known", "rather", "machine", "one", "respect", "sequence", "time", "compact", "finally", "martingale", "regret", "end", "return", "least", "nearly", "state", "policies", "discounted", "reward", "either", "function", "apply", "probabilities", "values", "example", "write", "complexity", "algorithms", "large", "see", "close", "would", "expected", "without", "strehl", "arbitrary", "within", "samplecomplexity", "problem", "maximum", "bandits", "never", "explore", "logarithmic"], "authors": "Tor Lattimore; Marcus Hutter; Peter Sunehag", "thumbnail_path": "thumbnails/The Sample-Complexity of General Reinforcement Learning.jpg"}, {"title": "Online Feature Selection for Model-based Reinforcement Learning", "topics": [0.014727551866453609, 0.92636231638504685, 0.014727522617970341, 0.014727582823112272, 0.014727523153192489, 0.014727503154224641], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/nguyen13.pdf", "most_common": ["learning", "state", "transition", "features", "feature", "model", "online", "lorerl", "regression", "optimal", "action", "logistic", "selection", "reinforcement", "frmax", "reward", "function", "factored", "also", "method", "multinomial", "however", "dynamics", "proceedings", "fepsg", "time", "environment", "learn", "states", "algorithm", "may", "policy", "small", "figure", "dbn", "data", "mdp", "based", "relevant", "conference", "structure", "agent", "machine", "matrix", "space", "rmax", "robot", "average", "exploration", "let", "actions", "accumulated", "parameter", "cmdp", "world", "models", "large", "regret", "binary", "vector", "random", "using", "stone", "episodes", "still", "group", "number", "structures", "mdagl", "set", "irrelevant", "value", "near", "manually", "used", "task", "sparse", "four", "international", "work", "table", "information", "regularization", "framework", "since", "probability", "without", "knowledge", "parameters", "experiments", "capture", "changes", "lasso", "often", "regularized", "predicting", "methods", "blorerl", "michael", "selected"], "authors": "Trung Nguyen; Zhuoru Li; Tomi Silander; Tze Yun Leong", "thumbnail_path": "thumbnails/Online Feature Selection for Model-based Reinforcement Learning.jpg"}, {"title": "Bayesian Learning of Recursively Factored Environments", "topics": [0.015745079398958264, 0.92127483953121836, 0.015745045347713187, 0.015745087173413271, 0.015745010805849256, 0.015744937742847891], "pdf_url": "http://jmlr.org/proceedings/papers/v28/bellemare13.pdf", "most_common": ["model", "environment", "learning", "space", "recursively", "factored", "factorization", "reinforcement", "set", "factorizations", "bayesian", "observation", "models", "decomposable", "veness", "atari", "qtf", "used", "given", "dim", "conference", "using", "nesting", "prior", "number", "best", "averaging", "possible", "time", "equation", "depth", "example", "base", "spaces", "intelligence", "log", "bellemare", "tree", "class", "patch", "environments", "image", "large", "section", "percept", "information", "recursive", "silver", "size", "factor", "algorithm", "joel", "cts", "domains", "notation", "many", "context", "denote", "hutter", "factors", "patches", "technique", "string", "larger", "product", "introduce", "denoted", "one", "probabilistic", "techniques", "case", "action", "also", "game", "loss", "describe", "whose", "international", "allows", "two", "particular", "weighting", "machine", "algorithms", "paper", "bowling", "performance", "frame", "approach", "games", "general", "neural", "processing", "within", "frames", "corresponding", "results", "planning", "sequential", "logarithmic"], "authors": "Marc Bellemare; Joel Veness; Michael Bowling", "thumbnail_path": "thumbnails/Bayesian Learning of Recursively Factored Environments.jpg"}, {"title": "Copy or Coincidence? A Model for Detecting Social Influence and Duplication Events", "topics": [0.014985177811212648, 0.92507425681266642, 0.01498515984624141, 0.014985241129740326, 0.014985038576885613, 0.01498512582325367], "pdf_url": "http://jmlr.org/proceedings/papers/v28/friedland13.pdf", "most_common": ["pairs", "data", "model", "cij", "number", "social", "positive", "one", "pair", "performance", "section", "similarity", "points", "score", "ratio", "using", "likelihood", "task", "dij", "distance", "set", "sets", "distributions", "auc", "twins", "method", "inference", "figure", "negative", "generative", "mij", "function", "true", "events", "detecting", "also", "two", "distribution", "would", "generate", "copy", "normal", "duplication", "entities", "point", "coincidence", "increases", "parameters", "values", "process", "parameter", "measure", "since", "could", "mining", "rarity", "detection", "almost", "measures", "form", "synthetic", "shows", "phone", "information", "ranking", "experiments", "baseline", "national", "estimate", "use", "science", "work", "links", "may", "lines", "paper", "matches", "always", "singleton", "variables", "instances", "given", "individual", "linked", "real", "know", "methods", "similar", "generated", "jensen", "turns", "large", "small", "contains", "entity", "ieee", "list", "network", "probability", "mixture"], "authors": "Lisa Friedland; David Jensen; Michael Lavine", "thumbnail_path": "thumbnails/Copy or Coincidence? A Model for Detecting Social Influence and Duplication Events.jpg"}, {"title": "Mixture of Mutually Exciting Processes for Viral Diffusion", "topics": [0.017368436062946965, 0.91315799570322687, 0.017368395402736755, 0.017368502308209351, 0.017368238010719784, 0.017368432512160234], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/yang13a.pdf", "most_common": ["network", "meme", "model", "inference", "viral", "memes", "events", "mixture", "algorithm", "process", "one", "models", "event", "time", "exciting", "mutually", "hawkes", "social", "two", "processes", "set", "point", "variational", "figure", "data", "hidden", "content", "log", "node", "rate", "use", "number", "note", "also", "modeling", "tracking", "fast", "nodes", "future", "based", "infected", "prior", "example", "inferred", "intensity", "snowsill", "using", "netrate", "simultaneously", "latent", "work", "history", "infectivity", "algorithms", "evolution", "probabilistic", "mhps", "mhp", "twitter", "cascades", "single", "structure", "matrix", "results", "tasks", "mmhp", "another", "shows", "contents", "multiple", "experiments", "kernel", "learning", "sparsity", "assuming", "comparison", "sequence", "function", "true", "existing", "large", "current", "causality", "parameters", "usually", "known", "rmse", "challenges", "used", "trends", "variables", "given", "elbo", "blogosphere", "involving", "terms", "genetic", "dag", "independent", "identify"], "authors": "Shuang-Hong Yang; Hongyuan Zha", "thumbnail_path": "thumbnails/Mixture of Mutually Exciting Processes for Viral Diffusion.jpg"}, {"title": "Dynamic Probabilistic Models for Latent Feature Propagation in Social Networks", "topics": [0.016964945689418736, 0.91517545493992891, 0.016964862811967615, 0.016964928469678724, 0.016964759335711992, 0.016965048753293851], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/heaukulani13.pdf", "most_common": ["latent", "feature", "social", "network", "model", "time", "hik", "data", "propagation", "networks", "features", "dataset", "dynamic", "markov", "nips", "lfp", "drift", "models", "see", "lfrm", "state", "parameters", "also", "distribution", "probability", "given", "using", "actor", "space", "variables", "structure", "current", "two", "following", "representations", "baseline", "one", "relational", "observed", "infocom", "use", "matrix", "observations", "set", "future", "samples", "link", "ghahramani", "results", "auc", "particular", "work", "parameter", "transition", "however", "previous", "methods", "prediction", "states", "number", "section", "statistically", "forecasting", "test", "method", "inference", "order", "hidden", "bernoulli", "training", "authors", "point", "snijders", "xing", "based", "foulds", "datasets", "chain", "miller", "prior", "sample", "example", "links", "information", "used", "mcmc", "interests", "probabilistic", "modelling", "hmm", "perform", "edges", "sequence", "year", "stochastic", "large", "interactions", "unobserved", "figure", "next"], "authors": "Creighton Heaukulani; Ghahramani Zoubin", "thumbnail_path": "thumbnails/Dynamic Probabilistic Models for Latent Feature Propagation in Social Networks.jpg"}, {"title": "Modeling Information Propagation with Survival Theory", "topics": [0.017913894786537161, 0.91041391570932695, 0.017930893602191317, 0.017913836638248425, 0.017913720009731023, 0.017913739253965066], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gomez-rodriguez13.pdf", "most_common": ["node", "cascade", "model", "nodes", "additive", "network", "information", "infected", "multiplicative", "time", "hazard", "infection", "models", "set", "propagation", "risk", "cascades", "test", "inference", "using", "likelihood", "consider", "networks", "survival", "function", "rate", "edge", "parameters", "times", "also", "contagion", "previously", "one", "leskovec", "observation", "proceedings", "sets", "infer", "theory", "accuracy", "modeling", "conference", "window", "given", "shaping", "methods", "mse", "therefore", "increase", "number", "size", "ccdf", "international", "independent", "edges", "duration", "two", "general", "optimal", "data", "performance", "several", "underlying", "memes", "log", "however", "learning", "acm", "vector", "decrease", "negative", "wang", "process", "parameter", "term", "used", "show", "observed", "real", "evaluate", "compute", "problem", "functions", "generated", "synthetic", "convexity", "solution", "knowledge", "apply", "training", "particular", "example", "machine", "synthetically", "since", "first", "mining", "continuous", "random", "sites"], "authors": "Manuel Gomez-Rodriguez; Jure Leskovec; Bernhard Schlkopf", "thumbnail_path": "thumbnails/Modeling Information Propagation with Survival Theory.jpg"}, {"title": "Learning Triggering Kernels for Multi-dimensional Hawkes Processes", "topics": [0.020548459819515412, 0.89725780947629385, 0.020548427140981328, 0.020548555440252567, 0.020548333861476132, 0.020548414261480553], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhou13.pdf", "most_common": ["kernels", "triggering", "kernel", "data", "hawkes", "base", "performance", "processes", "mmel", "figure", "learning", "true", "estimated", "loglik", "proposed", "events", "equation", "number", "problem", "method", "respect", "function", "parameters", "process", "set", "training", "algorithm", "follows", "work", "used", "measured", "smoothing", "nonparametric", "estimate", "dimensional", "exponential", "model", "samples", "two", "log", "time", "synthetic", "plot", "use", "estmated", "observed", "observe", "journal", "test", "dynamics", "particular", "better", "related", "linear", "quite", "intensity", "show", "thus", "real", "ijd", "moreover", "general", "models", "section", "optimizing", "following", "machine", "parameter", "paper", "propose", "splines", "constraints", "generate", "another", "also", "auuc", "based", "experiments", "case", "value", "optimization", "sets", "dimension", "world", "point", "functional", "distribution", "consider", "social", "positive", "values", "information", "end", "temporal", "event", "large", "relatively", "lewis", "estimation", "trigger"], "authors": "Ke Zhou; Le Song; Hongyuan Zha", "thumbnail_path": "thumbnails/Learning Triggering Kernels for Multi-dimensional Hawkes Processes.jpg"}, {"title": "Modeling Temporal Evolution and Multiscale Structure in Networks", "topics": [0.014699450857117932, 0.9265029150078552, 0.014699423359219532, 0.014699500085446276, 0.01469928424682934, 0.014699426443531706], "pdf_url": "http://jmlr.org/proceedings/papers/v28/herlau13.pdf", "most_common": ["temporal", "model", "vertices", "networks", "network", "tree", "structure", "hierarchical", "epoch", "vertex", "models", "change", "giant", "two", "using", "multiscale", "relational", "evolution", "epochs", "gibbs", "states", "irm", "modeling", "time", "democrats", "republicans", "fragmentation", "schmidt", "leafs", "set", "hierarchies", "consider", "thrm", "number", "see", "organization", "nips", "changes", "hrm", "complex", "shown", "issn", "considered", "information", "senators", "hierarchy", "jit", "distributed", "present", "right", "prior", "data", "onto", "voting", "trees", "new", "according", "modelling", "moves", "edge", "proposed", "senate", "results", "matrix", "construction", "enron", "binary", "may", "systems", "one", "given", "beta", "aij", "edges", "subtree", "unique", "methods", "bottom", "properties", "mccullagh", "single", "dynamic", "roy", "auc", "indicating", "let", "social", "type", "science", "process", "processes", "level", "probability", "illustrate", "top", "observations", "inferred", "multifurcating", "corresponds", "community"], "authors": "Tue Herlau; Morten Mrup; Mikkel Schmidt", "thumbnail_path": "thumbnails/Modeling Temporal Evolution and Multiscale Structure in Networks.jpg"}, {"title": "Scalable Optimization of Neighbor Embedding for Visualization", "topics": [0.015882700659490913, 0.92058659451140235, 0.015882746187324208, 0.015882765025090645, 0.015882597399423246, 0.015882596217268702], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/yang13b.pdf", "most_common": ["data", "methods", "embedding", "neighbor", "points", "visualization", "approximated", "fast", "optimization", "approximation", "learning", "cost", "large", "exact", "gradient", "objective", "method", "mnist", "using", "subset", "qij", "time", "computation", "information", "scalable", "sets", "pij", "hinton", "tree", "computed", "point", "classes", "function", "even", "figure", "machine", "algorithms", "new", "approach", "algorithm", "small", "hours", "sne", "size", "one", "group", "computational", "also", "der", "relative", "conference", "van", "maaten", "datasets", "compared", "original", "results", "stochastic", "bounding", "shows", "international", "box", "larger", "example", "complexity", "experiments", "systems", "uci", "mean", "matrix", "space", "linear", "timit", "neighborhood", "quality", "set", "whole", "nerv", "nldr", "several", "well", "samples", "output", "node", "images", "log", "approximate", "structure", "technique", "subsampling", "smaller", "nonlinear", "contains", "two", "covertype", "shown", "dataset", "divergence", "another", "pairwise"], "authors": "Zhirong Yang; Jaakko Peltonen; Samuel Kaski", "thumbnail_path": "thumbnails/Scalable Optimization of Neighbor Embedding for Visualization.jpg"}, {"title": "Learning the Structure of Sum-Product Networks", "topics": [0.017948899327098162, 0.52582129664353772, 0.40237875793931627, 0.017949006164813409, 0.017948661050606128, 0.017953378874628442], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gens13.pdf", "most_common": ["learning", "variables", "spn", "spns", "structure", "networks", "number", "instances", "query", "algorithm", "learnspn", "set", "learned", "evidence", "inference", "sum", "markov", "partition", "domingos", "graphical", "datasets", "models", "subsets", "test", "function", "distribution", "cll", "node", "variable", "time", "likelihood", "also", "used", "univariate", "using", "nodes", "network", "probability", "returns", "instance", "independent", "model", "pll", "product", "independence", "winmine", "davis", "computed", "bayesian", "cluster", "split", "lowd", "weights", "recursive", "xij", "return", "similar", "distributions", "wij", "clusters", "weight", "linear", "comparable", "table", "step", "fraction", "poon", "advantage", "splitting", "large", "let", "normalized", "root", "sij", "data", "found", "since", "mixture", "tractable", "many", "sampling", "corresponding", "case", "splits", "value", "della", "proposed", "leaf", "pietra", "dataset", "conditional", "deep", "compared", "results", "webkb", "gens", "use", "dna", "two", "values"], "authors": "Robert Gens; Domingos Pedro", "thumbnail_path": "thumbnails/Learning the Structure of Sum-Product Networks.jpg"}, {"title": "Deep learning with COTS HPC systems", "topics": [0.015277267677304892, 0.92361473284260565, 0.015276970183485438, 0.015277080306497421, 0.015276983592287855, 0.01527696539781888], "pdf_url": "http://jmlr.org/proceedings/papers/v28/coates13.pdf", "most_common": ["gpu", "gpus", "learning", "deep", "network", "neural", "systems", "large", "networks", "neurons", "figure", "use", "training", "using", "billion", "code", "size", "system", "train", "layer", "input", "computation", "parameters", "many", "hpc", "array", "receptive", "computing", "found", "krizhevsky", "implementation", "neuron", "cluster", "images", "number", "gradient", "cots", "much", "responses", "used", "local", "image", "compute", "larger", "pooling", "parameter", "also", "distributed", "results", "layers", "international", "blocks", "shown", "though", "optimized", "set", "infrastructure", "conference", "make", "dean", "scale", "processing", "communication", "single", "mpi", "contrast", "must", "one", "best", "lecun", "several", "output", "recognition", "block", "software", "trained", "memory", "information", "machine", "inputs", "paper", "window", "linear", "features", "normalization", "approach", "communications", "sparse", "coates", "matrix", "section", "obtained", "hinton", "convolutional", "scaling", "need", "able", "performance", "nvidia", "unsupervised"], "authors": "Adam Coates; Brody Huval; Tao Wang; David Wu; Bryan Catanzaro; Ng Andrew", "thumbnail_path": "thumbnails/Deep learning with COTS HPC systems.jpg"}, {"title": "Learning and Selecting Features Jointly with Point-wise Gated Boltzmann Machines", "topics": [0.017260190289416558, 0.91369920335890342, 0.017260163888803245, 0.01726022358712374, 0.017260138219606362, 0.017260080656146651], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/sohn13.pdf", "most_common": ["units", "pgbm", "hidden", "features", "learning", "feature", "visible", "model", "switch", "unit", "using", "data", "object", "boltzmann", "selection", "rbm", "supervised", "training", "irrelevant", "patterns", "deep", "two", "raw", "images", "learn", "generative", "used", "gated", "section", "component", "layer", "background", "convolutional", "figure", "group", "bengio", "models", "machines", "machine", "propose", "bounding", "lee", "network", "mixture", "neural", "performance", "jointly", "hinton", "foreground", "class", "larochelle", "cpgdn", "components", "follows", "second", "use", "unsupervised", "corresponding", "unlabeled", "recognition", "selecting", "large", "activations", "representations", "given", "one", "table", "accuracy", "label", "useful", "algorithm", "method", "groups", "imrbm", "sohn", "perform", "complex", "robust", "discriminative", "building", "learned", "train", "example", "may", "dataset", "shown", "shows", "show", "joint", "however", "box", "conditional", "examples", "block", "icml", "also", "inference", "distribution", "caltech", "test"], "authors": "Kihyuk Sohn; Guanyu Zhou; Chansoo Lee; Honglak Lee", "thumbnail_path": "thumbnails/Learning and Selecting Features Jointly with Point-wise Gated Boltzmann Machines.jpg"}, {"title": "Regularization of Neural Networks using DropConnect", "topics": [0.022924697641607119, 0.8853766898349773, 0.022924649319471142, 0.022924739465590933, 0.022924603722951676, 0.022924620015401753], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wan13.pdf", "most_common": ["dropconnect", "dropout", "layer", "network", "training", "feature", "model", "using", "error", "fully", "connected", "networks", "neural", "output", "mask", "input", "function", "images", "extractor", "weight", "rate", "learning", "matrix", "activation", "performance", "parameters", "table", "hinton", "softmax", "gpu", "set", "test", "weights", "regularization", "complexity", "voting", "random", "layers", "data", "train", "size", "lemma", "results", "example", "previous", "loss", "use", "relu", "generalization", "show", "rademacher", "units", "applied", "krizhevsky", "large", "activations", "unit", "memory", "experiments", "implementation", "ciresan", "mnist", "methods", "bound", "initial", "models", "convolutional", "rather", "zeiler", "features", "number", "result", "used", "epochs", "image", "single", "elements", "section", "experiment", "fergus", "inference", "trained", "element", "dataset", "mean", "shows", "randomly", "computer", "described", "tanh", "lecun", "biases", "functions", "consider", "two", "equation", "ieee", "bernoulli", "since", "standard"], "authors": "Li Wan; Matthew Zeiler; Sixin Zhang; Yann Le Cun; Rob Fergus", "thumbnail_path": "thumbnails/Regularization of Neural Networks using DropConnect.jpg"}, {"title": "Thurstonian Boltzmann Machines: Learning from Multiple Inequalities", "topics": [0.014036774628617538, 0.92981641790387826, 0.014036688441627795, 0.014036753620885918, 0.014036671045158431, 0.014036694359831989], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/tran13.pdf", "most_common": ["boltzmann", "tbm", "data", "variables", "gaussian", "hidden", "constraints", "model", "machines", "binary", "one", "learning", "thus", "distribution", "thurstonian", "using", "categories", "rbm", "probit", "ordinal", "evidences", "statistics", "information", "types", "rank", "continuous", "set", "collaborative", "pages", "evidence", "case", "analysis", "models", "section", "salakhutdinov", "machine", "inequality", "used", "point", "samples", "standard", "observed", "see", "underlying", "layer", "per", "survey", "hinton", "particular", "figure", "categorical", "probability", "units", "without", "input", "boxed", "ranking", "processing", "subset", "ordered", "multivariate", "unit", "two", "applications", "truyen", "matrix", "posteriors", "restricted", "given", "need", "proceedings", "inequalities", "however", "simple", "inference", "normal", "due", "chain", "markov", "example", "parameter", "max", "tran", "category", "since", "xil", "countries", "constrained", "min", "multiple", "latent", "learned", "best", "user", "boundaries", "many", "much", "systems", "general", "neural"], "authors": "Truyen Tran; Dinh Phung; Svetha Venkatesh", "thumbnail_path": "thumbnails/Thurstonian Boltzmann Machines: Learning from Multiple Inequalities.jpg"}, {"title": "Iterative Learning and Denoising in Convolutional Neural Associative Memories", "topics": [0.014204086766627088, 0.92897796309411451, 0.014204075248643507, 0.014203895655399354, 0.014205516579221103, 0.014204462655994491], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/karbasi13.pdf", "most_common": ["learning", "algorithm", "neural", "pattern", "patterns", "set", "network", "capacity", "recall", "associative", "error", "cluster", "noise", "one", "phase", "neurons", "degree", "convolutional", "iterative", "number", "graph", "denoising", "work", "ieee", "proposed", "input", "constraint", "vectors", "figure", "constraints", "also", "noisy", "single", "results", "linear", "among", "neuron", "theorem", "memories", "vector", "learn", "algorithms", "correct", "retrieval", "size", "given", "sparsity", "matrix", "orthogonal", "entries", "small", "training", "iteration", "networks", "local", "memorized", "performance", "fraction", "large", "shown", "note", "threshold", "state", "subspace", "dual", "let", "dbns", "redundancy", "weight", "probability", "bipartite", "show", "oja", "case", "exponential", "model", "errors", "section", "kumar", "following", "proof", "order", "clusters", "furthermore", "features", "correction", "able", "new", "considered", "based", "lausanne", "used", "overlapping", "similar", "salavati", "assume", "since", "consider", "nodes", "method"], "authors": "Amin Karbasi; Amir Hesam Salavati; Amin Shokrollahi,", "thumbnail_path": "thumbnails/Iterative Learning and Denoising in Convolutional Neural Associative Memories.jpg"}, {"title": "No more pesky learning rates", "topics": [0.015649438252941492, 0.92175284917646261, 0.015649451006622427, 0.01564947263562862, 0.015649374337934237, 0.015649414590410547], "pdf_url": "http://jmlr.org/proceedings/papers/v28/schaul13.pdf", "most_common": ["learning", "rate", "sgd", "loss", "rates", "gradient", "adaptive", "one", "parameter", "diagonal", "training", "method", "optimal", "hessian", "error", "algorithm", "stochastic", "neural", "parameters", "best", "lecun", "estimates", "table", "samples", "test", "hidden", "performance", "tuning", "using", "quadratic", "update", "global", "pesky", "curvature", "adagrad", "used", "case", "bottou", "almeida", "figure", "machine", "algorithms", "smd", "number", "note", "average", "local", "settings", "set", "problem", "variance", "vsgd", "expected", "value", "amari", "methods", "schedule", "two", "sample", "data", "formula", "small", "given", "need", "mnist", "optimum", "across", "terms", "online", "layer", "see", "supplementary", "network", "time", "layers", "large", "approximation", "reconstruction", "use", "compare", "natural", "better", "denoted", "function", "new", "approach", "changes", "scale", "automatically", "dataset", "approximate", "form", "distribution", "deep", "single", "benchmark", "results", "norm", "every", "updates"], "authors": "Tom Schaul; Sixin Zhang; Yann LeCun", "thumbnail_path": "thumbnails/No more pesky learning rates.jpg"}, {"title": "Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures", "topics": [0.016470429549708478, 0.91764826359817619, 0.016470360173295829, 0.016470344913034722, 0.016470265597159466, 0.016470336168625279], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/bergstra13.pdf", "most_common": ["search", "model", "optimization", "random", "hyperparameter", "tpe", "algorithm", "pinto", "bergstra", "approach", "cox", "used", "vision", "data", "performance", "work", "best", "image", "hyperparameters", "set", "within", "making", "algorithms", "found", "space", "computer", "models", "science", "feature", "many", "learning", "loss", "images", "recognition", "trials", "svm", "test", "machine", "lfw", "features", "one", "class", "components", "function", "pooling", "two", "figure", "null", "error", "parameters", "view", "bayesian", "value", "coates", "spatial", "results", "parameter", "bank", "training", "language", "object", "experiments", "automatic", "lnorm", "expression", "choose", "task", "using", "tuning", "validation", "include", "values", "research", "given", "system", "face", "fbncc", "new", "distribution", "thousand", "neural", "hutter", "carried", "choice", "uniform", "particular", "history", "dihist", "better", "settings", "gaussian", "operation", "approaches", "typically", "distributed", "local", "prior", "patch", "three", "applied"], "authors": "James Bergstra; Daniel Yamins; David Cox", "thumbnail_path": "thumbnails/Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures.jpg"}, {"title": "Learning Heteroscedastic Models by Convex Programming under Group Sparsity", "topics": [0.01446137739094633, 0.92769320496387431, 0.014461365919068502, 0.014461387973670954, 0.014461280843421709, 0.014461382909018067], "pdf_url": "http://jmlr.org/proceedings/papers/v28/dalalyan13.pdf", "most_common": ["scheds", "group", "convex", "one", "lasso", "sparsity", "noise", "functions", "vector", "heteroscedastic", "assumption", "estimation", "procedure", "regression", "linear", "variance", "conditional", "function", "mean", "methods", "log", "programming", "learning", "model", "dantzig", "problem", "risk", "let", "theoretical", "estimating", "set", "theorem", "sparse", "models", "matrix", "case", "time", "large", "method", "scaled", "two", "selector", "new", "tuning", "optimization", "level", "constraints", "may", "result", "well", "also", "estimator", "bounded", "results", "covariates", "zhang", "prediction", "temperatures", "standard", "values", "data", "order", "used", "unknown", "optimal", "point", "proposed", "bounds", "constant", "paris", "every", "even", "use", "additive", "assumptions", "parameter", "propose", "gaussian", "since", "card", "number", "given", "std", "ofo", "interior", "sun", "based", "means", "joint", "terms", "bias", "dimensional", "denote", "ave", "temperature", "using", "condition", "diag", "obtained", "parameters"], "authors": "Arnak Dalalyan; Mohamed Hebiri; Katia Meziani; Joseph Salmon", "thumbnail_path": "thumbnails/Learning Heteroscedastic Models by Convex Programming under Group Sparsity.jpg"}, {"title": "Noisy Sparse Subspace Clustering", "topics": [0.016526839142243246, 0.9173658429062489, 0.016526947807947751, 0.016526848618079751, 0.016526769599258306, 0.016526751926222001], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wang13.pdf", "most_common": ["subspace", "noise", "clustering", "data", "noisy", "ssc", "random", "theorem", "analysis", "subspaces", "sparse", "log", "figure", "property", "matrix", "dual", "model", "problem", "min", "vidal", "detection", "soltanolkotabi", "lasso", "results", "solution", "ieee", "rank", "candes", "remark", "max", "points", "geometric", "let", "inradius", "deterministic", "proof", "magnitude", "lemma", "samples", "range", "algorithm", "even", "guarantee", "number", "relviolation", "dimension", "convex", "bound", "robustness", "requires", "two", "recovery", "machine", "motion", "spectral", "columns", "set", "sep", "see", "point", "margin", "incoherence", "elhamifar", "constant", "case", "projection", "transactions", "holds", "exact", "furthermore", "conditions", "error", "singapore", "robust", "supplementary", "practical", "also", "denote", "uniformly", "consider", "condition", "noiseless", "vector", "version", "increasing", "method", "segmentation", "theoretical", "following", "paper", "perfect", "optimal", "fully", "gaussian", "projected", "note", "face", "trivial", "intelligence", "drawn"], "authors": "Yu-Xiang Wang; Huan Xu", "thumbnail_path": "thumbnails/Noisy Sparse Subspace Clustering.jpg"}, {"title": "One-Bit Compressed Sensing: Provable Support and Vector Recovery", "topics": [0.01739370637142296, 0.91303155093490518, 0.017393694502366688, 0.017393773486808827, 0.017393625852136742, 0.017393648852359427], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gopi13.pdf", "most_common": ["algorithm", "recovery", "support", "log", "using", "sensing", "measurements", "matrix", "measurement", "vector", "compressed", "sign", "recover", "problem", "theorem", "approximate", "uff", "number", "based", "set", "methods", "section", "probability", "note", "plan", "see", "signal", "sparse", "baraniuk", "vershynin", "given", "design", "provable", "algorithms", "also", "compressive", "method", "error", "universal", "existing", "let", "following", "twostage", "supplementary", "sets", "expanders", "results", "matrices", "provide", "material", "denotes", "linear", "standard", "however", "present", "several", "robust", "signals", "output", "two", "supp", "time", "solution", "figure", "complexity", "ieee", "expander", "yes", "input", "constructed", "elements", "large", "vectors", "family", "high", "end", "free", "random", "approach", "union", "well", "underlying", "stage", "next", "parameters", "use", "haupt", "known", "tao", "information", "better", "optimal", "used", "transactions", "richard", "laska", "learning", "larger", "propose", "varying"], "authors": "Sivakant Gopi; Praneeth Netrapalli; Prateek Jain; Aditya Nori", "thumbnail_path": "thumbnails/One-Bit Compressed Sensing: Provable Support and Vector Recovery.jpg"}, {"title": "Smooth Sparse Coding via Marginal Regression for Learning Sparse Representations", "topics": [0.018985579153346744, 0.90507213333622905, 0.018985586071224376, 0.018985656843767979, 0.018985500432213732, 0.018985544163218196], "pdf_url": "http://jmlr.org/proceedings/papers/v28/balasubramanian13.pdf", "most_common": ["sparse", "coding", "dictionary", "smooth", "regression", "learning", "marginal", "data", "using", "standard", "kernel", "approach", "based", "set", "proposed", "step", "codes", "method", "lasso", "error", "sample", "feature", "used", "function", "representations", "accuracy", "local", "theorem", "reconstruction", "update", "algorithm", "similarity", "use", "image", "problem", "one", "see", "corresponds", "samples", "table", "space", "experiments", "optimization", "convergence", "time", "norm", "two", "following", "example", "complexity", "propose", "gradient", "could", "features", "alternative", "recognition", "smoothing", "bounds", "results", "statistical", "matrix", "size", "also", "advantage", "projection", "information", "may", "temporal", "might", "training", "generalization", "min", "respect", "corresponding", "several", "leads", "better", "main", "framework", "term", "related", "given", "rates", "distance", "note", "class", "traditional", "speedup", "covering", "score", "previous", "procedure", "descent", "obtain", "bandwidth", "comparison", "videos", "functions", "test", "vector"], "authors": "Krishnakumar Balasubramanian; Kai Yu; Guy Lebanon", "thumbnail_path": "thumbnails/Smooth Sparse Coding via Marginal Regression for Learning Sparse Representations.jpg"}, {"title": "Sparse projections onto the simplex", "topics": [0.014166391768282606, 0.92916818066688855, 0.014166354337344075, 0.014166402148483031, 0.01416629798620197, 0.014166373092799694], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kyrillidis13.pdf", "most_common": ["approach", "problem", "convex", "algorithm", "sparse", "onto", "solution", "let", "simplex", "true", "since", "projections", "estimated", "rank", "kernel", "measurements", "projection", "figure", "given", "pdf", "means", "matrix", "portfolio", "set", "quantum", "number", "also", "learning", "tomography", "constraints", "density", "support", "vector", "via", "use", "following", "hence", "relative", "using", "constraint", "index", "projector", "recovery", "one", "gradient", "approaches", "solutions", "case", "loss", "parzen", "sparsity", "argmin", "assume", "results", "cardinality", "result", "based", "liu", "euclidean", "optimization", "error", "rip", "function", "supp", "time", "approximation", "proof", "sample", "element", "gaussian", "shows", "greedy", "probability", "gssp", "trace", "estimation", "thus", "minimize", "nonconvex", "obtain", "guarantees", "quadratic", "cevher", "kyrillidis", "consider", "norm", "even", "hyperplane", "order", "eigenvalue", "operator", "restricted", "note", "random", "gshp", "knowledge", "experiments", "argmax", "avg", "descent"], "authors": "Anastasios Kyrillidis; Stephen Becker; Volkan Cevher; Christoph Koch", "thumbnail_path": "thumbnails/Sparse projections onto the simplex.jpg"}, {"title": "Intersecting singularities for multi-structured estimation", "topics": [0.015153435025177681, 0.92423294210475693, 0.015153416404196398, 0.015153460701506841, 0.015153359541551567, 0.01515338622281074], "pdf_url": "http://jmlr.org/proceedings/papers/v28/richard13.pdf", "most_common": ["norm", "rank", "sparse", "trace", "matrix", "estimation", "convex", "matrices", "singularities", "using", "penalty", "linear", "ranksity", "case", "noise", "vec", "two", "intersecting", "regularizers", "span", "log", "optimization", "block", "problem", "algorithm", "following", "new", "function", "index", "singular", "lifting", "algorithms", "supp", "consider", "lifted", "one", "given", "point", "dimension", "orthogonal", "penalties", "chandrasekaran", "penalized", "cases", "min", "points", "set", "see", "value", "learning", "regularizer", "dense", "values", "diag", "component", "objects", "theoretical", "space", "robust", "normal", "sum", "instance", "operator", "results", "level", "respectively", "compressed", "subgradient", "nonsmooth", "least", "observation", "norms", "subspaces", "experiments", "cone", "used", "analysis", "sensing", "sparsity", "inf", "entries", "dim", "unit", "use", "call", "information", "vandergheynst", "machine", "estimating", "structural", "denotes", "onto", "multiple", "bound", "state", "written", "tuning", "numerical", "intersection", "bach"], "authors": "Emile Richard; Francis BACH; Jean-Philippe Vert", "thumbnail_path": "thumbnails/Intersecting singularities for multi-structured estimation.jpg"}, {"title": "Sparse Uncorrelated Linear Discriminant Analysis", "topics": [0.019617741191449711, 0.9019113341819287, 0.019617683000721486, 0.019617919804817717, 0.019617596259427043, 0.019617725561655565], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/zhang13.pdf", "most_common": ["sparse", "data", "lda", "discriminant", "solution", "sulda", "ulda", "class", "problem", "analysis", "linear", "uncorrelated", "optimization", "trace", "solutions", "slda", "orthogonal", "transformation", "minimum", "matrix", "generalized", "plda", "dimension", "sparsity", "rank", "bregman", "results", "number", "space", "scatter", "optimal", "linearized", "features", "extracted", "column", "algorithm", "accelerated", "algorithms", "yin", "journal", "let", "two", "tibshirani", "computed", "characterization", "theorem", "classical", "matrices", "vector", "gene", "statistical", "based", "method", "arg", "using", "section", "selected", "chu", "applications", "machine", "denotes", "training", "table", "accuracy", "set", "learning", "mutually", "compute", "implies", "cai", "max", "solving", "fukunaga", "one", "paper", "satisfying", "however", "huang", "many", "experimental", "thus", "reduced", "hastie", "srbct", "existing", "solved", "international", "test", "following", "feature", "experiments", "jin", "since", "projected", "directly", "classes", "null", "min", "also", "penalty"], "authors": "Xiaowei Zhang; Delin Chu", "thumbnail_path": "thumbnails/Sparse Uncorrelated Linear Discriminant Analysis.jpg"}, {"title": "Estimating Unknown Sparsity in Compressed Sensing", "topics": [0.013595400175224223, 0.93202308814157986, 0.013595387346625082, 0.013595419145544478, 0.013595343710393455, 0.01359536148063285], "pdf_url": "http://jmlr.org/proceedings/papers/v28/lopes13.pdf", "most_common": ["sparsity", "measurements", "estimating", "estimate", "error", "rank", "section", "matrix", "unknown", "recovery", "problem", "value", "parameter", "relative", "signal", "stable", "compressed", "ieee", "also", "vectors", "sensing", "theorem", "bound", "log", "number", "random", "set", "measurement", "theory", "choice", "procedure", "deterministic", "small", "reconstruction", "order", "since", "show", "estimation", "noise", "gaussian", "case", "coordinate", "using", "sparse", "measure", "matrices", "level", "large", "vector", "based", "known", "figure", "transactions", "coordinates", "note", "distribution", "linear", "let", "parameters", "high", "values", "assumptions", "given", "one", "result", "many", "well", "dimension", "left", "signals", "estimator", "function", "depend", "standard", "two", "theoretical", "information", "may", "shows", "computed", "property", "used", "sets", "right", "scale", "additional", "true", "journal", "important", "assume", "interval", "results", "entries", "approximation", "estimated", "following", "obtained", "plotted", "use", "cauchy"], "authors": "Miles Lopes", "thumbnail_path": "thumbnails/Estimating Unknown Sparsity in Compressed Sensing.jpg"}, {"title": "Concurrent Reinforcement Learning from Customer Interaction Sequences", "topics": [0.019217340331870763, 0.90391338786971742, 0.019217290462497927, 0.019217432326528366, 0.019217363567992269, 0.01921718544139326], "pdf_url": "http://jmlr.org/proceedings/papers/v28/silver13.pdf", "most_common": ["customer", "learning", "concurrent", "reinforcement", "interaction", "customers", "interactions", "algorithm", "online", "actions", "time", "updates", "function", "real", "example", "concurrency", "company", "may", "algorithms", "action", "variables", "null", "bandit", "decision", "contextual", "decisions", "one", "email", "given", "sutton", "however", "many", "sequences", "policy", "using", "learn", "history", "data", "response", "observations", "rewards", "applied", "batch", "value", "update", "environment", "sequential", "performance", "interacting", "reward", "sequence", "scenarios", "agent", "work", "occur", "parallel", "internet", "also", "measured", "simulator", "setting", "abe", "prior", "two", "optimal", "event", "note", "pages", "distributed", "conference", "partial", "large", "new", "figure", "high", "times", "framework", "typically", "international", "subsequent", "requests", "used", "levels", "opportunity", "problem", "single", "compared", "requested", "options", "total", "therefore", "feature", "might", "number", "immediate", "observation", "request", "histories", "state", "approach"], "authors": "David Silver; Leonard Newnham; David Barker; Suzanne Weller;Jason McFall", "thumbnail_path": "thumbnails/Concurrent Reinforcement Learning from Customer Interaction Sequences.jpg"}, {"title": "Modelling Sparse Dynamical Systems with Compressed Predictive State Representations", "topics": [0.015755850765995484, 0.92122082210108003, 0.015755833442125704, 0.015755881284057797, 0.015755792768608154, 0.015755819638132905], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/hamilton13.pdf", "most_common": ["cpsr", "algorithm", "tests", "compressed", "learning", "systems", "observation", "model", "error", "tpsr", "large", "prediction", "set", "matrices", "used", "matrix", "state", "dynamical", "models", "space", "probability", "one", "also", "observable", "using", "boots", "projection", "vector", "random", "sparse", "domain", "number", "history", "algorithms", "histories", "thus", "dimension", "psr", "empirical", "domains", "predictive", "however", "results", "estimates", "would", "sample", "observations", "bound", "modelling", "possible", "mol", "psrs", "spectral", "method", "work", "representation", "compression", "gordon", "regression", "analysis", "partially", "use", "probabilities", "distribution", "figure", "information", "representations", "size", "able", "pocman", "variance", "theorem", "present", "test", "assume", "include", "learned", "therefore", "reduce", "since", "linear", "target", "projections", "approach", "estimation", "col", "sparsity", "veness", "column", "case", "let", "parameters", "particular", "feature", "shows", "length", "maillard", "singh", "spaces", "many"], "authors": "William Hamilton; Mahdi Milani Fard,; Joelle Pineau,", "thumbnail_path": "thumbnails/Modelling Sparse Dynamical Systems with Compressed Predictive State Representations.jpg"}, {"title": "Coco-Q: Learning in Stochastic Games with Side Payments", "topics": [0.019429250196482693, 0.90284402687530385, 0.019429180868631681, 0.019429373380192596, 0.019439097861118242, 0.019429070818270774], "pdf_url": "http://jmlr.org/proceedings/papers/v28/sodomka13.pdf", "most_common": ["coco", "values", "game", "games", "goal", "figure", "side", "learning", "stochastic", "value", "agents", "trajectory", "grid", "payments", "step", "two", "agent", "ego", "move", "minmax", "one", "operator", "players", "kalai", "left", "maxmax", "nash", "policy", "probability", "friend", "reach", "set", "shared", "solution", "possible", "time", "alter", "joint", "goals", "littman", "action", "proceedings", "player", "would", "machine", "square", "shown", "conference", "reward", "algorithm", "play", "equilibrium", "actions", "expected", "also", "turkey", "convergence", "moves", "incredible", "foe", "michael", "sum", "international", "since", "converges", "converge", "state", "unique", "right", "moving", "pays", "transfer", "concept", "team", "policies", "total", "use", "operators", "example", "states", "greenwald", "shows", "illustrate", "note", "without", "payment", "solutions", "symmetric", "however", "second", "corresponding", "prisoner", "made", "sticks", "functions", "correlated", "stick", "markov", "equation", "following"], "authors": "Elizabeth Hilliard; Eric Sodomka; Michael Littman; Amy Greenwald", "thumbnail_path": "thumbnails/Coco-Q: Learning in Stochastic Games with Side Payments.jpg"}, {"title": "Guided Policy Search", "topics": [0.017449412566897818, 0.91274986511517209, 0.017449369591913171, 0.017449492249438644, 0.017452581786527522, 0.017449278690050963], "pdf_url": "http://jmlr.org/proceedings/papers/v28/levine13.pdf", "most_common": ["policy", "samples", "guiding", "ddp", "search", "learning", "initial", "methods", "used", "tbdp", "gps", "policies", "also", "reward", "guided", "method", "use", "trajectory", "using", "distributions", "prior", "importance", "distribution", "optimization", "neural", "example", "new", "gradient", "test", "sample", "algorithm", "current", "learn", "optimal", "systems", "international", "conference", "figure", "since", "sampling", "rollouts", "learned", "work", "adaptive", "variant", "local", "line", "states", "abbeel", "good", "mean", "gaussian", "iteration", "show", "complex", "actions", "previous", "humanoid", "examples", "log", "making", "high", "hidden", "shown", "could", "walking", "set", "often", "estimator", "dynamic", "stochastic", "section", "approach", "regions", "one", "given", "exp", "state", "tang", "well", "peters", "low", "reinforcement", "single", "walker", "suitable", "machine", "return", "term", "found", "trajectories", "standard", "training", "require", "hopper", "schaal", "best", "units", "terrains", "sampled"], "authors": "Sergey Levine; Vladlen Koltun", "thumbnail_path": "thumbnails/Guided Policy Search.jpg"}, {"title": "The Cross-Entropy Method Optimizes for Quantiles", "topics": [0.014020223282116634, 0.92989888958907796, 0.014020277657563512, 0.014020277879244699, 0.014020119215308015, 0.01402021237668921], "pdf_url": "http://jmlr.org/proceedings/papers/v28/goschin13.pdf", "most_common": ["proportional", "distribution", "policy", "algorithm", "value", "method", "mce", "quantile", "quantiles", "convergence", "values", "optimization", "generation", "optimizes", "set", "algorithms", "results", "two", "expected", "reward", "one", "policies", "input", "noise", "distributions", "setting", "parameters", "optimal", "standard", "szita", "rubinstein", "search", "inputs", "evaluations", "space", "rho", "solutions", "game", "tetris", "function", "number", "experiment", "mannor", "samples", "noisy", "particular", "according", "learning", "initial", "maximum", "properties", "control", "stock", "profile", "goal", "paper", "also", "performance", "case", "problem", "empirical", "thus", "bernoulli", "used", "blackjack", "using", "goschin", "stochastic", "section", "version", "example", "machine", "operations", "kroese", "reasonable", "research", "stage", "population", "determined", "ran", "show", "experiments", "state", "various", "simple", "inventory", "well", "repeated", "time", "second", "even", "theoretical", "parameter", "variant", "executed", "weight", "ordering", "selection", "phenomenon", "converge"], "authors": "Sergiu Goschin; Ari Weinstein; Michael Littman", "thumbnail_path": "thumbnails/The Cross-Entropy Method Optimizes for Quantiles.jpg"}, {"title": "A Practical Algorithm for Topic Modeling with Provable Guarantees", "topics": [0.01598980027786176, 0.92005119179919459, 0.01598975025629723, 0.015989824692313023, 0.015989711308168907, 0.015989721666164497], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/arora13.pdf", "most_common": ["algorithm", "topic", "anchor", "matrix", "algorithms", "documents", "words", "topics", "recover", "error", "word", "model", "arora", "gibbs", "data", "recovery", "points", "set", "rows", "provable", "using", "use", "recoverkl", "models", "results", "given", "vertices", "new", "modeling", "document", "guarantees", "distributions", "nips", "linear", "sampling", "step", "synthetic", "parameters", "corpora", "practical", "found", "number", "blei", "point", "learning", "hull", "time", "dirichlet", "times", "corpus", "close", "distribution", "coherence", "convex", "shown", "running", "probability", "zzz", "simplex", "whose", "even", "mccallum", "two", "work", "one", "performance", "selection", "many", "present", "sample", "david", "mcmc", "likelihood", "separability", "show", "based", "mimno", "empirical", "zero", "used", "analysis", "solve", "lda", "supplementary", "log", "generated", "large", "learned", "method", "let", "latent", "least", "also", "three", "procedure", "input", "real", "span", "vertex", "row"], "authors": "Sanjeev Arora; Rong Ge; Yonatan Halpern; David Mimno; Ankur Moitra; David Sontag; Yichen Wu; Michael Zhu", "thumbnail_path": "thumbnails/A Practical Algorithm for Topic Modeling with Provable Guarantees.jpg"}, {"title": "Online Latent Dirichlet Allocation with Infinite Vocabulary", "topics": [0.017154465644925416, 0.91422745183857246, 0.017154430774100185, 0.017154517855435272, 0.01715457758637591, 0.01715455630059062], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhai13.pdf", "most_common": ["topic", "words", "distribution", "models", "model", "online", "vocabulary", "infvoc", "dirichlet", "variational", "blei", "inference", "word", "topics", "minibatch", "latent", "pmi", "truncation", "process", "better", "tos", "settings", "section", "documents", "parameters", "use", "distributions", "algorithms", "set", "bayesian", "allocation", "figure", "parameter", "base", "david", "score", "wang", "nonparametric", "new", "however", "learning", "coherence", "lda", "scale", "newsgroups", "reordering", "probability", "dtm", "two", "delay", "used", "language", "jordan", "approach", "modeling", "document", "streaming", "minibatches", "algorithm", "consider", "large", "zdn", "rank", "vocabularies", "later", "capture", "higher", "uses", "possible", "dynamic", "stochastic", "index", "instead", "size", "corpus", "accuracy", "values", "mimno", "batch", "underlying", "within", "conditional", "hybrid", "strings", "level", "multinomial", "based", "approaches", "contains", "must", "information", "hierarchical", "data", "allow", "choose", "reasonable", "log", "training", "length", "number"], "authors": "KE ZHAI; Jordan Boyd-Graber", "thumbnail_path": "thumbnails/Online Latent Dirichlet Allocation with Infinite Vocabulary.jpg"}, {"title": "Gibbs Max-Margin Topic Models with Fast Sampling Algorithms", "topics": [0.016735585767702083, 0.91632224125208983, 0.016735555273942614, 0.0167356177960441, 0.01673547332267189, 0.016735526587549229], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/zhu13.pdf", "most_common": ["gibbs", "topic", "medlda", "distribution", "data", "posterior", "expected", "sampling", "training", "max", "gibbsmedlda", "model", "time", "set", "loss", "models", "exp", "using", "learning", "algorithms", "problem", "binary", "topics", "accuracy", "zhu", "prediction", "supervised", "performance", "margin", "regression", "vmedlda", "solve", "lda", "svm", "methods", "fast", "variational", "collapsed", "min", "also", "latent", "see", "inference", "term", "multiple", "lemma", "testing", "augmentation", "results", "sample", "machine", "gaussian", "zdn", "standard", "one", "given", "seconds", "draw", "existing", "large", "prior", "research", "figure", "assumptions", "shows", "estimate", "variables", "number", "need", "words", "experiments", "bayesian", "document", "uses", "hinge", "conditional", "inverse", "assignments", "vector", "upper", "word", "reviews", "learn", "numbers", "information", "response", "jiang", "since", "likelihood", "dirichlet", "maximum", "restricting", "due", "new", "used", "without", "scale", "journal", "distributions", "log"], "authors": "Jun Zhu; Ning Chen; Hugh Perkins; Bo Zhang", "thumbnail_path": "thumbnails/Gibbs Max-Margin Topic Models with Fast Sampling Algorithms.jpg"}, {"title": "Modeling Musical Influence with Topic Models", "topics": [0.019532751873577621, 0.31609283750426337, 0.01953294871566124, 0.019532705042714156, 0.019532371868166278, 0.60577638499561737], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/shalit13.pdf", "most_common": ["songs", "topic", "model", "musical", "rock", "song", "music", "jazz", "innovation", "artists", "models", "modeling", "using", "dataset", "metal", "time", "blei", "blues", "artist", "audio", "features", "classic", "later", "scores", "use", "hop", "ranked", "one", "hip", "international", "proceedings", "pop", "genres", "folk", "information", "years", "topics", "genre", "epoch", "used", "figure", "data", "gerrish", "measure", "median", "conference", "epochs", "popular", "year", "structure", "two", "spearman", "score", "several", "found", "dim", "indie", "earlier", "innovative", "number", "mean", "content", "electronic", "overall", "evolution", "retrieval", "approach", "many", "learning", "baseline", "early", "distribution", "acoustic", "since", "rap", "considered", "across", "described", "much", "funk", "study", "ismir", "tags", "known", "soul", "correlation", "research", "shows", "million", "language", "rank", "given", "top", "new", "available", "examples", "table", "single", "results", "include"], "authors": "Uri Shalit; Daphna Weinshall; Gal Chechik", "thumbnail_path": "thumbnails/Modeling Musical Influence with Topic Models.jpg"}, {"title": "Nested Chinese Restaurant Franchise Process: Applications to User Tracking and Document Modeling", "topics": [0.014228076950814468, 0.92886030566219635, 0.014227745051733241, 0.014228057352412027, 0.014227807915120487, 0.014228007067723522], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ahmed13.pdf", "most_common": ["model", "process", "node", "hierarchical", "tree", "restaurant", "distribution", "chinese", "location", "user", "topics", "nested", "sampling", "structure", "topic", "language", "child", "global", "franchise", "table", "models", "new", "modeling", "document", "path", "words", "algorithm", "use", "sample", "probability", "regions", "dirichlet", "set", "using", "moreover", "data", "assume", "inference", "tweets", "hong", "documents", "two", "since", "given", "ncrf", "tweet", "exact", "root", "eisenstein", "content", "variables", "number", "microblogs", "ahmed", "users", "roj", "results", "nips", "hpam", "blei", "terms", "methods", "nodes", "regional", "dir", "teh", "usa", "figure", "hierarchy", "generative", "paths", "generating", "thus", "used", "ncrp", "object", "vertex", "dataset", "associated", "distributions", "test", "xoj", "method", "full", "represented", "want", "rather", "one", "need", "note", "best", "approach", "component", "however", "region", "obtain", "twitter", "zoj", "existing", "pachinko"], "authors": "Amr Ahmed; Liangjie Hong; Alexander Smola", "thumbnail_path": "thumbnails/Nested Chinese Restaurant Franchise Process: Applications to User Tracking and Document Modeling.jpg"}, {"title": "Parallel Markov Chain Monte Carlo for Nonparametric Mixture Models", "topics": [0.015960869670899401, 0.92019574603451026, 0.015960875121938507, 0.015960913747881771, 0.015960771550344033, 0.01596082387442584], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/williamson13.pdf", "most_common": ["dirichlet", "data", "inference", "cluster", "process", "processor", "time", "parallel", "using", "models", "mixture", "hdp", "model", "number", "gibbs", "processors", "monte", "carlo", "nonparametric", "allocations", "distribution", "sampling", "auxiliary", "clusters", "one", "variational", "sampler", "methods", "points", "distributed", "local", "global", "markov", "avparallel", "random", "used", "approximate", "single", "algorithm", "chain", "teh", "described", "set", "conditional", "gamma", "variable", "algorithms", "synch", "independence", "given", "according", "steps", "existing", "method", "obtained", "figure", "probability", "observations", "measures", "xmi", "approach", "conditioned", "perform", "split", "perplexity", "implemented", "sequential", "introducing", "representation", "since", "quality", "performance", "eight", "point", "bayesian", "particle", "nips", "appropriate", "hierarchical", "resulting", "parameter", "four", "paper", "assignments", "smc", "concentration", "note", "based", "processes", "learning", "gap", "independent", "dpmm", "without", "obtain", "xing", "step", "true", "minutes", "independently"], "authors": "Sinead Williamson; Avinava Dubey; Eric Xing", "thumbnail_path": "thumbnails/Parallel Markov Chain Monte Carlo for Nonparametric Mixture Models.jpg"}, {"title": "MAD-Bayes: MAP-based Asymptotic Derivations from Bayes", "topics": [0.013124206034539758, 0.93437897194255848, 0.013124208186073627, 0.013124255995850523, 0.013124171238757521, 0.013124186602220258], "pdf_url": "http://jmlr.org/proceedings/papers/v28/broderick13.pdf", "most_common": ["feature", "data", "algorithm", "objective", "cluster", "number", "features", "clustering", "algorithms", "one", "row", "clusters", "means", "jordan", "map", "new", "learning", "bayesian", "random", "may", "function", "four", "ibp", "probability", "kulis", "problem", "gibbs", "model", "collapsed", "let", "gaussian", "point", "case", "prior", "process", "znk", "ghahramani", "index", "base", "values", "estimate", "given", "allocation", "using", "posterior", "consider", "via", "pictures", "run", "second", "nonparametric", "broderick", "mean", "matrix", "shows", "likelihood", "also", "set", "initializations", "asymptotics", "tabletop", "picture", "appear", "counts", "parameter", "note", "stepwise", "latent", "penalty", "local", "mixture", "crp", "faces", "optimization", "initialization", "obtain", "models", "choice", "customer", "optimal", "statistical", "framework", "since", "combinatorial", "nth", "log", "assign", "hyperparameter", "beta", "show", "text", "equal", "sampling", "sampler", "value", "assigned", "pitman", "form", "similar", "even"], "authors": "Tamara Broderick; Brian Kulis; Michael Jordan", "thumbnail_path": "thumbnails/MAD-Bayes: MAP-based Asymptotic Derivations from Bayes.jpg"}, {"title": "Topic Model Diagnostics: Assessing Domain Relevance via Topical Alignment", "topics": [0.015816803172702742, 0.92091513299833105, 0.01581675099561853, 0.015816881405450536, 0.015816585539474133, 0.015817845888423089], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chuang13.pdf", "most_common": ["topic", "topical", "topics", "models", "concepts", "latent", "reference", "model", "measures", "figure", "junk", "lda", "using", "fused", "domain", "resolved", "matching", "similarity", "alignment", "scores", "concept", "values", "david", "human", "two", "matches", "number", "correspondence", "ramage", "word", "also", "dot", "set", "optimization", "rescaled", "via", "product", "hyperparameter", "blei", "assessing", "newman", "evaluation", "likelihood", "pairs", "probability", "score", "intrinsic", "stanford", "based", "information", "introduce", "framework", "one", "matrix", "chart", "diagnostics", "coherence", "relevance", "repeated", "research", "large", "work", "correlation", "misalignment", "modeling", "mccallum", "experts", "within", "provide", "parameter", "steyvers", "wallach", "likelihoods", "corpus", "considered", "text", "manning", "mimno", "observe", "user", "analysis", "match", "range", "examine", "results", "plda", "entries", "missing", "marked", "trained", "process", "axis", "may", "measure", "daniel", "diagnostic", "rank", "quality", "built", "random"], "authors": "Jason Chuang; Sonal Gupta; Christopher Manning; Jeffrey Heer", "thumbnail_path": "thumbnails/Topic Model Diagnostics: Assessing Domain Relevance via Topical Alignment.jpg"}, {"title": "On the importance of initialization and momentum in deep learning", "topics": [0.014339225581553145, 0.92830401658615458, 0.014339187675970677, 0.014339273236823638, 0.014339173299943329, 0.014339123619554644], "pdf_url": "http://jmlr.org/proceedings/papers/v28/sutskever13.pdf", "most_common": ["momentum", "learning", "nag", "deep", "methods", "neural", "results", "training", "martens", "gradient", "convergence", "networks", "optimization", "initialization", "use", "rate", "method", "problems", "used", "sutskever", "directions", "hinton", "random", "local", "see", "table", "performance", "using", "rnns", "stochastic", "along", "may", "error", "previous", "particular", "parameter", "found", "standard", "achieve", "update", "even", "type", "information", "initializations", "objective", "importance", "recurrent", "convex", "scale", "certain", "sgd", "thus", "train", "large", "also", "however", "many", "bengio", "problem", "tasks", "accelerated", "one", "phase", "velocity", "set", "descent", "units", "like", "experiments", "nesterov", "cient", "quadratic", "constant", "better", "curvature", "given", "coe", "much", "schedule", "appendix", "dynamics", "errors", "work", "values", "temporal", "across", "dnns", "larger", "make", "without", "seems", "classical", "models", "initialized", "reported", "allows", "hidden", "spectral", "proceedings", "achieved"], "authors": "Ilya Sutskever; James Martens; George Dahl; Geoffrey Hinton", "thumbnail_path": "thumbnails/On the importance of initialization and momentum in deep learning.jpg"}, {"title": "A non-IID Framework for Collaborative Filtering with Restricted Boltzmann Machines", "topics": [0.015590391385285752, 0.9220481426602507, 0.015590385862050481, 0.015590440543678998, 0.015590266178640176, 0.015590373370093964], "pdf_url": "http://jmlr.org/proceedings/papers/v28/georgiev13.pdf", "most_common": ["model", "rbm", "visible", "ratings", "models", "hidden", "collaborative", "layer", "results", "two", "prediction", "rating", "also", "hybrid", "user", "multinomial", "items", "training", "using", "better", "framework", "units", "matrix", "users", "mae", "order", "quality", "given", "learning", "item", "boltzmann", "movielens", "machines", "proceedings", "values", "data", "one", "best", "yields", "datasets", "unit", "figure", "restricted", "sarwar", "salakhutdinov", "predictions", "original", "number", "filtering", "rbms", "algorithms", "used", "evaluation", "average", "correlations", "nodes", "truyen", "use", "performance", "based", "modeling", "value", "real", "standalone", "weights", "layers", "finally", "new", "trained", "weight", "shows", "could", "see", "however", "similar", "single", "compared", "latent", "opposed", "work", "information", "correlation", "features", "table", "latter", "joint", "set", "binary", "previous", "right", "usa", "generated", "wij", "related", "shown", "linear", "yum", "connected", "sum", "comparable"], "authors": "Kostadin Georgiev; Preslav Nakov", "thumbnail_path": "thumbnails/A non-IID Framework for Collaborative Filtering with Restricted Boltzmann Machines.jpg"}, {"title": "Parsing epileptic events using a Markov switching process model for correlated time series", "topics": [0.24389871952431508, 0.68885971284356995, 0.016808911546974146, 0.016809059546249939, 0.016808817017397309, 0.016814779521493618], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/wulsin13.pdf", "most_common": ["state", "channel", "event", "channels", "model", "time", "events", "series", "process", "seizure", "eeg", "markov", "epileptic", "sample", "ieeg", "clinical", "data", "transition", "using", "dynamics", "states", "parsing", "parameters", "innovations", "three", "fox", "correlated", "seizures", "modeling", "structure", "supplement", "feature", "switching", "dynamic", "bursts", "set", "electrode", "prior", "one", "conditional", "chains", "sampling", "number", "analysis", "similar", "graph", "innovation", "multivariate", "via", "given", "jordan", "sequences", "conference", "graphical", "heldout", "two", "also", "sparse", "models", "denotes", "vector", "onset", "end", "nonparametric", "mcmc", "observations", "beta", "proceedings", "correlations", "individual", "learning", "covariance", "hmm", "bayesian", "middle", "capture", "sequence", "use", "statistics", "posterior", "spatial", "consider", "large", "work", "example", "machine", "factorial", "recordings", "features", "observation", "conditioned", "left", "dependency", "shared", "distributions", "important", "independently", "red", "independencies", "predictions"], "authors": "Drausin Wulsin; Emily Fox; Brian Litt", "thumbnail_path": "thumbnails/Parsing epileptic events using a Markov switching process model for correlated time series.jpg"}, {"title": "Exploring the Mind: Integrating Questionnaires and fMRI", "topics": [0.014097338979249537, 0.9295128852297242, 0.014097474147830382, 0.014097483279990981, 0.014097255620681631, 0.014097562742523497], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/salazar13.pdf", "most_common": ["model", "data", "matrix", "sparse", "binary", "fmri", "real", "questions", "questionnaires", "text", "topic", "amygdala", "distribution", "associated", "graphical", "prior", "latent", "models", "learned", "ordered", "proposed", "precision", "consider", "use", "figure", "categorical", "people", "features", "analysis", "also", "questionnaire", "answers", "via", "panel", "section", "probit", "integrating", "joint", "stimuli", "using", "two", "related", "exploring", "topics", "mind", "reactivity", "performance", "multiple", "considered", "network", "covariance", "within", "expressions", "construction", "vector", "based", "yij", "salazar", "factor", "modeling", "bayesian", "results", "groups", "predict", "brain", "yoshida", "average", "factorization", "responses", "west", "used", "question", "posterior", "four", "types", "relationships", "zero", "ibp", "parameters", "visual", "may", "response", "meeds", "representation", "shows", "connectivity", "given", "note", "measured", "learning", "employ", "modeled", "subjects", "yields", "algorithm", "structure", "finally", "updated", "every", "component"], "authors": "Esther Salazar; Ryan Bogdan; Adam Gorka; Ahmad Hariri; Lawrence Carin", "thumbnail_path": "thumbnails/Exploring the Mind: Integrating Questionnaires and fMRI.jpg"}, {"title": "Gated Autoencoders with Tied Input Weights", "topics": [0.015709315569281412, 0.92145330514984591, 0.015709296455095573, 0.015709350796351211, 0.015709230319519537, 0.015709501709906242], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/alain13.pdf", "most_common": ["factor", "units", "network", "mapping", "layer", "images", "gated", "learning", "transformations", "cga", "rotations", "autoencoders", "matrix", "transformation", "angle", "input", "rotation", "memisevic", "one", "weights", "reconstruction", "error", "activation", "since", "given", "complex", "size", "two", "values", "representation", "pairs", "case", "image", "set", "see", "algorithm", "degree", "use", "projections", "real", "tied", "mathematical", "represent", "learned", "product", "number", "orthogonal", "hinton", "training", "particular", "pixels", "eigenvalues", "figure", "better", "also", "networks", "mean", "cross", "classical", "inner", "work", "numbers", "corresponding", "neural", "quadrature", "matrices", "section", "algorithms", "diagonal", "detection", "fact", "eigenvectors", "would", "parameters", "action", "unit", "multiplication", "representations", "weight", "spectrum", "performance", "proceedings", "thus", "approach", "however", "fny", "fnx", "cosine", "used", "less", "compared", "like", "recognition", "imaginary", "comparison", "deep", "commuting", "whereas", "test", "layers"], "authors": "Alain Droniou; Olivier Sigaud", "thumbnail_path": "thumbnails/Gated Autoencoders with Tied Input Weights.jpg"}, {"title": "Simple Sparsification Improves Sparse Denoising Autoencoders in Denoising Highly Corrupted Images", "topics": [0.019692430140010649, 0.90153800465446166, 0.019692410467276451, 0.019692476827896842, 0.019692336812041224, 0.019692341098313207], "pdf_url": "http://jmlr.org/proceedings/papers/v28/cho13.pdf", "most_common": ["image", "denoising", "dae", "simple", "sparse", "noise", "latent", "hidden", "sparsity", "spdae", "encoder", "trained", "proposed", "sample", "error", "images", "reconstruction", "decoder", "representation", "test", "autoencoders", "performance", "patches", "given", "see", "noisy", "level", "improves", "denoised", "set", "using", "deep", "corrupted", "one", "coding", "white", "average", "case", "used", "spdaes", "model", "data", "gaussian", "learning", "units", "without", "function", "layers", "obtained", "two", "activation", "daes", "patch", "layer", "neural", "samples", "use", "small", "space", "training", "number", "xie", "target", "explicitly", "instance", "regularizer", "also", "applied", "burger", "component", "maps", "representations", "explicit", "clean", "approach", "however", "improvement", "input", "larger", "discriminative", "type", "following", "regularization", "found", "especially", "models", "code", "shrinkage", "large", "conventional", "additive", "cho", "information", "max", "ieee", "approaches", "levels", "nonlinearity", "pixels", "autoencoder"], "authors": "Kyunghyun Cho", "thumbnail_path": "thumbnails/Simple Sparsification Improves Sparse Denoising Autoencoders in Denoising Highly Corrupted Images.jpg"}, {"title": "Natural Image Bases to Represent Neuroimaging Data", "topics": [0.018719350115854485, 0.90625283867971218, 0.018719202242312896, 0.018719327863990803, 0.018869819488549239, 0.01871946160958032], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gupta13b.pdf", "most_common": ["mri", "bases", "data", "natural", "image", "feature", "using", "figure", "used", "set", "neuroimaging", "mci", "images", "brain", "shows", "disease", "represent", "pooling", "features", "performance", "learning", "learned", "visual", "basis", "early", "table", "representation", "approach", "adni", "patches", "activations", "method", "learn", "neural", "dementia", "parameters", "however", "analysis", "sparse", "algorithm", "results", "matsuda", "two", "convolutional", "sigmoid", "structural", "autoencoder", "imabayashi", "slice", "inspection", "information", "lesions", "binary", "lecun", "research", "accuracy", "sensitivity", "thus", "journal", "validation", "activation", "convolution", "stereotactic", "diagnostic", "kloppel", "clinical", "scans", "sae", "class", "yang", "ica", "median", "network", "various", "extraction", "layer", "surface", "normalization", "also", "input", "three", "test", "computerized", "progression", "teh", "autoencoders", "clinicians", "section", "search", "healthy", "scan", "hinton", "high", "work", "values", "following", "collection", "statistical", "university", "shown"], "authors": "Ashish Gupta; Murat Ayhan; Anthony Maida", "thumbnail_path": "thumbnails/Natural Image Bases to Represent Neuroimaging Data.jpg"}, {"title": "Direct Modeling of Complex Invariances for Visual Object Features", "topics": [0.016153633133182011, 0.9192313916622602, 0.016153574121914715, 0.016153678433147679, 0.016153462841433555, 0.016154259808061712], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/yuhui13.pdf", "most_common": ["complex", "invariance", "learning", "dictionary", "feature", "would", "pooling", "features", "invariances", "object", "data", "modeling", "direct", "using", "visual", "training", "size", "image", "receptive", "view", "layer", "system", "set", "coates", "representation", "base", "accuracy", "results", "algorithm", "networks", "case", "amount", "labeled", "approach", "one", "result", "performance", "local", "patch", "simple", "table", "unsupervised", "deep", "rotation", "additional", "see", "transforms", "like", "output", "layers", "patches", "experiment", "method", "network", "coding", "knowledge", "sparse", "recognition", "similar", "activation", "full", "prior", "vik", "also", "best", "strategy", "neural", "per", "spatial", "large", "learn", "example", "dataset", "related", "directly", "zou", "class", "invariant", "recent", "competitive", "improvement", "works", "pooled", "appear", "highly", "use", "two", "convolutional", "give", "good", "beyond", "could", "encoding", "believe", "dtk", "say", "gains", "however", "much", "lecun"], "authors": "Ka Yu Hui", "thumbnail_path": "thumbnails/Direct Modeling of Complex Invariances for Visual Object Features.jpg"}, {"title": "Spectral Compressed Sensing via Structured Matrix Completion", "topics": [0.016418932961597438, 0.91790520883467475, 0.016418933095201701, 0.016419031815459235, 0.016419011995167276, 0.016418881297899569], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chen13g.pdf", "most_common": ["matrix", "hankel", "completion", "emac", "enhanced", "algorithm", "spectral", "sensing", "compressed", "via", "data", "frequency", "recovery", "incoherence", "structured", "matrices", "frequencies", "object", "model", "samples", "theorem", "form", "number", "one", "condition", "set", "signal", "candes", "entries", "theoretical", "observation", "problem", "ieee", "random", "conditions", "norm", "following", "based", "lemma", "observed", "sparse", "processing", "results", "small", "let", "information", "singular", "algorithms", "rank", "order", "value", "underlying", "noise", "denote", "obtained", "projection", "exact", "reconstruction", "harmonic", "suppose", "numerical", "possible", "minimization", "true", "time", "consider", "phase", "chi", "guarantee", "max", "imaging", "onto", "locations", "transactions", "section", "ground", "however", "sampling", "recht", "location", "sparsity", "super", "noisy", "gross", "models", "resolution", "partial", "stable", "rate", "method", "thresholding", "applications", "nonparametric", "denotes", "probability", "size", "given", "constant", "approach", "experiments"], "authors": "Yuxin Chen; Yuejie Chi", "thumbnail_path": "thumbnails/Spectral Compressed Sensing via Structured Matrix Completion.jpg"}, {"title": "Sparse PCA through Low-rank Approximations", "topics": [0.013076187949007612, 0.93461925808566648, 0.013076158982347945, 0.013076233688591947, 0.01307606833786725, 0.013076092956518629], "pdf_url": "http://jmlr.org/proceedings/papers/v28/papailiopoulos13.pdf", "most_common": ["sparse", "algorithm", "pca", "data", "approximation", "principal", "set", "support", "matrix", "vector", "obtain", "component", "max", "largest", "vectors", "two", "zhang", "intersection", "optimal", "decay", "candidate", "sparsity", "spannogram", "case", "sets", "eigenvalue", "entries", "use", "one", "fullpath", "supports", "twitter", "eigenvector", "method", "approximations", "performance", "words", "step", "elimination", "tpower", "curves", "used", "analysis", "possible", "ghaoui", "unit", "main", "absolute", "fact", "eigenvectors", "using", "papailiopoulos", "constant", "elements", "international", "end", "machine", "experiments", "pcs", "exactly", "show", "covariance", "opt", "running", "power", "journal", "time", "moghaddam", "desired", "table", "greek", "ieee", "tweets", "matrices", "given", "scheme", "points", "google", "equal", "simply", "learning", "observe", "yuan", "guarantees", "output", "bound", "log", "problem", "test", "microsoft", "maximum", "greeceg", "solution", "indices", "eigenvalues", "love", "work", "compare", "information", "feature"], "authors": "Dimitris Papailiopoulos; Alexandros Dimakis; Stavros Korokythakis", "thumbnail_path": "thumbnails/Sparse PCA through Low-rank Approximations.jpg"}, {"title": "Efficient Sparse Group Feature Selection via Nonconvex Optimization", "topics": [0.016468331497512739, 0.91765833595632562, 0.016468381697368639, 0.016468383275713545, 0.016468301429258696, 0.016468266143820763], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/xiang13.pdf", "most_common": ["group", "selection", "sparse", "feature", "nonconvex", "method", "projection", "lasso", "convex", "algorithm", "optimization", "following", "methods", "groups", "solution", "optimal", "parameter", "via", "algorithms", "features", "results", "set", "huang", "proposed", "section", "data", "number", "oracle", "two", "statistical", "performance", "learning", "zhang", "max", "journal", "estimator", "admm", "constraints", "table", "however", "moreover", "model", "theorem", "constraint", "log", "function", "problem", "formulation", "parameters", "end", "gradient", "given", "also", "objective", "result", "approach", "tuning", "mcp", "shen", "step", "therefore", "accelerated", "breheny", "solving", "since", "bridge", "boyd", "based", "minimize", "nonzero", "global", "whose", "consistent", "selected", "composite", "hold", "values", "machine", "may", "minimizer", "paper", "programming", "assumption", "note", "bisection", "subject", "sglp", "due", "value", "return", "used", "less", "agm", "time", "computation", "high", "discussion", "theory", "accuracy", "addition"], "authors": "Shuo Xiang; Xiaotong Shen; Jieping Ye", "thumbnail_path": "thumbnails/Efficient Sparse Group Feature Selection via Nonconvex Optimization.jpg"}, {"title": "A General Iterative Shrinkage and Thresholding Algorithm for Non-convex Regularized Optimization Problems", "topics": [0.016448451083870379, 0.91775795322450104, 0.016448393682735981, 0.016448450339812438, 0.016448347509346713, 0.016448404159733351], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/gong13a.pdf", "most_common": ["algorithm", "problem", "min", "line", "search", "function", "gist", "objective", "criterion", "arg", "iterative", "general", "value", "convex", "log", "shrinkage", "following", "thresholding", "sparse", "proposed", "sequence", "step", "convergence", "cpu", "time", "analysis", "problems", "zhang", "sign", "scaled", "max", "data", "size", "seconds", "monotone", "lemma", "optimization", "solve", "learning", "solution", "two", "proof", "used", "initialize", "iteration", "thus", "sets", "theorem", "journal", "via", "propose", "many", "point", "proximal", "using", "wright", "critical", "bounded", "commonly", "outer", "solving", "university", "assumption", "obtain", "operator", "limit", "gong", "rule", "scp", "monotonically", "penalties", "satisfy", "let", "assumptions", "algorithms", "paper", "class", "based", "tmin", "regularizers", "points", "solves", "hold", "machine", "applications", "ieee", "easily", "related", "regularizer", "experiments", "however", "table", "present", "also", "follows", "signal", "transactions", "considering", "processing", "computational"], "authors": "Pinghua Gong; Changshui Zhang; Zhaosong Lu; Jianhua Huang; Jieping Ye", "thumbnail_path": "thumbnails/A General Iterative Shrinkage and Thresholding Algorithm for Non-convex Regularized Optimization Problems.jpg"}, {"title": "Robust Sparse Regression under Adversarial Corruption", "topics": [0.014997295733287862, 0.92501350474794974, 0.01499746536341701, 0.014997350153440102, 0.014997171603729294, 0.014997212398176082], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chen13h.pdf", "most_common": ["robust", "regression", "corruption", "algorithm", "corrupted", "support", "sparse", "lasso", "model", "recovery", "matrix", "number", "algorithms", "outliers", "one", "log", "consider", "even", "standard", "dantzig", "force", "convex", "brute", "entries", "rotr", "following", "show", "response", "selector", "performance", "many", "theorem", "noise", "inner", "high", "outlier", "linear", "also", "error", "guarantees", "adversarial", "setting", "least", "approach", "simple", "optimization", "note", "using", "rows", "covariates", "case", "results", "chen", "use", "ieee", "trimmed", "correct", "recover", "output", "design", "pursuit", "particular", "figure", "parameter", "might", "statistics", "covariate", "min", "distributed", "set", "well", "loss", "methods", "caramanis", "problem", "problems", "random", "second", "section", "approaches", "product", "natural", "may", "data", "observations", "transactions", "let", "handle", "fail", "tsybakov", "true", "models", "assume", "row", "errors", "two", "example", "thresholding", "gaussian", "parameters"], "authors": "Yudong Chen; Constantine Caramanis; Shie Mannor", "thumbnail_path": "thumbnails/Robust Sparse Regression under Adversarial Corruption.jpg"}, {"title": "ABC Reinforcement Learning", "topics": [0.018478206697439544, 0.90760900363263319, 0.01847815745129942, 0.01847824403546687, 0.018478209668875679, 0.018478178514285126], "pdf_url": "http://jmlr.org/proceedings/papers/v28/dimitrakakis13.pdf", "most_common": ["abc", "reinforcement", "learning", "policy", "bayesian", "approximate", "posterior", "model", "statistic", "environment", "value", "number", "good", "using", "prior", "may", "use", "however", "lspi", "inference", "sampling", "samples", "sampled", "simple", "utility", "parameters", "history", "data", "class", "pendulum", "used", "computation", "probability", "trajectories", "even", "optimal", "ntrj", "framework", "policies", "ndat", "problem", "algorithm", "markov", "sample", "better", "lagoudakis", "given", "simulators", "thompson", "set", "dimitrakakis", "approach", "rollouts", "general", "bertsekas", "theorem", "simulator", "decision", "additional", "time", "via", "goal", "parametrised", "since", "sequence", "distribution", "expected", "methods", "simulation", "function", "models", "problems", "finally", "case", "results", "two", "car", "statistical", "standard", "estimate", "need", "icml", "also", "fact", "well", "real", "statistics", "generated", "consider", "vlassis", "dynamic", "advantage", "strens", "approximation", "action", "proof", "would", "process", "particular", "poupart"], "authors": "Christos Dimitrakakis; Nikolaos Tziortziotis", "thumbnail_path": "thumbnails/ABC Reinforcement Learning.jpg"}, {"title": "Mean Reversion with a Variance Threshold", "topics": [0.015027606962535049, 0.58798598004802682, 0.015027575226714102, 0.015027683990976107, 0.35190361575204604, 0.015027538019701815], "pdf_url": "http://jmlr.org/proceedings/papers/v28/cuturi13.pdf", "most_common": ["variance", "mean", "trading", "problem", "using", "reversion", "basket", "process", "baskets", "costs", "threshold", "time", "vector", "optimal", "portmanteau", "crossing", "given", "transaction", "series", "box", "minimize", "predictability", "solution", "figure", "solving", "sharpe", "techniques", "statistic", "section", "criteria", "matrix", "cointegration", "stationary", "assets", "order", "eigenvalue", "tiao", "subject", "show", "minimizing", "three", "two", "weights", "program", "multivariate", "unit", "asset", "one", "average", "ratio", "volatility", "contract", "johansen", "ols", "problems", "results", "def", "sample", "matrices", "yang", "solutions", "computed", "nemirovski", "convex", "relaxation", "strategy", "mathematical", "per", "noise", "form", "consider", "cost", "cents", "following", "jurek", "variables", "relaxations", "estimation", "thus", "analysis", "solve", "also", "arbitrage", "classical", "bound", "detailed", "variable", "reverting", "exact", "resulting", "programming", "write", "produce", "data", "paper", "since", "autoregressive", "hence", "generalized", "measures"], "authors": "Marco Cuturi; Alexandre dAspremont", "thumbnail_path": "thumbnails/Mean Reversion with a Variance Threshold.jpg"}, {"title": "Gaussian Process Kernels for Pattern Discovery and Extrapolation", "topics": [0.016056923002073061, 0.91971492429328461, 0.016056853099322636, 0.016056951660290659, 0.016056845153349413, 0.016057502791679498], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wilson13.pdf", "most_common": ["kernel", "kernels", "gaussian", "data", "process", "spectral", "pattern", "function", "figure", "using", "training", "functions", "covariance", "used", "density", "squared", "rasmussen", "exponential", "patterns", "learned", "learning", "williams", "shown", "discovery", "predictive", "processes", "sinc", "stationary", "extrapolation", "mean", "popular", "peak", "mixture", "long", "machine", "correlation", "simple", "bayesian", "inference", "discover", "one", "performance", "neural", "components", "model", "airline", "periodic", "marginal", "red", "negative", "likelihood", "months", "passenger", "structure", "term", "extrapolate", "could", "points", "black", "densities", "human", "distribution", "covariances", "small", "trend", "hyperparameters", "features", "given", "exp", "however", "many", "mixtures", "rational", "large", "expressive", "section", "component", "frequency", "shows", "log", "also", "region", "proposed", "adams", "noise", "quadratic", "true", "models", "every", "positive", "gaussians", "standard", "number", "gps", "wilson", "class", "closed", "moreover", "empirical", "blue"], "authors": "Andrew Wilson; Ryan Adams", "thumbnail_path": "thumbnails/Gaussian Process Kernels for Pattern Discovery and Extrapolation.jpg"}, {"title": "Average Reward Optimization Objective In Partially Observable Domains", "topics": [0.016377407896182593, 0.91809981657300888, 0.016377331154999987, 0.016377458278263427, 0.016390697854191529, 0.016377288243353487], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/grinberg13.pdf", "most_common": ["reward", "policy", "state", "linear", "average", "psr", "function", "stationary", "process", "prp", "system", "action", "let", "distribution", "systems", "representation", "predictive", "pomdp", "states", "observable", "behavior", "represented", "example", "one", "markov", "control", "framework", "probability", "partially", "psrs", "stochastic", "based", "domains", "following", "hidden", "optimization", "actions", "examples", "two", "represent", "search", "rational", "given", "result", "theorem", "vector", "objective", "fact", "learning", "without", "dimension", "using", "memory", "since", "induced", "number", "observations", "rewards", "planning", "parameters", "conference", "policies", "setting", "whose", "changes", "might", "evolution", "matrix", "future", "singh", "proceedings", "international", "sequences", "corresponding", "underlying", "properties", "consider", "particular", "figure", "mean", "hence", "also", "observation", "processes", "ergodic", "property", "well", "analysis", "model", "appropriate", "sequence", "called", "section", "jaeger", "respect", "obtained", "mao", "complexity", "james", "show"], "authors": "Yuri Grinberg; Doina Precup", "thumbnail_path": "thumbnails/Average Reward Optimization Objective In Partially Observable Domains.jpg"}, {"title": "Planning by Prioritized Sweeping with Small Backups", "topics": [0.019695220408834486, 0.90152422945937838, 0.019695099006087863, 0.019695283591335374, 0.019695080864347438, 0.019695086670016366], "pdf_url": "http://jmlr.org/proceedings/papers/v28/vanseijen13.pdf", "most_common": ["backup", "backups", "full", "small", "state", "time", "successor", "value", "planning", "model", "reversed", "per", "update", "usa", "one", "performance", "nsa", "cient", "method", "action", "learning", "using", "number", "states", "based", "methods", "sample", "prioritized", "optimal", "policy", "rsa", "psa", "step", "performs", "task", "reinforcement", "moore", "algorithm", "values", "used", "computation", "complexity", "computational", "mdps", "equation", "sweeping", "estimate", "pair", "reward", "function", "estimates", "second", "section", "initialize", "priority", "note", "demonstrate", "new", "since", "average", "predecessor", "case", "single", "queue", "memory", "following", "figure", "performed", "episodes", "transition", "version", "error", "equal", "atkeson", "results", "evaluation", "large", "current", "domains", "composite", "agent", "peng", "return", "introduce", "instead", "pairs", "times", "hence", "wiering", "williams", "observed", "cycles", "require", "expected", "decision", "use", "goal", "greedy", "top", "rewards"], "authors": "Harm van Seijen; Rich Sutton", "thumbnail_path": "thumbnails/Planning by Prioritized Sweeping with Small Backups.jpg"}, {"title": "Dynamic Covariance Models for Multivariate Financial Time Series", "topics": [0.019931930275723108, 0.7565064855307817, 0.019931852417329757, 0.019931983052643872, 0.019931745543143049, 0.16376600318037862], "pdf_url": "http://jmlr.org/proceedings/papers/v28/wu13.pdf", "most_common": ["bekk", "bmdc", "time", "model", "models", "predictive", "particle", "multivariate", "series", "dynamic", "covariance", "method", "data", "parameters", "performance", "inference", "likelihood", "number", "bayesian", "methods", "process", "parameter", "experiments", "mean", "gwp", "daily", "section", "returns", "average", "posterior", "aud", "standard", "used", "figure", "financial", "particles", "wishart", "generalized", "proposed", "regularized", "matrices", "cost", "table", "rapf", "dataset", "gaussian", "previous", "journal", "ghahramani", "market", "garch", "eur", "wilson", "equity", "case", "using", "step", "finally", "stochastic", "estimates", "prediction", "engle", "brl", "predictions", "values", "shows", "diagonal", "volatility", "statistical", "best", "however", "empirical", "jpy", "computational", "distribution", "auxiliary", "algorithm", "results", "novel", "large", "sequential", "shown", "training", "autoregressive", "times", "also", "set", "importance", "analyzed", "comparison", "datasets", "maximum", "shrinkage", "zero", "heteroscedastic", "changes", "plot", "given", "following", "performed"], "authors": "Yue Wu; Jose Miguel Hernandez-Lobato; Ghahramani Zoubin", "thumbnail_path": "thumbnails/Dynamic Covariance Models for Multivariate Financial Time Series.jpg"}, {"title": "Learning Sparse Penalties for Change-point Detection using Max Margin Interval Regression", "topics": [0.016881409625108933, 0.91559293023806054, 0.016881546143539483, 0.016881481434820232, 0.016881261466274236, 0.016881371092196642], "pdf_url": "http://jmlr.org/proceedings/papers/v28/hocking13.pdf", "most_common": ["using", "model", "log", "data", "annotation", "penalty", "learning", "loss", "function", "interval", "error", "signal", "regression", "number", "surrogate", "detection", "table", "optimal", "term", "problem", "figure", "annotated", "smoothing", "penalties", "target", "margin", "signals", "learn", "set", "use", "convex", "functions", "features", "algorithm", "annotations", "complexity", "shown", "since", "exp", "models", "segments", "feature", "max", "used", "noise", "variance", "sparse", "one", "arg", "plausiblek", "calculate", "two", "selection", "minimizing", "several", "changes", "sets", "bic", "kmax", "constant", "every", "panel", "visual", "may", "regions", "estimate", "mbic", "points", "line", "four", "vector", "estimated", "section", "learned", "method", "segmentation", "size", "changepoint", "min", "show", "however", "many", "uses", "results", "exact", "relaxation", "training", "criterion", "propose", "found", "separable", "note", "algorithms", "multiple", "lavielle", "expert", "drawn", "limits", "hocking", "database"], "authors": "Toby Hocking; Guillem Rigaill; Jean-Philippe VERT; Francis BACH", "thumbnail_path": "thumbnails/Learning Sparse Penalties for Change-point Detection using Max Margin Interval Regression.jpg"}, {"title": "Hierarchically-coupled hidden Markov models for learning kinetic rates from single-molecule data", "topics": [0.013345139727088345, 0.93327448994223117, 0.013345103654843843, 0.013345173639641663, 0.013345029573666831, 0.013345063462528161], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/willemvandemeent13.pdf", "most_common": ["time", "states", "model", "data", "inference", "series", "bayes", "set", "state", "models", "number", "log", "estimation", "learning", "variational", "empirical", "posterior", "veb", "analysis", "hyperparameters", "kinetic", "lower", "markov", "ensemble", "hidden", "experimental", "results", "rates", "simulated", "bound", "parameters", "transition", "single", "two", "experiments", "shows", "inferred", "selection", "hmms", "prior", "figure", "approach", "terms", "maximum", "distribution", "type", "known", "lveb", "likelihood", "means", "expectation", "individual", "bayesian", "procedure", "used", "methods", "graphical", "method", "conformational", "gonzalez", "molecule", "smfret", "consensus", "form", "similar", "use", "machine", "transitions", "shown", "could", "histograms", "hyperparameter", "show", "mixture", "using", "respect", "distributions", "bishop", "whereas", "algorithm", "biophysical", "maximization", "obtained", "parameter", "energy", "given", "observations", "jordan", "also", "shared", "error", "parametric", "bronson", "yields", "observables", "level", "experiment", "along", "fei", "equation"], "authors": "Jan-Willem Van de Meent; Jonathan Bronson; Frank Wood; Ruben Gonzalez, Jr.; Chris Wiggins", "thumbnail_path": "thumbnails/Hierarchically-coupled hidden Markov models for learning kinetic rates from single-molecule data.jpg"}, {"title": "Learning Connections in Financial Time Series", "topics": [0.017606432405359793, 0.9119674890438626, 0.017606395224345272, 0.017606505397931686, 0.017606469207246216, 0.017606708721254517], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/ganeshapillai13.pdf", "most_common": ["returns", "return", "model", "equities", "portfolio", "correlation", "matrix", "using", "method", "daily", "connectedness", "time", "market", "portfolios", "learning", "expected", "series", "risk", "large", "use", "two", "equity", "extreme", "used", "given", "factor", "connections", "weights", "financial", "day", "methods", "learn", "sharpe", "table", "events", "journal", "covariance", "positive", "therefore", "figure", "sector", "set", "cov", "optimization", "multivariate", "values", "map", "days", "historical", "cumulative", "negative", "problem", "partial", "learned", "losses", "ratio", "data", "sectors", "energy", "since", "least", "also", "construction", "fac", "cost", "minimum", "based", "statistical", "among", "precision", "regression", "built", "maximum", "results", "list", "active", "crisis", "information", "may", "pcr", "companies", "evcr", "measures", "sensitivity", "variance", "build", "average", "models", "relationships", "solnik", "work", "analysis", "squares", "estimate", "investors", "min", "performance", "bac", "parameters", "new"], "authors": "Gartheeban Ganeshapillai; John Guttag; Andrew Lo", "thumbnail_path": "thumbnails/Learning Connections in Financial Time Series.jpg"}, {"title": "The Extended Parameter Filter", "topics": [0.015369624204488489, 0.92315176280402289, 0.015369712746507912, 0.015369684746956424, 0.015369598325395537, 0.015369617172628736], "pdf_url": "http://jmlr.org/proceedings/papers/v28/bugraerol13.pdf", "most_common": ["parameter", "model", "time", "approximation", "transition", "density", "particles", "particle", "algorithm", "gibbs", "mean", "approximate", "epf", "figure", "order", "models", "parameters", "polynomial", "extended", "function", "taylor", "section", "state", "sampling", "may", "distribution", "process", "sample", "values", "static", "true", "kalman", "filter", "converges", "statistics", "separable", "variables", "note", "observation", "storvik", "carlo", "method", "following", "sir", "one", "system", "converge", "approach", "arbitrary", "posterior", "deviation", "update", "monte", "let", "use", "sin", "statistical", "matrix", "space", "shows", "case", "bayesian", "step", "general", "degeneracy", "standard", "data", "series", "gaussian", "given", "estimation", "learning", "value", "theorem", "using", "per", "problem", "sequential", "inference", "known", "equation", "dynamical", "complexity", "markov", "however", "approximations", "doucet", "show", "respect", "applied", "sequence", "supplementary", "statistic", "log", "form", "constant", "assume", "cauchy", "requires", "dynamic"], "authors": "Yusuf Bugra Erol;", "thumbnail_path": "thumbnails/The Extended Parameter Filter.jpg"}, {"title": "Transition Matrix Estimation in High Dimensional Time Series", "topics": [0.016439482937168466, 0.91780263541583074, 0.01643946840752215, 0.016439503093122861, 0.01643946450672867, 0.016439445639627206], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/han13a.pdf", "most_common": ["matrix", "transition", "var", "method", "data", "let", "equation", "estimation", "time", "lasso", "models", "vector", "high", "series", "dimensional", "autoregressive", "model", "methods", "paper", "ridge", "represent", "section", "max", "new", "norm", "following", "log", "norms", "proposed", "estimator", "matrices", "covariance", "sparsity", "stationary", "averaged", "frobenius", "estimating", "linear", "penalty", "respect", "three", "analysis", "liu", "using", "problem", "results", "synthetic", "entries", "level", "analyzing", "sample", "theoretical", "provide", "stock", "lag", "propose", "induced", "result", "pattern", "nonzero", "provided", "convergence", "argmin", "existing", "dimensionality", "multivariate", "table", "brain", "statistical", "number", "one", "minj", "points", "subject", "losses", "empirical", "optimization", "error", "journal", "han", "moreover", "comparison", "compared", "prediction", "sign", "marginal", "work", "figure", "process", "introduce", "gaussian", "support", "size", "asymptotic", "doubly", "maxj", "performance", "selection", "show", "set"], "authors": "Fang Han; Han Liu", "thumbnail_path": "thumbnails/Transition Matrix Estimation in High Dimensional Time Series.jpg"}, {"title": "Dependent Normalized Random Measures", "topics": [0.015238431438162805, 0.92380754114173691, 0.015238536308138944, 0.015238514473476589, 0.015238253528170122, 0.015238723110314602], "pdf_url": "http://jmlr.org/proceedings/papers/v28/chen13i.pdf", "most_common": ["random", "normalized", "qrt", "process", "measures", "dependent", "sampler", "time", "gamma", "models", "slice", "number", "hmngg", "marginal", "topic", "probability", "set", "measure", "atoms", "htngg", "datasets", "parameter", "region", "dirichlet", "posterior", "see", "nrms", "crm", "mngg", "also", "independent", "teh", "tngg", "crms", "tnrm", "distribution", "two", "zrtk", "wrk", "distributed", "mnrm", "documents", "poisson", "appendix", "thinning", "variables", "observations", "construction", "nrm", "used", "samplers", "weights", "following", "stl", "intensity", "thus", "model", "lin", "thinned", "ess", "work", "times", "mixture", "vtl", "using", "spatial", "test", "larger", "sample", "xtl", "data", "nonparametric", "training", "rao", "constructions", "generalized", "class", "ngg", "words", "associated", "bayesian", "hdp", "assigned", "follows", "icml", "hierarchical", "atom", "hmngp", "allowing", "tpami", "index", "rate", "base", "resulting", "inference", "call", "marginally", "values", "regions", "james"], "authors": "Changyou Chen; Vinayak Rao; Yee Whye Teh; Wray Buntine", "thumbnail_path": "thumbnails/Dependent Normalized Random Measures.jpg"}, {"title": "Topic Discovery through Data Dependent and Random Projections", "topics": [0.015712305289804548, 0.92143846222627379, 0.015712291157156773, 0.015712337244911723, 0.015712355937968124, 0.015712248143885141], "pdf_url": "http://jmlr.org/proceedings/papers/v28/ding13.pdf", "most_common": ["novel", "topic", "words", "algorithm", "matrix", "word", "topics", "random", "ddp", "arora", "set", "gibbs", "algorithms", "data", "points", "projections", "extreme", "document", "convex", "dataset", "two", "number", "documents", "dependent", "nmf", "distinct", "clustering", "complexity", "error", "proposition", "given", "also", "approach", "discovery", "extracted", "since", "probability", "blei", "learning", "steyvers", "maximum", "table", "iid", "training", "ground", "modeling", "swimmer", "patterns", "image", "zzz", "provable", "projection", "work", "following", "example", "figure", "sample", "end", "correspond", "shown", "one", "separability", "multiple", "based", "direction", "truth", "distribution", "estimated", "method", "latent", "parameters", "apply", "positive", "values", "tan", "dirichlet", "nonnegative", "show", "asymptotically", "present", "empirical", "analysis", "proposed", "input", "using", "output", "images", "similar", "associated", "single", "clean", "synthetic", "condition", "diag", "section", "body", "let", "machine", "order", "positions"], "authors": "Weicong Ding; Mohammad Hossein Rohban; Prakash Ishwar; Venkatesh Saligrama", "thumbnail_path": "thumbnails/Topic Discovery through Data Dependent and Random Projections.jpg"}, {"title": "Factorial Multi-Task Learning : A Bayesian Nonparametric Approach", "topics": [0.014617482711263933, 0.92691287006339251, 0.014617445707271449, 0.014617409531210192, 0.014617527402384659, 0.014617264584477273], "pdf_url": "http://jmlr.org/proceedings/papers/v28/gupta13a.pdf", "most_common": ["tasks", "learning", "task", "model", "process", "subspace", "groups", "data", "using", "beta", "number", "group", "hierarchical", "prior", "predictors", "bayesian", "regression", "nonparametric", "bases", "posterior", "factor", "shared", "set", "training", "used", "dirichlet", "use", "datasets", "machine", "factorial", "framework", "related", "joint", "across", "sampling", "analysis", "gupta", "varying", "iii", "given", "performance", "relatedness", "distribution", "results", "synthetic", "dataset", "however", "real", "sharing", "multiple", "modeling", "second", "proposed", "index", "degree", "allows", "figure", "rmse", "inferred", "approach", "basis", "gibbs", "school", "method", "multitask", "passos", "individual", "conference", "bernoulli", "journal", "two", "jointly", "inference", "applications", "experiments", "one", "argyriou", "stl", "see", "problem", "automatically", "research", "unrelated", "ztk", "construction", "hbp", "therefore", "kumar", "xti", "share", "sample", "feature", "kang", "matrix", "partition", "mixture", "written", "fut", "zgt", "examples"], "authors": "Sunil Gupta; Dinh Phung; Svetha Venkatesh", "thumbnail_path": "thumbnails/Factorial Multi-Task Learning : A Bayesian Nonparametric Approach.jpg"}, {"title": "Scaling the Indian Buffet Process via Submodular Maximization", "topics": [0.016409333975762115, 0.91795358766778734, 0.016409276257509868, 0.016409411187756521, 0.016409177933413698, 0.016409212977770548], "pdf_url": "http://jmlr.org/proceedings/papers/v28/reed13.pdf", "most_common": ["submodular", "ibp", "inference", "meibp", "latent", "variational", "models", "methods", "dataset", "model", "algorithm", "nonnegative", "maximization", "data", "function", "indian", "priors", "solution", "via", "process", "feature", "map", "complexity", "ghahramani", "matrix", "features", "evidence", "using", "distribution", "time", "prior", "ugibbs", "znk", "bnmf", "gaussian", "show", "solutions", "converged", "lower", "aibp", "bound", "true", "mfvb", "sampling", "results", "likelihood", "given", "optimization", "binary", "used", "factors", "updates", "large", "test", "akd", "scaling", "kan", "random", "local", "rvs", "synthetic", "figure", "optimal", "number", "also", "set", "however", "convergence", "equivalence", "following", "vibp", "kbn", "obtains", "shows", "piano", "columns", "flickr", "bayesian", "obtain", "sparse", "assignments", "submodularity", "maximum", "global", "welling", "small", "let", "kurihara", "larger", "use", "framework", "space", "see", "optimum", "terms", "independent", "maximizing", "yields", "truncated", "approximate"], "authors": "Colorado Reed; Ghahramani Zoubin", "thumbnail_path": "thumbnails/Scaling the Indian Buffet Process via Submodular Maximization.jpg"}, {"title": "A Variational Approximation for Topic Modeling of Hierarchical Corpora", "topics": [0.016069107325561462, 0.91964242814357833, 0.016069177584091019, 0.016069164147844948, 0.016081083976729339, 0.01606903882219482], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/kim13.pdf", "most_common": ["topic", "variational", "corpora", "dirichlet", "tilda", "model", "hierarchical", "hdps", "models", "proportions", "approximation", "corpus", "inference", "topics", "documents", "number", "results", "lda", "document", "parameters", "latent", "one", "blackhatworld", "teh", "section", "also", "blei", "modeling", "gibbs", "bound", "categories", "variables", "approach", "sampling", "learning", "figure", "subcategories", "wang", "category", "log", "freelancer", "large", "prior", "two", "nonparametric", "online", "proceedings", "job", "distribution", "lower", "deep", "nodes", "work", "root", "paper", "parent", "conference", "levels", "algorithm", "represent", "zdn", "machine", "applications", "developed", "main", "approaches", "international", "see", "terms", "however", "attached", "many", "procedure", "nips", "describes", "structure", "finally", "postings", "use", "information", "collection", "inequality", "related", "used", "special", "internet", "tokens", "note", "words", "set", "graphical", "bayesian", "web", "opt", "articles", "methods", "form", "node", "draw", "four"], "authors": "Do-kyum Kim; Geoffrey Voelker; Lawrence Saul", "thumbnail_path": "thumbnails/A Variational Approximation for Topic Modeling of Hierarchical Corpora.jpg"}, {"title": "Manifold Preserving Hierarchical Topic Models for Quantization and Approximation", "topics": [0.019068185682442621, 0.90465917065272572, 0.019068159400570151, 0.019068243601518601, 0.019068094554724007, 0.019068146108018887], "pdf_url": "http://jmlr.org/proceedings/papers/v28/kim13a.pdf", "most_common": ["manifold", "data", "samples", "sampling", "quantization", "input", "topic", "source", "figure", "plsi", "mixture", "proposed", "topics", "training", "interpolation", "sparse", "number", "preserving", "models", "convex", "separation", "using", "random", "overcomplete", "hull", "model", "latent", "parameters", "set", "hierarchical", "method", "neighbors", "approximation", "use", "two", "points", "also", "sparsity", "results", "better", "one", "layer", "cross", "speech", "variable", "original", "second", "learned", "vectors", "rates", "entropy", "ordinary", "parameter", "corners", "linear", "sum", "selection", "reconstruct", "rate", "case", "representation", "note", "probabilistic", "estimation", "best", "sources", "digit", "provide", "systems", "matrix", "nts", "estimate", "sets", "class", "neighboring", "proceedings", "whole", "analysis", "provides", "additional", "weights", "four", "blue", "reconstruction", "inputs", "performance", "combination", "shows", "first", "instance", "get", "new", "result", "terms", "however", "smaragdis", "learning", "conference", "three", "less"], "authors": "Minje Kim; Paris Smaragdis", "thumbnail_path": "thumbnails/Manifold Preserving Hierarchical Topic Models for Quantization and Approximation.jpg"}, {"title": "Subtle Topic Models and Discovering Subtly Manifested Software Concerns Automatically ", "topics": [0.017173928000495969, 0.91413050320274136, 0.01717388863269757, 0.017174002763360001, 0.017173858940800903, 0.017173818459904275], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/das13.pdf", "most_common": ["topic", "topics", "subtle", "software", "concerns", "stm", "models", "document", "dirichlet", "process", "ftm", "hdp", "number", "discovering", "detect", "coherence", "vectors", "used", "using", "code", "subtly", "words", "gsbp", "automatically", "distribution", "word", "recall", "concern", "proceedings", "inference", "may", "documents", "manifested", "dataset", "two", "sample", "standard", "corpus", "sentences", "also", "generalized", "however", "problem", "conference", "model", "source", "rare", "discover", "perplexity", "use", "detected", "detecting", "across", "level", "international", "jhotdraw", "sentence", "one", "table", "approach", "distributions", "berkeleydb", "section", "prior", "stick", "breaking", "bdai", "note", "average", "case", "thus", "binary", "important", "program", "small", "rarely", "example", "occur", "propose", "probability", "dos", "datasets", "observed", "ability", "extent", "well", "keywords", "latent", "cases", "end", "nips", "engineering", "denotes", "top", "gold", "text", "conditional", "due", "empirical", "lda"], "authors": "Mrinal Das; Suparna Bhattacharya; Chiranjib Bhattacharyya; Gopinath Kanchi", "thumbnail_path": "thumbnails/Subtle Topic Models and Discovering Subtly Manifested Software Concerns Automatically .jpg"}, {"title": "Latent Dirichlet Allocation Topic Model with Soft Assignment of Descriptors to Words", "topics": [0.017106788647402858, 0.91446615483984006, 0.017106728825796932, 0.017106837785937912, 0.017106678293766046, 0.017106811607256415], "pdf_url": "http://jmlr.org/proceedings/papers/v28/weinshall13.pdf", "most_common": ["model", "words", "lda", "assignment", "dictionary", "word", "video", "soft", "descriptors", "topic", "events", "log", "using", "probability", "variational", "generative", "detection", "represented", "parameter", "one", "documents", "mixture", "described", "distribution", "descriptor", "learning", "document", "extended", "use", "set", "inference", "algorithm", "given", "blei", "estimation", "vector", "order", "original", "mahadevan", "section", "data", "hard", "latent", "novelty", "parameters", "representation", "used", "size", "state", "bag", "bags", "fdn", "similar", "models", "novel", "fdnj", "following", "collection", "hidden", "training", "dirichlet", "features", "observed", "online", "exp", "dataset", "dynamic", "obtained", "probabilities", "visual", "event", "topics", "frame", "respect", "thus", "cvpr", "performance", "method", "therefore", "may", "likelihood", "isa", "corpus", "continuous", "sivic", "vision", "achieved", "modeling", "lower", "identify", "fdna", "image", "methods", "function", "histogram", "update", "patches", "level", "discrete", "new"], "authors": "Daphna Weinshall; Gal Levi; Dmitri Hanukaev", "thumbnail_path": "thumbnails/Latent Dirichlet Allocation Topic Model with Soft Assignment of Descriptors to Words.jpg"}, {"title": "Efficient Multi-label Classification with Many Labels", "topics": [0.0175711536725108, 0.91214414902198915, 0.017570991922064034, 0.017571184218193807, 0.017571018180074977, 0.01757150298516726], "pdf_url": "http://jmlr.org/proceedings/papers/v28/bi13.pdf", "most_common": ["label", "number", "labels", "data", "sampling", "matrix", "proposed", "columns", "error", "log", "algorithm", "boutsidis", "learning", "time", "plst", "section", "encoding", "cssp", "set", "many", "probability", "table", "cplst", "large", "approximation", "moplms", "rank", "training", "selected", "also", "using", "methods", "dmoz", "machine", "selection", "algorithms", "proceedings", "thus", "subset", "rmse", "lin", "best", "much", "drineas", "output", "results", "use", "sample", "shows", "however", "conference", "trials", "proposition", "full", "sets", "kernel", "binary", "used", "analysis", "desc", "column", "delicious", "problem", "svd", "prediction", "international", "method", "may", "space", "performance", "various", "optimization", "perform", "obtain", "transformation", "takes", "problems", "vector", "obtained", "ndk", "computationally", "approach", "moreover", "transformed", "lebanon", "step", "compute", "balasubramanian", "zhang", "hyc", "even", "vectors", "select", "following", "tai", "multilabel", "randomized", "given", "testing", "rrqr"], "authors": "Wei Bi; James Kwok", "thumbnail_path": "thumbnails/Efficient Multi-label Classification with Many Labels.jpg"}, {"title": "A Randomized Mirror Descent Algorithm for Large Scale Multiple Kernel Learning", "topics": [0.015865124598177106, 0.92067440608512219, 0.015865120136273191, 0.015865194670106546, 0.015865065173093277, 0.015865089337227831], "pdf_url": "http://jmlr.csail.mit.edu/proceedings/papers/v28/afkanpour13.pdf", "most_common": ["algorithm", "kernel", "learning", "kernels", "method", "gradient", "descent", "large", "let", "randomized", "note", "mirror", "set", "methods", "problem", "number", "mkl", "convex", "multiple", "case", "kloft", "algorithms", "section", "sampling", "polynomial", "also", "scale", "machine", "space", "see", "time", "estimate", "example", "complexity", "base", "one", "based", "however", "input", "weights", "stochastic", "product", "notation", "coordinate", "computational", "function", "use", "iteration", "pages", "cortes", "results", "degree", "compare", "sample", "standard", "performance", "distribution", "optimization", "thus", "journal", "underlying", "bach", "convergence", "assume", "consider", "research", "cost", "training", "experiments", "given", "importance", "conference", "empirical", "predictor", "denote", "vector", "uniform", "holds", "data", "shown", "shows", "proceedings", "approach", "paper", "terms", "value", "depends", "using", "loss", "works", "nesterov", "form", "volume", "fact", "solution", "penalized", "linearly", "particular", "learn", "following"], "authors": "Arash Afkanpour; Andras Gyorgy; Csaba Szepesvari; Michael Bowling", "thumbnail_path": "thumbnails/A Randomized Mirror Descent Algorithm for Large Scale Multiple Kernel Learning.jpg"}, {"title": "MILEAGE: Multiple Instance LEArning with Global Embedding", "topics": [0.015179698976515167, 0.92410221592363406, 0.015179648620145491, 0.0151795457610805, 0.015179401719817137, 0.015179488998807561], "pdf_url": "http://jmlr.org/proceedings/papers/v28/zhang13a.pdf", "most_common": ["global", "method", "local", "instance", "positive", "learning", "proposed", "example", "methods", "representation", "bundle", "instances", "multiple", "problem", "feature", "bag", "mileage", "bij", "two", "mil", "experiments", "better", "used", "one", "objective", "function", "representations", "dataset", "misvm", "traditional", "embedding", "optimization", "solve", "theorem", "convex", "max", "based", "negative", "bags", "andrews", "set", "remp", "cutting", "however", "log", "results", "ratio", "fuduli", "considered", "also", "image", "datasets", "svm", "solving", "training", "features", "given", "iteration", "min", "maxj", "accuracy", "text", "parts", "whether", "large", "insider", "information", "complexity", "shown", "threat", "rademacher", "please", "margin", "proximity", "research", "joachims", "vector", "approximation", "labeled", "optimal", "parameter", "derived", "framework", "conducted", "employed", "paper", "detection", "otherwise", "unlabeled", "lower", "icml", "planes", "novel", "solution", "section", "parameters", "ratios", "following", "proof", "machine"], "authors": "Dan Zhang; Jingrui He; Luo Si; Richard Lawrence", "thumbnail_path": "thumbnails/MILEAGE: Multiple Instance LEArning with Global Embedding.jpg"}]}